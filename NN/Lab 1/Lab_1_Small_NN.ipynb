{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 1 Small - NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgeaidinis/NTUA/blob/master/NN/Lab%201/Lab_1_Small_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKqs0XolswuQ",
        "colab_type": "text"
      },
      "source": [
        "Αϊδίνης Γιώργος 03116031\n",
        "\n",
        "Κολιός Παναγιώτης 03116100\n",
        "\n",
        "---\n",
        "\n",
        "Ομάδα M.B.8\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Lab 1: Επιβλεπόμενη Μάθηση - Ταξινόμηση - Μικρό Dataset (S11 - Quality Assessment of Digital Colposcopies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypUIaKPuxyCI",
        "colab_type": "text"
      },
      "source": [
        "Αρχικά ενημερώνουμε τις βιβλιοθήκες που θα χρησιμοποιήσουμε.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZTpGgaqwT3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "16aae320-a435-4028-8d6d-fd4811c1896e"
      },
      "source": [
        "!pip install --upgrade pip #upgrade pip package installer\n",
        "!pip install scikit-learn --upgrade #upgrade scikit-learn package\n",
        "!pip install numpy --upgrade #upgrade numpy package\n",
        "!pip install pandas --upgrade #--upgrade #upgrade pandas package"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n",
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/d0/860c4f6a7027e00acff373d9f5327f4ae3ed5872234b3cbdd7bcb52e5eff/scikit_learn-0.22-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "Installing collected packages: scikit-learn\n",
            "  Found existing installation: scikit-learn 0.21.3\n",
            "    Uninstalling scikit-learn-0.21.3:\n",
            "      Successfully uninstalled scikit-learn-0.21.3\n",
            "Successfully installed scikit-learn-0.22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_deFZG7YvKWh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   Το dataset περιγράφει μετρήσεις κολποσκοπήσεων και την κατάσταση (ετικέτα) των αντίστοιχων κόλπων, όπως προκύπτει από τις εκτιμήσεις καθενός από 6 ειδικούς και την εκτίμηση της πλειοψηφίας. Οι μετρήσεις και οι εκτιμήσεις είναι διαφορετικές για τις διαφορετικές μεθόδους με τις οποίες πραγματοποιούνται οι κολποσκοπήσεις: Hinselmann, Green, Schiller.\n",
        "\n",
        "\n",
        "\n",
        "2.    Έχουμε συνολικά 287 δείγματα, 92 από τη μέθοδο Schiller, 98 από τη μέθοδο Green και 97 από τη μέθοδο Hinselmann. Σε κάθε δείγμα περιέχονται μετρήσεις για 62 χαρακτηριστικά-παρατηρήσεις από τα οποία προέκυψαν οι εκτιμήσεις. Όλα τα χαρακτηριστικά είναι διατεταγμένα.Οι μετρήσεις είναι αριθμητικά δεδομένα και αφορούν τιμές όπως τις επιφάνειες περιοχών του κόπλου.\n",
        "\n",
        "3.    Υπάρχουν επικεφαλίδες στην πρώτη γραμμή πάνω από τα χαρακτηριστικά και τις ετικέτες, οι οποίες θα πρέπει να αφαιρεθούν. Δεν υπάρχει στήλη για την αρίθμηση των γραμμών.\n",
        "\n",
        "4.    Η τιμή της κατάστασης μπορεί να πάρει δύο τιμές, 0 για κακή και 1 για καλή. Όπως υποδεικνύεται από τις FAQ το πρόβλημα θα αναλυθεί ως binary classification λαμβάνοντας υπόψην μόνο τις εκτιμήσεις της πλειοψηφίας. Έτσι οι στήλες των ετικετών που αφορούν μεμονωμένα τον κάθε ειδικό αφαιρούνται και μένει μόνο η τελευταία στήλη με τις εκτιμήσεις της πλειοψηφίας. Η στήλη αυτή είναι η τελευταία (θέση 69 στον αρχικό πίνακα). Παρατηρούμε οτι όλες οι ισοψηφίες (3-3) επιλύονται θεωρώντας την κατάσταση ως καλή, γεγονός που ίσως μας αναγκάσει να αυξήσουμε αργότερα το πλήθος των δειγμάτων με ετικέτα 0 ή να διαγράψουμε δείγματα με ετικέτα 1.\n",
        "\n",
        "    \n",
        "5.    Συνενώνουμε τα αρχεία που αφορούν τις 3 διαφορετικές μεθόδους. Μετά τη συνένωση οι επικεφαλίδες προστέθηκαν ως γραμμές, με αποτέλεσμα να έχουμε 3 φορές την ίδια γραμμή με τις επικεφαλίδες, τις οποίες και αφαιρούμε.\n",
        "\n",
        "6.    Δεν υπάρχουν απουσιάζουσες τιμές.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPGXEYNcqtmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def download(url, file):\n",
        "    if not os.path.isfile(file):\n",
        "        print(\"Download file... \" + file + \" ...\")\n",
        "        urlretrieve(url,file)\n",
        "        print(\"File downloaded\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL_pZToQuTs4",
        "colab_type": "code",
        "outputId": "742cd47c-8750-429d-92c0-a3e5a18b42e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "download(\"http://archive.ics.uci.edu/ml/machine-learning-databases/00384/Quality%20Assessment%20-%20Digital%20Colposcopy.zip\",\"QADC.zip\")\n",
        "print(\"All the files are downloaded\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download file... QADC.zip ...\n",
            "File downloaded\n",
            "All the files are downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1fY1PPQ7L9d",
        "colab_type": "code",
        "outputId": "1cc2358e-2c68-403f-8785-2ffce3ac7c1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QADC.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFe5qqIq6jSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q \"QADC.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AZDcWwK7IKb",
        "colab_type": "code",
        "outputId": "6ab79c34-923e-4224-a98c-80a7984b0cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " QADC.zip  'Quality Assessment - Digital Colposcopy'   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDKrxf0wzLvH",
        "colab_type": "text"
      },
      "source": [
        "Rename directory for better handling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxlh8yEDy47d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv Quality\\ Assessment\\ -\\ Digital\\ Colposcopy QADC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PDIZ5HBzx9i",
        "colab_type": "text"
      },
      "source": [
        "Remove attributes line for the 2nd and 3rd files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhtKAnFCyl0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"QADC/hinselmann.csv\",'r') as f:\n",
        "    with open(\"QADC/hinselmann1.csv\",'w') as f1:\n",
        "        next(f) # skip header line\n",
        "        for line in f:\n",
        "            f1.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcY__jBiymmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"QADC/schiller.csv\",'r') as f:\n",
        "    with open(\"QADC/schiller1.csv\",'w') as f1:\n",
        "        next(f) # skip header line\n",
        "        for line in f:\n",
        "            f1.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hTiHGpp0JR2",
        "colab_type": "text"
      },
      "source": [
        "create one big .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VimXlyS7fGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat QADC/green.csv QADC/hinselmann1.csv QADC/schiller1.csv > all.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPLZO8N605LP",
        "colab_type": "text"
      },
      "source": [
        "We needed to concatenate the 3 .csv files && remove the category names from the second and third files gia na min exoume asxeta instances\n",
        "We also need to remove the attribute of the experts, apart from the concensus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVGBnlk67zwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"all.csv\")\n",
        "df = df.drop(df.columns[[62, 63, 64, 65, 66, 67]], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0110eLi0kT7",
        "colab_type": "text"
      },
      "source": [
        "Let's print number, names and types of attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ1Qrlcl0h_t",
        "colab_type": "code",
        "outputId": "57e8961f-3f6d-4e76-8a4a-125926f57e07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print (\"We have \",len(df.columns), \" attributes.\")\n",
        "for i in range(0, len(df.columns)):\n",
        "    print('{:<10}{:<40}{:<10}{:<20}'.format(str(i+1), str(df.columns[i]),\"type: \", str(df.dtypes[df.columns[i]])))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have  63  attributes.\n",
            "1         cervix_area                             type:     float64             \n",
            "2         os_area                                 type:     float64             \n",
            "3         walls_area                              type:     float64             \n",
            "4         speculum_area                           type:     float64             \n",
            "5         artifacts_area                          type:     float64             \n",
            "6         cervix_artifacts_area                   type:     float64             \n",
            "7         os_artifacts_area                       type:     float64             \n",
            "8         walls_artifacts_area                    type:     float64             \n",
            "9         speculum_artifacts_area                 type:     float64             \n",
            "10        cervix_specularities_area               type:     float64             \n",
            "11        os_specularities_area                   type:     float64             \n",
            "12        walls_specularities_area                type:     float64             \n",
            "13        speculum_specularities_area             type:     float64             \n",
            "14        specularities_area                      type:     float64             \n",
            "15        area_h_max_diff                         type:     float64             \n",
            "16        rgb_cervix_r_mean                       type:     float64             \n",
            "17        rgb_cervix_r_std                        type:     float64             \n",
            "18        rgb_cervix_r_mean_minus_std             type:     float64             \n",
            "19        rgb_cervix_r_mean_plus_std              type:     float64             \n",
            "20        rgb_cervix_g_mean                       type:     float64             \n",
            "21        rgb_cervix_g_std                        type:     float64             \n",
            "22        rgb_cervix_g_mean_minus_std             type:     float64             \n",
            "23        rgb_cervix_g_mean_plus_std              type:     float64             \n",
            "24        rgb_cervix_b_mean                       type:     float64             \n",
            "25        rgb_cervix_b_std                        type:     float64             \n",
            "26        rgb_cervix_b_mean_minus_std             type:     float64             \n",
            "27        rgb_cervix_b_mean_plus_std              type:     float64             \n",
            "28        rgb_total_r_mean                        type:     float64             \n",
            "29        rgb_total_r_std                         type:     float64             \n",
            "30        rgb_total_r_mean_minus_std              type:     float64             \n",
            "31        rgb_total_r_mean_plus_std               type:     float64             \n",
            "32        rgb_total_g_mean                        type:     float64             \n",
            "33        rgb_total_g_std                         type:     float64             \n",
            "34        rgb_total_g_mean_minus_std              type:     float64             \n",
            "35        rgb_total_g_mean_plus_std               type:     float64             \n",
            "36        rgb_total_b_mean                        type:     float64             \n",
            "37        rgb_total_b_std                         type:     float64             \n",
            "38        rgb_total_b_mean_minus_std              type:     float64             \n",
            "39        rgb_total_b_mean_plus_std               type:     float64             \n",
            "40        hsv_cervix_h_mean                       type:     float64             \n",
            "41        hsv_cervix_h_std                        type:     float64             \n",
            "42        hsv_cervix_s_mean                       type:     float64             \n",
            "43        hsv_cervix_s_std                        type:     float64             \n",
            "44        hsv_cervix_v_mean                       type:     float64             \n",
            "45        hsv_cervix_v_std                        type:     float64             \n",
            "46        hsv_total_h_mean                        type:     float64             \n",
            "47        hsv_total_h_std                         type:     float64             \n",
            "48        hsv_total_s_mean                        type:     float64             \n",
            "49        hsv_total_s_std                         type:     float64             \n",
            "50        hsv_total_v_mean                        type:     float64             \n",
            "51        hsv_total_v_std                         type:     float64             \n",
            "52        fit_cervix_hull_rate                    type:     float64             \n",
            "53        fit_cervix_hull_total                   type:     float64             \n",
            "54        fit_cervix_bbox_rate                    type:     float64             \n",
            "55        fit_cervix_bbox_total                   type:     float64             \n",
            "56        fit_circle_rate                         type:     float64             \n",
            "57        fit_circle_total                        type:     float64             \n",
            "58        fit_ellipse_rate                        type:     float64             \n",
            "59        fit_ellipse_total                       type:     float64             \n",
            "60        fit_ellipse_goodness                    type:     float64             \n",
            "61        dist_to_center_cervix                   type:     float64             \n",
            "62        dist_to_center_os                       type:     float64             \n",
            "63        consensus                               type:     float64             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFW2ZAJs6pIz",
        "colab_type": "text"
      },
      "source": [
        "We need to count the occurences of each label (healthy or unhealthy):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2757HtVM6vna",
        "colab_type": "code",
        "outputId": "1b4d1d58-e350-4bd7-f70d-f0c37ec063b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels_df = df.iloc[:, [62]]\n",
        "labels = labels_df.values.reshape(287,)\n",
        "positive = 0\n",
        "negative = 0\n",
        "for i in range(0, len(labels)):\n",
        "    positive += labels[i]==1\n",
        "    negative += labels[i]==0\n",
        "print(\"positive = \", positive, \" negative: \", negative)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive =  216  negative:  71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe8KtmADxNwS",
        "colab_type": "text"
      },
      "source": [
        "Βλεπουμε οτι εχουμε unbalanced data set, καθως η κλαση των positive(υγειων) ειναι κατα πολυ μεγαλυτερη σε μεγεθος απο την κλαση των negative. (75-25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2l2kgIc_qXj",
        "colab_type": "text"
      },
      "source": [
        "Train - Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBRy3W1k8o82",
        "colab_type": "code",
        "outputId": "a572d573-95a2-4966-8019-947a36bf461a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train, test, train_labels, test_labels = train_test_split(df, labels, test_size=0.2)\n",
        "print(len(train))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCzWdW8gFcSO",
        "colab_type": "code",
        "outputId": "04b528d7-818b-41fd-c10b-02a2ff952802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from scipy import stats as st\n",
        "\n",
        "\n",
        "# standardization\n",
        "std_x = st.zscore(train)\n",
        "Xvar = np.var(std_x, axis=0)\n",
        "print(Xvar)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHjdhP3J_umE",
        "colab_type": "text"
      },
      "source": [
        "Undersampling - Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68L7yenY70BL",
        "colab_type": "code",
        "outputId": "9acd097b-1991-4b06-b8f2-3208c9aa7b52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "positive = 0\n",
        "negative = 0\n",
        "for i in range(0, len(train_labels)):\n",
        "    positive += train_labels[i]==1\n",
        "    negative += train_labels[i]==0\n",
        "print(\"positive = \", positive, \" negative: \", negative)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive =  168  negative:  61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4v4by5X_pXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler(sampling_strategy=0.65)\n",
        "train_oversampled, train_labels_oversampled = ros.fit_sample(train,train_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4DIEMGOD-E6",
        "colab_type": "code",
        "outputId": "77bb3fc5-4837-4fdb-da75-157ddc07e455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "positive = 0\n",
        "negative = 0\n",
        "for i in range(0, len(train_labels_oversampled)):\n",
        "    positive += train_labels_oversampled[i]==1\n",
        "    negative += train_labels_oversampled[i]==0\n",
        "print(\"positive = \", positive, \" negative: \", negative)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive =  168  negative:  109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFvQGqnPEikC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "ros = RandomUnderSampler(random_state=0)\n",
        "train_undersampled, train_labels_undersampled = ros.fit_sample(train_oversampled,train_labels_oversampled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u666iwHyE6BK",
        "colab_type": "code",
        "outputId": "0aa3239d-c91f-46a6-db86-ac523eca8294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "positive = 0\n",
        "negative = 0\n",
        "for i in range(0, len(train_labels_undersampled)):\n",
        "    positive += train_labels_undersampled[i]==1\n",
        "    negative += train_labels_undersampled[i]==0\n",
        "print(\"positive = \", positive, \" negative: \", negative)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive =  109  negative:  109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6p2K8aVFENn",
        "colab_type": "code",
        "outputId": "93725612-e7bb-4de2-c9b1-e4703a3c61d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "Xvar = np.var(train_undersampled, axis=0)\n",
        "print(Xvar)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.12691261e-02 3.61629869e-05 5.06633006e-02 3.31683580e-02\n",
            " 5.97877841e-03 4.17111071e-03 2.52883102e-02 1.32303302e-02\n",
            " 1.62743613e-02 3.79363879e-04 1.84239646e-03 5.22005865e-04\n",
            " 1.07333419e-02 1.40059234e-03 1.91484385e-02 2.40058327e+03\n",
            " 2.83609049e+02 1.48765018e+03 3.88073445e+03 2.67541489e+03\n",
            " 2.81423502e+02 1.72347159e+03 4.19020519e+03 4.29400117e+03\n",
            " 4.53625821e+02 2.55803397e+03 6.93722001e+03 1.36194867e+03\n",
            " 4.85024891e+02 6.34514587e+02 3.05943253e+03 1.22467463e+03\n",
            " 4.75230701e+02 6.31961675e+02 2.76784898e+03 2.63780393e+03\n",
            " 6.17556154e+02 1.23128402e+03 5.27943615e+03 5.02250143e-01\n",
            " 4.09780081e-01 3.26893621e+03 4.72034553e+02 4.08366776e+03\n",
            " 4.03883168e+02 4.18070963e-01 6.08136759e-02 3.12170936e+03\n",
            " 3.82062317e+02 2.01005609e+03 4.81268714e+02 4.15469100e-02\n",
            " 5.97261229e-02 3.76501587e-02 6.58716640e-02 2.25062652e-02\n",
            " 1.98287332e-01 4.41239669e-02 5.43453165e-02 9.74883079e+03\n",
            " 7.31094441e-02 3.23395859e-02 2.50000000e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDZtTNqMBZZE",
        "colab_type": "code",
        "outputId": "3ca47c35-219e-4755-c59f-cdb37a8e1502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from scipy import stats as st\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "train_scaled = preprocessing.scale(train_undersampled)\n",
        "\n",
        "Xvar = np.var(train_scaled, axis=0)\n",
        "print(Xvar)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fYR_D06D1yn",
        "colab_type": "code",
        "outputId": "3fe5bf89-29f3-47e2-dcc9-7558b4815c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "Yvar = np.var(np.asarray(test), axis=0)\n",
        "print(Yvar)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.01536118e-02 4.41991898e-05 2.81535435e-02 3.13689254e-02\n",
            " 5.72414548e-03 2.33192761e-03 2.17612781e-02 7.98061016e-03\n",
            " 1.66159378e-02 1.34389384e-03 4.58203757e-03 5.88747471e-04\n",
            " 1.13288016e-02 1.00843653e-03 1.68077244e-02 2.19638544e+03\n",
            " 2.11328095e+02 1.67776569e+03 3.13766138e+03 2.29478853e+03\n",
            " 2.40123287e+02 1.62062062e+03 3.44920301e+03 3.40560817e+03\n",
            " 3.85452344e+02 2.31832386e+03 5.26379716e+03 1.04808799e+03\n",
            " 3.11456889e+02 6.78684267e+02 2.04040549e+03 9.09464542e+02\n",
            " 3.26039380e+02 6.15038098e+02 1.85596975e+03 1.94031903e+03\n",
            " 4.31011151e+02 9.51666927e+02 3.79099343e+03 4.51687200e-01\n",
            " 2.02965863e-01 2.64748970e+03 3.09842192e+02 2.36892387e+03\n",
            " 2.63756651e+02 3.81609055e-01 5.62918344e-02 2.67513543e+03\n",
            " 4.13497564e+02 6.84060310e+02 2.51571463e+02 1.77867905e-02\n",
            " 4.91124673e-02 1.89743576e-02 5.41145530e-02 1.27377657e-02\n",
            " 1.68569381e-01 1.85292408e-02 4.49743714e-02 1.07219739e+04\n",
            " 4.98401337e-02 2.20424377e-02 1.42687277e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prSXp5QRGssp",
        "colab_type": "code",
        "outputId": "e655287f-0df9-418c-b204-5537f6e8ba28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "scaler = preprocessing.StandardScaler().fit(train_undersampled)\n",
        "test_scaled = scaler.transform(test)\n",
        "Yvar = np.var(np.asarray(test_scaled), axis=0)\n",
        "print(Yvar)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.81857887 1.22222177 0.55569896 0.94574852 0.95741054 0.55906634\n",
            " 0.86052718 0.60320567 1.02098863 3.54249288 2.48699869 1.12785605\n",
            " 1.05547756 0.72000717 0.87775953 0.91493824 0.74513876 1.12779584\n",
            " 0.80852257 0.85773184 0.85324533 0.94032337 0.8231585  0.79310835\n",
            " 0.84971429 0.90629127 0.75877616 0.76955029 0.6421462  1.06961177\n",
            " 0.66692286 0.74261728 0.68606548 0.97322056 0.67054589 0.73558122\n",
            " 0.6979303  0.77290609 0.71806786 0.89932717 0.49530436 0.80989335\n",
            " 0.65639727 0.58009711 0.65305185 0.91278536 0.92564433 0.8569457\n",
            " 1.0822778  0.34031902 0.52272557 0.42811344 0.82229458 0.50396488\n",
            " 0.82151489 0.56596533 0.85012683 0.41993597 0.82756665 1.09982152\n",
            " 0.6817195  0.68159307 0.57074911]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2doolScyIJqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from scipy import stats as st\n",
        "from sklearn import neighbors\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    This is a function that applies a transformation (selection) on a dataset, \n",
        "    based on the type of the selector. Takes 3 arguments, one is mandatory and \n",
        "    is the dataset, which is a tuple of data. It needs to be in the form:\n",
        "    (train_data, train_labels, test_data, test_labels). The other two can be\n",
        "    None, and when they are, no transformation happens. The selector argument\n",
        "    is a string and can be one of two things: either \"PCA\" or \n",
        "    \"Variance Threshold\". In either case, there can be arguments, and in \"PCA\"\n",
        "    the arguments can be an int of the number of principal components, and in\n",
        "    \"Variance Threshold\", it can be a float. Returns the transformed dataset.\n",
        "\"\"\"\n",
        "def Apply_selector(data, selector = None, arguments = None):\n",
        "    (train, train_labels, test, test_labels) = data\n",
        "    if selector == \"PCA\":    \n",
        "        if arguments:\n",
        "            number_of_components = arguments\n",
        "            pca = PCA(n_components = number_of_components)\n",
        "            pca.fit(train)\n",
        "            train_reduced = pca.transform(train)\n",
        "            test_reduced = pca.transform(test)\n",
        "        else:\n",
        "            pca = PCA()\n",
        "            pca.fit(train)\n",
        "            train_reduced = pca.transform(train)\n",
        "            test_reduced = pca.transform(test)\n",
        "    elif selector == \"Variance Threshold\":\n",
        "        if arguments:\n",
        "            t = arguments\n",
        "            sel = VarianceThreshold(threshold=t)\n",
        "            train_reduced = sel.fit_transform(train)\n",
        "            test_reduced = sel.transform(test)\n",
        "        else:\n",
        "            sel = VarianceThreshold()\n",
        "            train_reduced = sel.fit_transform(train)\n",
        "            test_reduced = sel.transform(test)\n",
        "    else:\n",
        "        (train_reduced, train_labels, test_reduced, test_labels) = data\n",
        "    return (train_reduced, train_labels, test_reduced, test_labels)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    This is a function that applies resampling on a dataset, based on the \n",
        "    type of sampling method. Takes 3 arguments, one is mandatory and \n",
        "    is the dataset, which is a tuple of data. It needs to be in the form:\n",
        "    (train_data, train_labels, test_data, test_labels). The other two can be\n",
        "    None, and when they are, no sampling happens. The sampling argument\n",
        "    is a string and can be one of three things: \"Over\", \"Under\" or \n",
        "    \"OverUnder\". In any case, there can be arguments, and in Under or Over or\n",
        "    OverUnder it can be a float with the ratio of samples between classes. \n",
        "    Returns the resampled dataset.\n",
        "\"\"\"\n",
        "def Apply_sampling(data, sampling = None, arguments = None):\n",
        "    (train, train_labels, test, test_labels) = data\n",
        "    if sampling == \"Over\":    \n",
        "        if arguments:\n",
        "            ratio = arguments\n",
        "            ros = RandomOverSampler(sampling_strategy=ratio)\n",
        "            train_oversampled, train_labels_oversampled = ros.fit_sample(train,train_labels)\n",
        "        else:\n",
        "            ros = RandomOverSampler()\n",
        "            train_oversampled, train_labels_oversampled = ros.fit_sample(train,train_labels)\n",
        "        return (train_oversampled, train_labels_oversampled, test, test_labels)\n",
        "    elif sampling == \"Under\":\n",
        "        if arguments:\n",
        "            ratio = arguments\n",
        "            rus = RandomUnderSampler(sampling_strategy=ratio)\n",
        "            train_undersampled, train_labels_undersampled = rus.fit_sample(train,train_labels)\n",
        "        else:\n",
        "            rus = RandomUnderSampler()\n",
        "            train_undersampled, train_labels_undersampled = rus.fit_sample(train,train_labels)\n",
        "        return (train_undersampled, train_labels_undersampled, test, test_labels)\n",
        "    elif sampling==\"OverUnder\":\n",
        "        if arguments:    \n",
        "            ratio = arguments\n",
        "            ros = RandomOverSampler(sampling_strategy=ratio)\n",
        "            train_oversampled, train_labels_oversampled = ros.fit_sample(train,train_labels)\n",
        "            rus = RandomUnderSampler()\n",
        "            train_undersampled, train_labels_undersampled = rus.fit_sample(train_oversampled,train_labels_oversampled)\n",
        "        else:\n",
        "            ros = RandomOverSampler()\n",
        "            train_oversampled, train_labels_oversampled = ros.fit_sample(train,train_labels)\n",
        "            rus = RandomUnderSampler()\n",
        "            train_undersampled, train_labels_undersampled = rus.fit_sample(train_oversampled,train_labels_oversampled)\n",
        "        return (train_undersampled, train_labels_undersampled, test, test_labels)\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    This is a function that applies a transformation (standardization) on a dataset, \n",
        "    based on the type of the standardizer. Takes 3 arguments, one is mandatory and \n",
        "    is the dataset, which is a tuple of data. It needs to be in the form:\n",
        "    (train_data, train_labels, test_data, test_labels). The other two can be\n",
        "    None, and when they are, no transformation happens. The selector argument\n",
        "    is a string and can be one of two things: either \"zscore\" or \n",
        "    \"minmax\". Argument arguments is always None. Returns the transformed dataset.\n",
        "\"\"\"\n",
        "def Apply_standardizer(data, standardizer = None,  arguments = None):\n",
        "    (train, train_labels, test, test_labels) = data\n",
        "    if standardizer==\"zscore\":\n",
        "        std_train = st.zscore(train)\n",
        "    elif standardizer==\"minmax\":\n",
        "        std_train = (train - np.min(train) )/ (np.max(train) - np.min(train))\n",
        "    else:\n",
        "        std_train = train\n",
        "    return (std_train, train_labels, test, test_labels)\n",
        "\n",
        "\"\"\"\n",
        "    This is a function that creates a classifier object. It does not train, \n",
        "    it takes the name of the classifier, along with the arguments we want \n",
        "    to pass to the instance creator for the classifier and returns the \n",
        "    classifier object.\n",
        "\"\"\"\n",
        "def Create_classifier(classifier,  arguments = None):\n",
        "    if classifier==\"kNN\":\n",
        "        if arguments and arguments!=-1:\n",
        "            clf = neighbors.KNeighborsClassifier(n_jobs = -1, n_neighbors = arguments)\n",
        "        else:\n",
        "            clf = neighbors.KNeighborsClassifier(n_jobs = -1)\n",
        "    else:\n",
        "        if arguments:\n",
        "            strat = arguments\n",
        "            clf = DummyClassifier(strategy=strat)\n",
        "        else:\n",
        "            clf = neighbors.KNeighborsClassifier()\n",
        "    return clf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RktfiSkMmjfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    This is an implementation for the function imblearn.pipeline.Pipeline().\n",
        "    The way this function works is, it takes as input two arguments. The first\n",
        "    is a list. This list contains the steps that need to be executed in the \n",
        "    pipeline, IN ORDER. Always the last step is the classifier. Each step is\n",
        "    a tuple, which contains the name of the step, and the arguments needed to \n",
        "    execute the step, like so: (\"name\", arguments). The second argument of the \n",
        "    function is a tuple of data. It needs to be in the form:\n",
        "    (train_data, train_labels, test_data, test_labels). The function outputs a\n",
        "    tuple, which contains the processed data, ready for fitting the classier, \n",
        "    and the classifier object, as specified by the arguments, like so:\n",
        "    returns: (processed_data, classifier_object)\n",
        "\"\"\"\n",
        "def Pipeline(steps, data):\n",
        "    steps_dict = {\"selector\": Apply_selector,\n",
        "                  \"sampling\": Apply_sampling,\n",
        "                  \"standardizer\": Apply_standardizer,\n",
        "                  \"kNN\": Create_classifier,\n",
        "                  \"dummy\": Create_classifier}\n",
        "    for step in steps:\n",
        "        if step[0]!=\"kNN\" and step[0]!=\"dummy\":\n",
        "            data = steps_dict[step[0]](data,step[1])\n",
        "        else:\n",
        "            return ( data, Create_classifier(step[0], arguments = step[1]) )\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    This is an implementation for the function gridsearchcv. It takes 3\n",
        "    arguments, a tuple (model_name, model_parameters), the data to be fitted\n",
        "    and trained, and the specific parameters. The data parameter needs to be \n",
        "    in the form: (train_data, train_labels, test_data, test_labels). Lastly, \n",
        "    the Steps argument is a list, that has the steps for the data preprocessing,\n",
        "    as described in the Pipeline Function. For this exercise, we are dealing \n",
        "    only with dummy classifiers and kNN. The model_parameters if not None, is \n",
        "    a list of parameters (strings for dummy, ints for kNN).\n",
        "    Returns (classifier_object, best_parameter, accuracy_list)\n",
        "\"\"\"\n",
        "def model_tuning(model, data, preprocessing_steps = None):\n",
        "    if model[0]==\"dummy\":\n",
        "        if model[1]!=None:\n",
        "            accuracy_list = []\n",
        "            best_parameter = model[1][0]\n",
        "            for parameter in model[1]:\n",
        "                if preprocessing_steps:\n",
        "                    steps = preprocessing_steps + [(model[0], parameter)]\n",
        "                else:\n",
        "                    steps = [(model[0], parameter)]\n",
        "                (processed_data, clf) = Pipeline(steps, data)\n",
        "                (train, train_labels, test, test_labels) = processed_data\n",
        "                clf = clf.fit(train, train_labels)\n",
        "                preds = clf.predict(test)\n",
        "                accuracy_list.append(accuracy_score(test_labels, preds))\n",
        "                if accuracy_score(test_labels, preds) == max(accuracy_list):\n",
        "                    best_parameter = parameter\n",
        "        else:\n",
        "            accuracy_list = []\n",
        "            if preprocessing_steps:\n",
        "                steps = preprocessing_steps + [(model[0], model[1])]\n",
        "            else:\n",
        "                steps = [(model[0], model[1])]\n",
        "            (processed_data, clf) = Pipeline(steps, data)\n",
        "            (train, train_labels, test, test_labels) = processed_data\n",
        "            clf = clf.fit(train, train_labels)\n",
        "            preds = clf.predict(test)\n",
        "            accuracy_list.append(accuracy_score(test_labels, preds))\n",
        "            best_parameter = None\n",
        "    elif model[0] == \"kNN\":\n",
        "        if model[1]== -1:\n",
        "            accuracy_list = []\n",
        "            if preprocessing_steps:\n",
        "                steps = preprocessing_steps + [(model[0], model[1])]\n",
        "            else:\n",
        "                steps = [(model[0], model[1])]\n",
        "            (processed_data, clf) = Pipeline(steps, data)\n",
        "            (train, train_labels, test, test_labels) = processed_data\n",
        "            clf = clf.fit(train, train_labels)\n",
        "            preds = clf.predict(test)\n",
        "            accuracy_list.append(accuracy_score(test_labels, preds))\n",
        "            best_parameter = None\n",
        "        else:\n",
        "            accuracy_list = []\n",
        "            best_parameter = model[1][0]\n",
        "            for parameter in model[1]:\n",
        "                if preprocessing_steps:\n",
        "                    steps = preprocessing_steps + [(model[0], parameter)]\n",
        "                else:\n",
        "                    steps = [(model[0], parameter)]\n",
        "                (processed_data, clf) = Pipeline(steps, data)\n",
        "                (train, train_labels, test, test_labels) = processed_data\n",
        "                clf = clf.fit(train, train_labels)\n",
        "                preds = clf.predict(test)\n",
        "                accuracy_list.append(accuracy_score(test_labels, preds))\n",
        "                if accuracy_score(test_labels, preds) == max(accuracy_list):\n",
        "                    best_parameter = parameter\n",
        "    return (clf, best_parameter, accuracy_list )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ2oqrmDedlH",
        "colab_type": "code",
        "outputId": "eafb41c9-f011-422b-d9e9-805631455af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "df = pd.read_csv(\"all.csv\")\n",
        "df = df.drop(df.columns[[62, 63, 64, 65, 66, 67]], axis=1)\n",
        "train, test, train_labels, test_labels = train_test_split(df, labels, test_size=0.2)\n",
        "print(len(train), len(test))\n",
        "data = (train, train_labels, test,  test_labels)\n",
        "print(\"1:\")\n",
        "clf, best_parameter, acc_list = model_tuning( (\"kNN\", -1),  data,    preprocessing_steps= [(\"selector\", \"PCA\"),(\"sampling\",\"Under\",0.5), (\"standardizer\", \"zscore\")]   )    \n",
        "print(best_parameter, max(acc_list))\n",
        "print(\"2:\")\n",
        "clf, best_parameter, acc_list = model_tuning( (\"dummy\", None),  data,    preprocessing_steps= [(\"selector\", \"PCA\"),(\"sampling\",\"Under\",0.5), (\"standardizer\", \"zscore\")]   )    \n",
        "print(best_parameter, max(acc_list))\n",
        "\n",
        "print(\"3:\")\n",
        "acc_list = []\n",
        "data = (train, train_labels, test,  test_labels)\n",
        "model = (\"kNN\", [1,2,3,4,5,6,7,8,9,10,20,30,40,50,100])\n",
        "clf, best_parameter, acc_list = model_tuning(model, data)\n",
        "print(best_parameter, max(acc_list))\n"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "229 58\n",
            "1:\n",
            "None 0.603448275862069\n",
            "2:\n",
            "None 0.46551724137931033\n",
            "3:\n",
            "20 0.8793103448275862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqq8OnaOlBuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9f913c1b-8556-470a-8aa2-140d8f6899a3"
      },
      "source": [
        "print(acc_list)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.8275862068965517, 0.7413793103448276, 0.8448275862068966, 0.8275862068965517, 0.8620689655172413, 0.8448275862068966, 0.8793103448275862, 0.8620689655172413, 0.8448275862068966, 0.8620689655172413, 0.8793103448275862, 0.8448275862068966, 0.8448275862068966, 0.8448275862068966, 0.8448275862068966]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-Dve50_lDni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}