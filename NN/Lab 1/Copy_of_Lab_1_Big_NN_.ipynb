{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Lab 1 Big - NN .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgeaidinis/NTUA/blob/master/NN/Lab%201/Copy_of_Lab_1_Big_NN_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNutqQMbsGh5",
        "colab_type": "text"
      },
      "source": [
        "Αϊδίνης Γιώργος 03116031\n",
        "\n",
        "Κολιός Παναγιώτης 03116100\n",
        "\n",
        "---\n",
        "\n",
        "Ομάδα M.B.8\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Lab 1: Επιβλεπόμενη Μάθηση - Ταξινόμηση - Μεγάλο Dataset (B10 - Epileptic Seizure Recognition)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbhZAASZwUlT",
        "colab_type": "code",
        "outputId": "13e2b954-66f8-45e3-a082-c98174bcc3d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install --upgrade pip #upgrade pip package installer\n",
        "!pip install scikit-learn --upgrade #upgrade scikit-learn package\n",
        "!pip install numpy --upgrade #upgrade numpy package\n",
        "!pip install pandas --upgrade #--upgrade #upgrade pandas package"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n",
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.3.3)\n",
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTTsqj4VMGvH",
        "colab_type": "text"
      },
      "source": [
        "# Β. Εισαγωγή του Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZREGY83HPNia",
        "colab_type": "text"
      },
      "source": [
        "Multiclass Classification: Το συγκεκριμένο dataset χρησιμοποιείται και για multiclass και για binary (1 vs 2-5) classification. Λόγω του παραπάνω, και καθώς στο small dataset κάναμε binary classification επιλέξαμε να κάνουμε multiclass σε αυτό.\n",
        "\n",
        "1. Έγινε καταγραφή της δραστηριότητας του εγκεφάλου 500 ατόμων για 23.6 δευτερόλεπτα/καταγραφή. Στόχος είναι η λήψη σωστής απόφασης περί του αν το άτομο βρίσκεται σε επιληπτική κρίση ή όχι. Έγινε δειγματοληψία κάθε καταγραφής, η οποία οδήγησε σε 4097 δείγματα. Τα 4097 δείγματα χωρίστηκαν σε 23 κομμάτια, με το καθένα να περιέχει 178 σημεία, που αντιστοιχούν σε 1 δευτερόλεπτο καταγραφής. Έτσι δημιουργήθηκαν 23*500 = 11500 γραμμές-δείγματα, καθένα από τα οποία αποτελείται από 178 σημεία που αντιστοιχούν σε 1 δευτερόλεπτο και αποτελόυν τη διάσταση των δεδομένων εισόδου. Η τελευταία στήλη περιέχει τις ετικέτες, οι οποίες παίρνουν τιμές 1-5, με την περίπτωση 1 να αφορά τις περιπτώσεις όπου το άτομο είχε επιληπτική κρίση και τις 2-5 τις περιπτώσεις όπου δεν είχε. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivFpi5Y6qs5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def download(url, file):\n",
        "    if not os.path.isfile(file):\n",
        "        print(\"Download file... \" + file + \" ...\")\n",
        "        urlretrieve(url,file)\n",
        "        print(\"File downloaded\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO7sxOv9uQ-O",
        "colab_type": "code",
        "outputId": "4d6ae7d3-9a25-4d9f-b647-0df59fc6fd44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "download(\"http://archive.ics.uci.edu/ml/machine-learning-databases/00388/data.csv\",\"ESR.csv\")\n",
        "print(\"All the files are downloaded\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download file... ESR.csv ...\n",
            "File downloaded\n",
            "All the files are downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atJR4ULlNnLD",
        "colab_type": "code",
        "outputId": "564c9ea8-1fb8-4ba0-be06-0bd61ac38c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ESR.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUP2fM13N0nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"ESR.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZZ3Jz97vZso",
        "colab_type": "text"
      },
      "source": [
        "2. Όπως είπαμε παραπάνω και όπως φαίνεται παρακάτω, υπάρχουν 11500 δείγματα, το καθένα με 178 χαρακτηριστικά, τα οποία αφορούν τις μεταβολές της ηλεκτρικής τάσης των σημάτων στους νευρώνες του ανθρωπίνου εγκεφάλου. Συνεπώς είναι διατεταγμένα. Επίσης είναι ακέραιοι αριθμοί.\n",
        "3. Υπάρχουν επικεφαλίδες στην πρώτη γραμμή και στοιχεία για το εκάστοτε δείγμα στην πρώτη στήλη, τα οποία θα πρέπει να αφαιρεθούν.\n",
        "4. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8vWCNtEOjBR",
        "colab_type": "code",
        "outputId": "d79e6524-1afa-4ecc-ef38-7dfa1b956e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11500, 180)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DPxsuXoW0QDt",
        "colab": {}
      },
      "source": [
        "df #print the dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tudu50uC0Qt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"We have \",len(df.columns), \" attributes.\")\n",
        "for i in range(0, len(df.columns)):\n",
        "    print('{:<10}{:<40}{:<10}{:<20}'.format(str(i+1), str(df.columns[i]),\"type: \", str(df.dtypes[df.columns[i]])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcm_GRAbqP4f",
        "colab_type": "text"
      },
      "source": [
        "5. Διαγράφουμε την πρώτη κολώνα, ώστε όλες οι κολώνες εκτός της τελευταίας να περιέχουν τιμές των χαρακτηριστικών, με την τελευταία να περιέχει τις ετικέτες."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSj6XEFTplQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(df.columns[[0]], axis=1)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRFK2k4GqnHQ",
        "colab_type": "text"
      },
      "source": [
        "6. Δεν υπάρχουν απουσιάζουσες τιμές.\n",
        "7. Χρησιμοποιούμε την bincount για να μετρήσουμε τη συχνότητα των κατηγοριών. Παρατηρούμε οτι έχουμε ενα εξαιρετικά ισορροπημένο dataset. Και οι 5 κατηγορίες είναι ισοπληθείς. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1haboerrVVO",
        "colab_type": "code",
        "outputId": "c59a21b2-3371-4d87-808f-b20fe2cc54ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels = df.iloc[:, 178]\n",
        "df = df.iloc[:, 0:178]   #remove lables from set\n",
        "print(\"frequencies:\", np.bincount(labels)[1:])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequencies: [2300 2300 2300 2300 2300]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rSqNc93uKNc",
        "colab_type": "text"
      },
      "source": [
        "8. Διαχωρίζουμε σε train και test set. Οι τιμές των χαρακτηριστικών αφορούν τα εγκεφαλικά σήματα (τάσεις), άρα είναι διατεταγμένα."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSBGq46YuZ0K",
        "colab_type": "code",
        "outputId": "f101502b-de61-4018-db9c-4c055f4ac10c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test, train_labels, test_labels = train_test_split(df, labels, test_size=0.3)\n",
        "print(len(train))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjCK0y1KwrOX",
        "colab_type": "text"
      },
      "source": [
        "# Γ. Baseline Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Im4uxp-MXUd",
        "colab_type": "text"
      },
      "source": [
        "##### Dummy Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxApc9Auw5eR",
        "colab_type": "text"
      },
      "source": [
        "Εκπαιδεύουμε τους classifiers με τις default τιμές για να δούμε συγκρίνουμε τα αποτέλεσματα πριν και μετά την προεργασία. <br>\n",
        "\n",
        "Αρχίζουμε με τους Dummy Classifiers. Παρατηρούμε οτι επιτυγχάνουμε σε όλους περίπου 20% επιτυχία, όπως ήταν αναμενόμενο καθώς έχουμε 5 κατηγορίες."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm5JMFaGxRSV",
        "colab_type": "code",
        "outputId": "59454b29-fcf6-48bc-ffea-8ed2f5604088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "dc_uniform = DummyClassifier(strategy=\"uniform\")\n",
        "dc_constant_1 = DummyClassifier(strategy=\"constant\", constant=1)\n",
        "dc_constant_2 = DummyClassifier(strategy=\"constant\", constant=2)\n",
        "dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
        "dc_stratified = DummyClassifier(strategy=\"stratified\")\n",
        "\n",
        "#using fit to train the classifiers\n",
        "model_uniform = dc_uniform.fit(train, train_labels)\n",
        "model_constant_1 = dc_constant_1.fit(train, train_labels)\n",
        "model_constant_2 = dc_constant_2.fit(train, train_labels)\n",
        "model_most_frequent = dc_most_frequent.fit(train, train_labels)\n",
        "model_stratified = dc_stratified.fit(train, train_labels)\n",
        "\n",
        "#now we make our predictions\n",
        "preds_uniform = dc_uniform.predict(test)\n",
        "preds_constant_1 = dc_constant_1.predict(test)\n",
        "preds_constant_2 = dc_constant_2.predict(test)\n",
        "preds_most_frequent = dc_most_frequent.predict(test)\n",
        "preds_stratified = dc_stratified.predict(test)\n",
        "\n",
        "#print prediction accuracy\n",
        "accuracy = {}\n",
        "print(\"Uniform Classifier: \", accuracy_score(test_labels, preds_uniform))\n",
        "print(\"Constant Classifier (1): \", accuracy_score(test_labels, preds_constant_1))\n",
        "print(\"Constant Classifier (2): \", accuracy_score(test_labels, preds_constant_2))\n",
        "print(\"Most Frequent Classifier: \", accuracy_score(test_labels, preds_most_frequent))\n",
        "print(\"Stratified Classifier: \", accuracy_score(test_labels, preds_stratified))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uniform Classifier:  0.20492753623188406\n",
            "Constant Classifier (1):  0.20115942028985506\n",
            "Constant Classifier (2):  0.2046376811594203\n",
            "Most Frequent Classifier:  0.196231884057971\n",
            "Stratified Classifier:  0.20231884057971014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDrfn2dg6OgQ",
        "colab_type": "text"
      },
      "source": [
        "Εκτυπώνουμε τον confusion matrix. Ο $C$ είναι ο πίνακας για τον οποίο ισχύει οτι $C_{i, j}$ είναι τα δείγματα της κατηγορίας $i$ που ταξινομήθηκαν στην $j$. Όπως φαίνεται οι Uniform και Stratified προβλέπουν οποιαδήποτε κατηγορία, ενώ οι άλλοι 3 είτε επιλέγουν σταθερά μία κατηγορία είτε αυτή με τα περισσότερα δείγματα. Μάλιστα, από τη στιγμή που τα δείγματα στο αρχικό data set είναι ίσα μεταξύ τους, τα πολυπληθέστερα δείγματα στο train set θα είναι τα λιγότερο πολυπληθή στο test set. Άρα ο classifier αυτός θα έχει χειρότερη επίδοση από τους constant classifiers, όπως φαίνεται και από τον confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMuRq4wD53zy",
        "colab_type": "code",
        "outputId": "c096e38d-bd66-4374-8d20-1eceaa48b7db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#produce confusion matrices\n",
        "cnf_matrix_uniform = confusion_matrix(test_labels, preds_uniform)\n",
        "cnf_matrix_constant_1 = confusion_matrix(test_labels, preds_constant_1)\n",
        "cnf_matrix_constant_2 = confusion_matrix(test_labels, preds_constant_2)\n",
        "cnf_matrix_most_frequent = confusion_matrix(test_labels, preds_most_frequent)\n",
        "cnf_matrix_stratified = confusion_matrix(test_labels, preds_stratified)\n",
        "\n",
        "#print confusion matrices\n",
        "print(\"Uniform Classifier Confusion Matrix\\n\")\n",
        "print(cnf_matrix_uniform, \"\\n\")\n",
        "print(\"Constant Classifier (1) Confusion Matrix\\n\")\n",
        "print(cnf_matrix_constant_1, \"\\n\")\n",
        "print(\"Constant Classifier (2) Confusion Matrix\\n\")\n",
        "print(cnf_matrix_constant_2, \"\\n\")\n",
        "print(\"Most Frequent Classifier Confusion Matrix\\n\")\n",
        "print(cnf_matrix_most_frequent, \"\\n\")\n",
        "print(\"Stratified Classifier Confusion Matrix\\n\")\n",
        "print(cnf_matrix_stratified, \"\\n\")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uniform Classifier Confusion Matrix\n",
            "\n",
            "[[133 136 135 142 148]\n",
            " [169 146  96 144 151]\n",
            " [133 145 148 136 123]\n",
            " [143 131 118 155 130]\n",
            " [132 136 152 143 125]] \n",
            "\n",
            "Constant Classifier (1) Confusion Matrix\n",
            "\n",
            "[[694   0   0   0   0]\n",
            " [706   0   0   0   0]\n",
            " [685   0   0   0   0]\n",
            " [677   0   0   0   0]\n",
            " [688   0   0   0   0]] \n",
            "\n",
            "Constant Classifier (2) Confusion Matrix\n",
            "\n",
            "[[  0 694   0   0   0]\n",
            " [  0 706   0   0   0]\n",
            " [  0 685   0   0   0]\n",
            " [  0 677   0   0   0]\n",
            " [  0 688   0   0   0]] \n",
            "\n",
            "Most Frequent Classifier Confusion Matrix\n",
            "\n",
            "[[  0   0   0 694   0]\n",
            " [  0   0   0 706   0]\n",
            " [  0   0   0 685   0]\n",
            " [  0   0   0 677   0]\n",
            " [  0   0   0 688   0]] \n",
            "\n",
            "Stratified Classifier Confusion Matrix\n",
            "\n",
            "[[137 167 122 131 137]\n",
            " [140 135 146 147 138]\n",
            " [127 148 135 142 133]\n",
            " [139 142 128 145 123]\n",
            " [123 133 134 152 146]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-GmyVk19rYV",
        "colab_type": "text"
      },
      "source": [
        "Εκτύπωση f1-micro average και f1-macro average.\n",
        "\n",
        "Η ακρίβεια αφορά την ικανότητα του εκτιμητή να εκτιμά ως δείγματα του test set που ανήκουν στη θετική κλάση μόνο αυτά που όντως ανήκουν.<br>\n",
        "Precision: $$P = \\frac{T_p}{T_p+F_p}$$\n",
        "\n",
        "Η ανάκληση αφορά την ικανότητα του εκτιμητή να εντοπίζει όλα τα δείγματα που ανήκουν στη θετική κλάση.<br>\n",
        "Recall: $$R = \\frac{T_p}{T_p + F_n}$$\n",
        "\n",
        "F1 score είναι ο αρμονικός μέσος όρος αυτών των δύο.<br>\n",
        "F1: $$F1 = 2\\frac{P \\times R}{P+R}$$\n",
        "\n",
        "Macro average: υπολογίζει f1 ξεχωριστά για κάθε κλάση και παίρνει τον μέσο όρο. Άρα κάθε κλάση αντιμετωπίζεται ισότιμα.\n",
        "\n",
        "Micro average: ενσωματώνει την πληροφορία για τον αριθμό των δειγμάτων που ανήκουν σε κάθε κλάση, χρησιμοποιώντας τις πραγματικές ποσότητες $T_p$, $F_p$, $F_n$ στον συνολικό υπολογισμό. Άρα είναι προτιμότερη όταν μία κλάση περιέχει αρκετά περισσότερα δείγματα."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXpKTfVv3xY6",
        "colab_type": "code",
        "outputId": "df53ccdb-bf91-41ee-f733-338057e4cf59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#f1-micro\n",
        "print('\\033[1m' + \"f1-micro\" + '\\033[0m')\n",
        "print(\"Uniform Classifier: \", precision_recall_fscore_support(test_labels, preds_uniform, average='micro'))\n",
        "print(\"Constant Classifier (1): \", precision_recall_fscore_support(test_labels, preds_constant_1, average='micro'))\n",
        "print(\"Constant Classifier (2): \", precision_recall_fscore_support(test_labels, preds_constant_2, average='micro'))\n",
        "print(\"Most Frequent Classifier: \", precision_recall_fscore_support(test_labels, preds_most_frequent, average='micro'))\n",
        "print(\"Stratified Classifier: \", precision_recall_fscore_support(test_labels, preds_stratified, average='micro'), \"\\n\")\n",
        "\n",
        "\n",
        "#f1-macro\n",
        "print('\\033[1m' + \"f1-macro\" + '\\033[0m')\n",
        "print(\"Uniform Classifier: \", precision_recall_fscore_support(test_labels, preds_uniform, average='macro'))\n",
        "print(\"Constant Classifier (1): \", precision_recall_fscore_support(test_labels, preds_constant_1, average='macro'))\n",
        "print(\"Constant Classifier (2): \", precision_recall_fscore_support(test_labels, preds_constant_2, average='macro'))\n",
        "print(\"Most Frequent Classifier: \", precision_recall_fscore_support(test_labels, preds_most_frequent, average='macro'))\n",
        "print(\"Stratified Classifier: \", precision_recall_fscore_support(test_labels, preds_stratified, average='macro'))\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mf1-micro\u001b[0m\n",
            "Uniform Classifier:  (0.20492753623188406, 0.20492753623188406, 0.20492753623188406, None)\n",
            "Constant Classifier (1):  (0.20115942028985506, 0.20115942028985506, 0.20115942028985506, None)\n",
            "Constant Classifier (2):  (0.2046376811594203, 0.2046376811594203, 0.2046376811594203, None)\n",
            "Most Frequent Classifier:  (0.196231884057971, 0.196231884057971, 0.196231884057971, None)\n",
            "Stratified Classifier:  (0.20231884057971014, 0.20231884057971014, 0.20231884057971014, None) \n",
            "\n",
            "\u001b[1mf1-macro\u001b[0m\n",
            "Uniform Classifier:  (0.20513152276246868, 0.20502744287274183, 0.20499468736487234, None)\n",
            "Constant Classifier (1):  (0.04023188405797101, 0.2, 0.06698841698841698, None)\n",
            "Constant Classifier (2):  (0.04092753623188406, 0.2, 0.06794995187680461, None)\n",
            "Most Frequent Classifier:  (0.0392463768115942, 0.2, 0.06561667070511266, None)\n",
            "Stratified Classifier:  (0.2025617905893406, 0.20241885429206366, 0.20242073614464723, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9DNzplOMs95",
        "colab_type": "text"
      },
      "source": [
        "##### Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1oeCSNONCxB",
        "colab_type": "text"
      },
      "source": [
        "Ο Gaussian Nauve Bayes υποθέτει οτι τα χαρακτηριστικά είναι ανεξάρτητα μεταξύ τους. Έτσι συνδέει κάθε χαρακτηριστικό $x_i$ με κάθε κλάση $y$ με την πιθανότητα $P(x_i \\mid y)$, η οποία υποθέτει πως ακολουθεί γκαουσιανή κατανομή. Χρησιμοποιεί τα δεδομένα προκειμένου για κάθε κλάση και χαρακτηριστικό, το οποίο παίρνει συνεχείς τιμές, να βρει τη μέση τιμή $\\mu_y$ και τη διακύμανση $\\sigma^2_y$ κάθε χαρακτηριστικού για τη κλάση $y$. Στην φάση του testing λαμβάνει υπόψην του τα γινόμενα των παραπάνω πιθανοτήτων των χαρακτηριστικών για κάθε κλάση, καθώς και την πιθανότητα της ίδιας της κλάσης και αναθέτει στο δείγμα την κλάση που μεγιστοποιεί το τελικό γινόμενο.\n",
        "\n",
        "Παρατηρούμε πως η ενσωμάτωση πληροφορίας, ακόμα και όταν έχουμε κάνει τις παραπάνω υποθέσεις υπερδιπλασιάζει την ακρίβεια των προβλέψεών μας.\n",
        "\n",
        "Επίσης, όπως φαίνεται από το confusion matrix υπάρχει αναθέτει πολλά δείγματα στην πέμπτη κλάση. Ωστόσο επιτυγχάνει σε μεγάλο βαθμό να εντοπίσει τις επιληπτικές κρίσεις (πρώτη κλάση)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej7lvLW_O8sm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "031205ff-fe72-4c2f-db7e-23e34362b5a0"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "\n",
        "#finding mean values and variations\n",
        "model_GNB = gnb.fit(train, train_labels)\n",
        "\n",
        "#making predictions\n",
        "preds = {}\n",
        "preds[\"Gaussian Naive Bayes\"] = gnb.predict(test)\n",
        "\n",
        "#calculate and print prediction accuracy\n",
        "accuracy = {}\n",
        "accuracy[\"Gaussian Naive Bayes\"] = accuracy_score(test_labels, preds[\"Gaussian Naive Bayes\"])\n",
        "print(\"Gaussian Naive Bayes: \", accuracy[\"Gaussian Naive Bayes\"], \"\\n\")\n",
        "\n",
        "#produce and print confusion matrix\n",
        "cnf_matrix_GNB = confusion_matrix(test_labels, preds[\"Gaussian Naive Bayes\"])\n",
        "print('\\033[1m' + \"Gaussian Naive Bayes - Confusion Matrix\" + '\\033[0m')\n",
        "print(cnf_matrix_GNB, \"\\n\")\n",
        "\n",
        "#f1-micro/macro\n",
        "print('\\033[1m' + \"f1-micro\" + '\\033[0m')\n",
        "print(\"Gaussian Naive Bayes: \", precision_recall_fscore_support(test_labels, preds[\"Gaussian Naive Bayes\"], average='micro'))\n",
        "print('\\033[1m' + \"f1-macro\" + '\\033[0m')\n",
        "print(\"Gaussian Naive Bayes: \", precision_recall_fscore_support(test_labels, preds[\"Gaussian Naive Bayes\"], average='macro'))\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gaussian Naive Bayes:  0.4350724637681159 \n",
            "\n",
            "\u001b[1mGaussian Naive Bayes - Confusion Matrix\u001b[0m\n",
            "[[571 122   0   1   0]\n",
            " [ 36 120 100  80 370]\n",
            " [  2  89 116 115 363]\n",
            " [  0 172 141 186 178]\n",
            " [  0  28  94  58 508]] \n",
            "\n",
            "\u001b[1mf1-micro\u001b[0m\n",
            "Gaussian Naive Bayes:  (0.4350724637681159, 0.4350724637681159, 0.435072463768116, None)\n",
            "\u001b[1mf1-macro\u001b[0m\n",
            "Gaussian Naive Bayes:  (0.440304679906499, 0.43503898147138953, 0.41798384443582093, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTnReOvNU069",
        "colab_type": "text"
      },
      "source": [
        "##### kNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NTWOpQ3U8mN",
        "colab_type": "text"
      },
      "source": [
        "Ο kNN υπολογίζει, για κάθε δείγμα του test set, τους k κοντινότερους γείτονές του, οι οποίοι είναι δείγματα του train set, στον n-διάστατο χώρο διαστάσεων των χαρακτηριστικών εισόδου. Αποφασίζει την κλάση του νέου δείγματα παίρνοντας είτε την πλειοψηφία των γειτόνων είτε λαμβάνοντας υπόψην και τις αποστάσεις του από αυτούς. Ως συνάρτηση απόστασης χρησιμοποιείται κυρίως η ευκλείδια. <br>\n",
        "Εξαιρετικά σημαντική για την απόδοσή του είναι η υπερπαράμετρος k. \n",
        "\n",
        "Το γεγονός οτι πρέπει να συγκρίνουμε την απόσταση κάθε νέου δείγματος στο train set με το νέο δείγμα καθιστά τη διαδικασία πρόβλεψης πολύ χρονοβόρα.\n",
        "Ωστόσο, η μεγάλη διαφορά από τον GNB είναι οτι δεν κάνει υποθέσεις για τις εξαρτήσεις των χαρακτηριστικών και τις κατανομές των πιθανοτήτων.\n",
        "\n",
        "Παρατηρούμε οτι επιτυγχάνει καλύτερες προβλέψεις από τον kNN, ωστόσο το ποσοστό είναι ακόμα χαμηλό."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6CGWaoHypKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65cb7e93-63cb-43fe-c441-9a082c9ced4b"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5) #setting k to 5\n",
        "\n",
        "#saves training samples and their labels\n",
        "knn.fit(train, train_labels)\n",
        "\n",
        "#making predictions\n",
        "preds[\"kNN\"] = knn.predict(test)\n",
        "\n",
        "#calculate and print prediction accuracy\n",
        "accuracy[\"kNN\"] = accuracy_score(test_labels, preds[\"kNN\"])\n",
        "print(\"kNN: \", accuracy[\"kNN\"])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kNN:  0.4692753623188406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T80Gv0FLXxkP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0319587d-e9da-435a-85c3-46b04942c6eb"
      },
      "source": [
        "#produce and print confusion matrix\n",
        "cnf_matrix_GNB = confusion_matrix(test_labels, preds[\"kNN\"])\n",
        "print('\\033[1m' + \"kNN - Confusion Matrix\" + '\\033[0m')\n",
        "print(cnf_matrix_GNB, \"\\n\")\n",
        "\n",
        "#f1-micro/macro\n",
        "print('\\033[1m' + \"f1-micro\" + '\\033[0m')\n",
        "print(\"kNN: \", precision_recall_fscore_support(test_labels, preds[\"kNN\"], average='micro'))\n",
        "print('\\033[1m' + \"f1-macro\" + '\\033[0m')\n",
        "print(\"kNN: \", precision_recall_fscore_support(test_labels, preds[\"kNN\"], average='macro'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mkNN - Confusion Matrix\u001b[0m\n",
            "[[474 102  80  32   6]\n",
            " [  3 444 249   1   9]\n",
            " [  0 231 448   0   6]\n",
            " [  0 180 191 197 109]\n",
            " [  0 285 343   4  56]] \n",
            "\n",
            "\u001b[1mf1-micro\u001b[0m\n",
            "kNN:  (0.4692753623188406, 0.4692753623188406, 0.4692753623188406, None)\n",
            "\u001b[1mf1-macro\u001b[0m\n",
            "kNN:  (0.5671756200262825, 0.4676583819869663, 0.4549905293668945, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHUP3bqgYgPZ",
        "colab_type": "text"
      },
      "source": [
        "##### Multi Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpMovT_TYxWN",
        "colab_type": "text"
      },
      "source": [
        "Παρατηρούμε οτι δεν αποδίδει καλύτερα ούτε από τους Dummy Classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EI0siWOYybR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c6735f53-a27e-4d35-dea7-d071c84730f0"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,), random_state=1)\n",
        "\n",
        "#training\n",
        "clf.fit(train, train_labels)\n",
        "\n",
        "#predicting\n",
        "preds[\"Multi Layer Perceptron\"] = clf.predict(test)\n",
        "\n",
        "#calculate and print prediction accuracy\n",
        "accuracy[\"Multi Layer Perceptron\"] = accuracy_score(test_labels, preds[\"Multi Layer Perceptron\"])\n",
        "print(\"Multi Layer Perceptron: \", accuracy[\"Multi Layer Perceptron\"])\n",
        "\n",
        "#produce and print confusion matrix\n",
        "cnf_matrix_GNB = confusion_matrix(test_labels, preds[\"Multi Layer Perceptron\"])\n",
        "print('\\033[1m' + \"Multi Layer Perceptron - Confusion Matrix\" + '\\033[0m')\n",
        "print(cnf_matrix_GNB, \"\\n\")\n",
        "\n",
        "#f1-micro/macro\n",
        "print('\\033[1m' + \"f1-micro\" + '\\033[0m')\n",
        "print(\"Multi Layer Perceptron: \", precision_recall_fscore_support(test_labels, preds[\"Multi Layer Perceptron\"], average='micro'))\n",
        "print('\\033[1m' + \"f1-macro\" + '\\033[0m')\n",
        "print(\"Multi Layer Perceptron: \", precision_recall_fscore_support(test_labels, preds[\"Multi Layer Perceptron\"], average='macro'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multi Layer Perceptron:  0.19652173913043477\n",
            "\u001b[1mMulti Layer Perceptron - Confusion Matrix\u001b[0m\n",
            "[[190 282  36 142  44]\n",
            " [213 298   7 169  19]\n",
            " [187 280  13 184  21]\n",
            " [180 305  24 152  16]\n",
            " [208 284  23 148  25]] \n",
            "\n",
            "\u001b[1mf1-micro\u001b[0m\n",
            "Multi Layer Perceptron:  (0.19652173913043477, 0.19652173913043477, 0.19652173913043475, None)\n",
            "\u001b[1mf1-macro\u001b[0m\n",
            "Multi Layer Perceptron:  (0.18346833292812365, 0.19514135716533865, 0.1609712261114407, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T02fDOdhs5p",
        "colab_type": "text"
      },
      "source": [
        "# Δ. Βελτιστοποίηση Ταξινομητών"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSSO7UFShzfL",
        "colab_type": "text"
      },
      "source": [
        "Χρησιμοποιούμε την διαδικασία pipeline για την εφαρμογή διαδοχικών μετασχηματισμών στα χαρακτηριστικά των δεδομένων. \n",
        "\n",
        "* Λόγω του ισορροπημένου dataset δεν χρειάζεται να χρησιμοποιήσουμε oversampler ή undersampler.\n",
        "\n",
        "* Διαστατικότητα: Χρησιμοποιούμε τον μετασχηματιστή VarianceThreshold, ο οποίος μειώνει τον αριθμό των χαρακτηριστικών με βάση την διακύμανση των τιμών του στα δείγματα (επιλογή χαρακτηριστικών). Όταν η διακύμανση είναι μικρή θεωρούμε οτι το χαρακτηριστικό δεν προσφέρει πολλή πληροφορία για την κατηγοριοποίηση. <br>\n",
        "Επίσης χρησιμοποιούμε τον PCA για την ανάλυση των δεδομένων σε κύριες συνιστώσες και την χρήση των συνιστωσών με την περισσότερη διακύμανση (εξαγωγή χαρακτηριστικών), δηλαδή πληροφορία. \n",
        "\n",
        "* Κανονικοποίηση: Αμβλύνουμε τις διαφορές μεταξύ των τιμών των χαρακτηριστικών. Αν ένα χαρακτηριστικό έχει πολύ μεγαλύτερες τιμές από ένα άλλο η σημασία του σε εκτιμητές όπως ο kNN, που μετρά τις αποστάσεις από τα χαρακτηριστικά, είναι μεγαλύτερη χωρίς αυτό να σημαίνει οτι παρέχει περισσότερη πληροφορία για την κατηγοριοποίηση. Χρησιμοποιούμε δύο μετασχηματιστές κανονικοποίησης, τον scaler και τον min_max_scaler. \n",
        "\n",
        "Η σειρά που ακολουθείται είναι η εξής:\n",
        "0. minmax αν VarianceThreshold για να μην επηρεαστεί η επιλογή από τις τιμές των χαρακτηριστικών\n",
        "1. Κανονικοποίηση (minmax ή z-score)\n",
        "2. PCA\n",
        "3. Εκτιμητής\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkD2OagKoBRj",
        "colab_type": "text"
      },
      "source": [
        "Χρήση grid search για την βελτιστοποίηση των υπερπαραμέτρων. Φτιάχνουμε σύνολο πιθανών συνδυασμών τιμών των παραμέτρων για να βρόυμε τον βέλτιστο. Υπολογίζεται ο μέσος όρος σε όλα τα folds (5 εδώ) του cross-validation με βάση της f1 μετρικές. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbDPNvE6iWzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}