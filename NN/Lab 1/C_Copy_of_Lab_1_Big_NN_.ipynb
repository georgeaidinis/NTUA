{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Lab 1 Big - NN .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgeaidinis/NTUA/blob/master/NN/Lab%201/C_Copy_of_Lab_1_Big_NN_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNutqQMbsGh5",
        "colab_type": "text"
      },
      "source": [
        "Αϊδίνης Γιώργος 03116031\n",
        "\n",
        "Κολιός Παναγιώτης 03116100\n",
        "\n",
        "---\n",
        "\n",
        "Ομάδα M.B.8\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Lab 1: Επιβλεπόμενη Μάθηση - Ταξινόμηση - Μεγάλο Dataset (B10 - Epileptic Seizure Recognition)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbhZAASZwUlT",
        "colab_type": "code",
        "outputId": "13e2b954-66f8-45e3-a082-c98174bcc3d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install --upgrade pip #upgrade pip package installer\n",
        "!pip install scikit-learn --upgrade #upgrade scikit-learn package\n",
        "!pip install numpy --upgrade #upgrade numpy package\n",
        "!pip install pandas --upgrade #--upgrade #upgrade pandas package"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n",
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.3.3)\n",
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTTsqj4VMGvH",
        "colab_type": "text"
      },
      "source": [
        "# Β. Εισαγωγή του Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZREGY83HPNia",
        "colab_type": "text"
      },
      "source": [
        "Multiclass Classification: Το συγκεκριμένο dataset χρησιμοποιείται και για multiclass και για binary (1 vs 2-5) classification. Λόγω του παραπάνω, και καθώς στο small dataset κάναμε binary classification επιλέξαμε να κάνουμε multiclass σε αυτό.\n",
        "\n",
        "1. Έγινε καταγραφή της δραστηριότητας του εγκεφάλου 500 ατόμων για 23.6 δευτερόλεπτα/καταγραφή. Στόχος είναι η λήψη σωστής απόφασης περί του αν το άτομο βρίσκεται σε επιληπτική κρίση ή όχι. Έγινε δειγματοληψία κάθε καταγραφής, η οποία οδήγησε σε 4097 δείγματα. Τα 4097 δείγματα χωρίστηκαν σε 23 κομμάτια, με το καθένα να περιέχει 178 σημεία, που αντιστοιχούν σε 1 δευτερόλεπτο καταγραφής. Έτσι δημιουργήθηκαν 23*500 = 11500 γραμμές-δείγματα, καθένα από τα οποία αποτελείται από 178 σημεία που αντιστοιχούν σε 1 δευτερόλεπτο και αποτελόυν τη διάσταση των δεδομένων εισόδου. Η τελευταία στήλη περιέχει τις ετικέτες, οι οποίες παίρνουν τιμές 1-5, με την περίπτωση 1 να αφορά τις περιπτώσεις όπου το άτομο είχε επιληπτική κρίση και τις 2-5 τις περιπτώσεις όπου δεν είχε. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivFpi5Y6qs5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def download(url, file):\n",
        "    if not os.path.isfile(file):\n",
        "        print(\"Download file... \" + file + \" ...\")\n",
        "        urlretrieve(url,file)\n",
        "        print(\"File downloaded\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO7sxOv9uQ-O",
        "colab_type": "code",
        "outputId": "019d6148-a3bd-49ef-ea0c-3a54241063af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "download(\"http://archive.ics.uci.edu/ml/machine-learning-databases/00388/data.csv\",\"ESR.csv\")\n",
        "print(\"All the files are downloaded\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All the files are downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atJR4ULlNnLD",
        "colab_type": "code",
        "outputId": "f4ef97ba-77ae-4fa8-fc70-d145b291da8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ESR.csv  sample_data  tmp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUP2fM13N0nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"ESR.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZZ3Jz97vZso",
        "colab_type": "text"
      },
      "source": [
        "2. Όπως είπαμε παραπάνω και όπως φαίνεται παρακάτω, υπάρχουν 11500 δείγματα, το καθένα με 178 χαρακτηριστικά, τα οποία αφορούν τις μεταβολές της ηλεκτρικής τάσης των σημάτων στους νευρώνες του ανθρωπίνου εγκεφάλου. Συνεπώς είναι διατεταγμένα. Επίσης είναι ακέραιοι αριθμοί.\n",
        "3. Υπάρχουν επικεφαλίδες στην πρώτη γραμμή και στοιχεία για το εκάστοτε δείγμα στην πρώτη στήλη, τα οποία θα πρέπει να αφαιρεθούν.\n",
        "4. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8vWCNtEOjBR",
        "colab_type": "code",
        "outputId": "491178e5-4031-42b6-abf7-b002aca69f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11500, 180)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DPxsuXoW0QDt",
        "outputId": "e88f9ba6-b3b9-42fb-e368-326490d55313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "source": [
        "df #print the dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>X11</th>\n",
              "      <th>X12</th>\n",
              "      <th>X13</th>\n",
              "      <th>X14</th>\n",
              "      <th>X15</th>\n",
              "      <th>X16</th>\n",
              "      <th>X17</th>\n",
              "      <th>X18</th>\n",
              "      <th>X19</th>\n",
              "      <th>X20</th>\n",
              "      <th>X21</th>\n",
              "      <th>X22</th>\n",
              "      <th>X23</th>\n",
              "      <th>X24</th>\n",
              "      <th>X25</th>\n",
              "      <th>X26</th>\n",
              "      <th>X27</th>\n",
              "      <th>X28</th>\n",
              "      <th>X29</th>\n",
              "      <th>X30</th>\n",
              "      <th>X31</th>\n",
              "      <th>X32</th>\n",
              "      <th>X33</th>\n",
              "      <th>X34</th>\n",
              "      <th>X35</th>\n",
              "      <th>X36</th>\n",
              "      <th>X37</th>\n",
              "      <th>X38</th>\n",
              "      <th>X39</th>\n",
              "      <th>...</th>\n",
              "      <th>X140</th>\n",
              "      <th>X141</th>\n",
              "      <th>X142</th>\n",
              "      <th>X143</th>\n",
              "      <th>X144</th>\n",
              "      <th>X145</th>\n",
              "      <th>X146</th>\n",
              "      <th>X147</th>\n",
              "      <th>X148</th>\n",
              "      <th>X149</th>\n",
              "      <th>X150</th>\n",
              "      <th>X151</th>\n",
              "      <th>X152</th>\n",
              "      <th>X153</th>\n",
              "      <th>X154</th>\n",
              "      <th>X155</th>\n",
              "      <th>X156</th>\n",
              "      <th>X157</th>\n",
              "      <th>X158</th>\n",
              "      <th>X159</th>\n",
              "      <th>X160</th>\n",
              "      <th>X161</th>\n",
              "      <th>X162</th>\n",
              "      <th>X163</th>\n",
              "      <th>X164</th>\n",
              "      <th>X165</th>\n",
              "      <th>X166</th>\n",
              "      <th>X167</th>\n",
              "      <th>X168</th>\n",
              "      <th>X169</th>\n",
              "      <th>X170</th>\n",
              "      <th>X171</th>\n",
              "      <th>X172</th>\n",
              "      <th>X173</th>\n",
              "      <th>X174</th>\n",
              "      <th>X175</th>\n",
              "      <th>X176</th>\n",
              "      <th>X177</th>\n",
              "      <th>X178</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>X21.V1.791</td>\n",
              "      <td>135</td>\n",
              "      <td>190</td>\n",
              "      <td>229</td>\n",
              "      <td>223</td>\n",
              "      <td>192</td>\n",
              "      <td>125</td>\n",
              "      <td>55</td>\n",
              "      <td>-9</td>\n",
              "      <td>-33</td>\n",
              "      <td>-38</td>\n",
              "      <td>-10</td>\n",
              "      <td>35</td>\n",
              "      <td>64</td>\n",
              "      <td>113</td>\n",
              "      <td>152</td>\n",
              "      <td>164</td>\n",
              "      <td>127</td>\n",
              "      <td>50</td>\n",
              "      <td>-47</td>\n",
              "      <td>-121</td>\n",
              "      <td>-138</td>\n",
              "      <td>-125</td>\n",
              "      <td>-101</td>\n",
              "      <td>-50</td>\n",
              "      <td>11</td>\n",
              "      <td>39</td>\n",
              "      <td>24</td>\n",
              "      <td>48</td>\n",
              "      <td>64</td>\n",
              "      <td>46</td>\n",
              "      <td>13</td>\n",
              "      <td>-19</td>\n",
              "      <td>-61</td>\n",
              "      <td>-96</td>\n",
              "      <td>-130</td>\n",
              "      <td>-132</td>\n",
              "      <td>-116</td>\n",
              "      <td>-115</td>\n",
              "      <td>-71</td>\n",
              "      <td>...</td>\n",
              "      <td>54</td>\n",
              "      <td>90</td>\n",
              "      <td>111</td>\n",
              "      <td>107</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>18</td>\n",
              "      <td>-25</td>\n",
              "      <td>-69</td>\n",
              "      <td>-65</td>\n",
              "      <td>-44</td>\n",
              "      <td>-33</td>\n",
              "      <td>-57</td>\n",
              "      <td>-88</td>\n",
              "      <td>-114</td>\n",
              "      <td>-130</td>\n",
              "      <td>-114</td>\n",
              "      <td>-83</td>\n",
              "      <td>-53</td>\n",
              "      <td>-79</td>\n",
              "      <td>-72</td>\n",
              "      <td>-85</td>\n",
              "      <td>-109</td>\n",
              "      <td>-98</td>\n",
              "      <td>-72</td>\n",
              "      <td>-65</td>\n",
              "      <td>-63</td>\n",
              "      <td>-11</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>-17</td>\n",
              "      <td>-15</td>\n",
              "      <td>-31</td>\n",
              "      <td>-77</td>\n",
              "      <td>-103</td>\n",
              "      <td>-127</td>\n",
              "      <td>-116</td>\n",
              "      <td>-83</td>\n",
              "      <td>-51</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>X15.V1.924</td>\n",
              "      <td>386</td>\n",
              "      <td>382</td>\n",
              "      <td>356</td>\n",
              "      <td>331</td>\n",
              "      <td>320</td>\n",
              "      <td>315</td>\n",
              "      <td>307</td>\n",
              "      <td>272</td>\n",
              "      <td>244</td>\n",
              "      <td>232</td>\n",
              "      <td>237</td>\n",
              "      <td>258</td>\n",
              "      <td>212</td>\n",
              "      <td>2</td>\n",
              "      <td>-267</td>\n",
              "      <td>-605</td>\n",
              "      <td>-850</td>\n",
              "      <td>-1001</td>\n",
              "      <td>-1109</td>\n",
              "      <td>-1090</td>\n",
              "      <td>-967</td>\n",
              "      <td>-746</td>\n",
              "      <td>-464</td>\n",
              "      <td>-152</td>\n",
              "      <td>118</td>\n",
              "      <td>318</td>\n",
              "      <td>427</td>\n",
              "      <td>473</td>\n",
              "      <td>485</td>\n",
              "      <td>447</td>\n",
              "      <td>397</td>\n",
              "      <td>339</td>\n",
              "      <td>312</td>\n",
              "      <td>314</td>\n",
              "      <td>326</td>\n",
              "      <td>335</td>\n",
              "      <td>332</td>\n",
              "      <td>324</td>\n",
              "      <td>310</td>\n",
              "      <td>...</td>\n",
              "      <td>27</td>\n",
              "      <td>146</td>\n",
              "      <td>229</td>\n",
              "      <td>269</td>\n",
              "      <td>297</td>\n",
              "      <td>307</td>\n",
              "      <td>303</td>\n",
              "      <td>305</td>\n",
              "      <td>306</td>\n",
              "      <td>307</td>\n",
              "      <td>280</td>\n",
              "      <td>231</td>\n",
              "      <td>159</td>\n",
              "      <td>85</td>\n",
              "      <td>51</td>\n",
              "      <td>43</td>\n",
              "      <td>62</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>89</td>\n",
              "      <td>123</td>\n",
              "      <td>136</td>\n",
              "      <td>127</td>\n",
              "      <td>102</td>\n",
              "      <td>95</td>\n",
              "      <td>105</td>\n",
              "      <td>131</td>\n",
              "      <td>163</td>\n",
              "      <td>168</td>\n",
              "      <td>164</td>\n",
              "      <td>150</td>\n",
              "      <td>146</td>\n",
              "      <td>152</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>154</td>\n",
              "      <td>143</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>X8.V1.1</td>\n",
              "      <td>-32</td>\n",
              "      <td>-39</td>\n",
              "      <td>-47</td>\n",
              "      <td>-37</td>\n",
              "      <td>-32</td>\n",
              "      <td>-36</td>\n",
              "      <td>-57</td>\n",
              "      <td>-73</td>\n",
              "      <td>-85</td>\n",
              "      <td>-94</td>\n",
              "      <td>-99</td>\n",
              "      <td>-94</td>\n",
              "      <td>-96</td>\n",
              "      <td>-104</td>\n",
              "      <td>-103</td>\n",
              "      <td>-92</td>\n",
              "      <td>-75</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-53</td>\n",
              "      <td>-37</td>\n",
              "      <td>-14</td>\n",
              "      <td>-10</td>\n",
              "      <td>-39</td>\n",
              "      <td>-78</td>\n",
              "      <td>-102</td>\n",
              "      <td>-98</td>\n",
              "      <td>-80</td>\n",
              "      <td>-54</td>\n",
              "      <td>-40</td>\n",
              "      <td>-35</td>\n",
              "      <td>-39</td>\n",
              "      <td>-32</td>\n",
              "      <td>-13</td>\n",
              "      <td>7</td>\n",
              "      <td>34</td>\n",
              "      <td>41</td>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>-82</td>\n",
              "      <td>-107</td>\n",
              "      <td>-126</td>\n",
              "      <td>-124</td>\n",
              "      <td>-108</td>\n",
              "      <td>-84</td>\n",
              "      <td>-68</td>\n",
              "      <td>-61</td>\n",
              "      <td>-56</td>\n",
              "      <td>-63</td>\n",
              "      <td>-62</td>\n",
              "      <td>-33</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>45</td>\n",
              "      <td>37</td>\n",
              "      <td>48</td>\n",
              "      <td>62</td>\n",
              "      <td>80</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>-11</td>\n",
              "      <td>-39</td>\n",
              "      <td>-44</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-48</td>\n",
              "      <td>-42</td>\n",
              "      <td>-6</td>\n",
              "      <td>29</td>\n",
              "      <td>57</td>\n",
              "      <td>64</td>\n",
              "      <td>48</td>\n",
              "      <td>19</td>\n",
              "      <td>-12</td>\n",
              "      <td>-30</td>\n",
              "      <td>-35</td>\n",
              "      <td>-35</td>\n",
              "      <td>-36</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>X16.V1.60</td>\n",
              "      <td>-105</td>\n",
              "      <td>-101</td>\n",
              "      <td>-96</td>\n",
              "      <td>-92</td>\n",
              "      <td>-89</td>\n",
              "      <td>-95</td>\n",
              "      <td>-102</td>\n",
              "      <td>-100</td>\n",
              "      <td>-87</td>\n",
              "      <td>-79</td>\n",
              "      <td>-72</td>\n",
              "      <td>-68</td>\n",
              "      <td>-74</td>\n",
              "      <td>-80</td>\n",
              "      <td>-83</td>\n",
              "      <td>-73</td>\n",
              "      <td>-68</td>\n",
              "      <td>-61</td>\n",
              "      <td>-58</td>\n",
              "      <td>-59</td>\n",
              "      <td>-64</td>\n",
              "      <td>-79</td>\n",
              "      <td>-84</td>\n",
              "      <td>-97</td>\n",
              "      <td>-94</td>\n",
              "      <td>-84</td>\n",
              "      <td>-77</td>\n",
              "      <td>-75</td>\n",
              "      <td>-72</td>\n",
              "      <td>-68</td>\n",
              "      <td>-76</td>\n",
              "      <td>-76</td>\n",
              "      <td>-72</td>\n",
              "      <td>-67</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-67</td>\n",
              "      <td>-68</td>\n",
              "      <td>...</td>\n",
              "      <td>-69</td>\n",
              "      <td>-66</td>\n",
              "      <td>-74</td>\n",
              "      <td>-69</td>\n",
              "      <td>-61</td>\n",
              "      <td>-51</td>\n",
              "      <td>-45</td>\n",
              "      <td>-45</td>\n",
              "      <td>-49</td>\n",
              "      <td>-58</td>\n",
              "      <td>-64</td>\n",
              "      <td>-78</td>\n",
              "      <td>-80</td>\n",
              "      <td>-90</td>\n",
              "      <td>-87</td>\n",
              "      <td>-83</td>\n",
              "      <td>-78</td>\n",
              "      <td>-64</td>\n",
              "      <td>-38</td>\n",
              "      <td>-22</td>\n",
              "      <td>-29</td>\n",
              "      <td>-42</td>\n",
              "      <td>-51</td>\n",
              "      <td>-68</td>\n",
              "      <td>-71</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-74</td>\n",
              "      <td>-74</td>\n",
              "      <td>-80</td>\n",
              "      <td>-82</td>\n",
              "      <td>-81</td>\n",
              "      <td>-80</td>\n",
              "      <td>-77</td>\n",
              "      <td>-85</td>\n",
              "      <td>-77</td>\n",
              "      <td>-72</td>\n",
              "      <td>-69</td>\n",
              "      <td>-65</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>X20.V1.54</td>\n",
              "      <td>-9</td>\n",
              "      <td>-65</td>\n",
              "      <td>-98</td>\n",
              "      <td>-102</td>\n",
              "      <td>-78</td>\n",
              "      <td>-48</td>\n",
              "      <td>-16</td>\n",
              "      <td>0</td>\n",
              "      <td>-21</td>\n",
              "      <td>-59</td>\n",
              "      <td>-90</td>\n",
              "      <td>-103</td>\n",
              "      <td>-84</td>\n",
              "      <td>-43</td>\n",
              "      <td>-9</td>\n",
              "      <td>3</td>\n",
              "      <td>-21</td>\n",
              "      <td>-60</td>\n",
              "      <td>-96</td>\n",
              "      <td>-103</td>\n",
              "      <td>-75</td>\n",
              "      <td>-29</td>\n",
              "      <td>14</td>\n",
              "      <td>55</td>\n",
              "      <td>78</td>\n",
              "      <td>73</td>\n",
              "      <td>28</td>\n",
              "      <td>-13</td>\n",
              "      <td>-43</td>\n",
              "      <td>-68</td>\n",
              "      <td>-78</td>\n",
              "      <td>-75</td>\n",
              "      <td>-55</td>\n",
              "      <td>-41</td>\n",
              "      <td>-19</td>\n",
              "      <td>-20</td>\n",
              "      <td>-29</td>\n",
              "      <td>-36</td>\n",
              "      <td>-20</td>\n",
              "      <td>...</td>\n",
              "      <td>38</td>\n",
              "      <td>26</td>\n",
              "      <td>10</td>\n",
              "      <td>-4</td>\n",
              "      <td>-13</td>\n",
              "      <td>-8</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>29</td>\n",
              "      <td>57</td>\n",
              "      <td>63</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "      <td>-13</td>\n",
              "      <td>-23</td>\n",
              "      <td>-9</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>-12</td>\n",
              "      <td>-32</td>\n",
              "      <td>-41</td>\n",
              "      <td>-65</td>\n",
              "      <td>-83</td>\n",
              "      <td>-89</td>\n",
              "      <td>-73</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11495</th>\n",
              "      <td>X22.V1.114</td>\n",
              "      <td>-22</td>\n",
              "      <td>-22</td>\n",
              "      <td>-23</td>\n",
              "      <td>-26</td>\n",
              "      <td>-36</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-49</td>\n",
              "      <td>-57</td>\n",
              "      <td>-64</td>\n",
              "      <td>-73</td>\n",
              "      <td>-79</td>\n",
              "      <td>-76</td>\n",
              "      <td>-70</td>\n",
              "      <td>-63</td>\n",
              "      <td>-57</td>\n",
              "      <td>-57</td>\n",
              "      <td>-50</td>\n",
              "      <td>-45</td>\n",
              "      <td>-34</td>\n",
              "      <td>-33</td>\n",
              "      <td>-32</td>\n",
              "      <td>-30</td>\n",
              "      <td>-24</td>\n",
              "      <td>-24</td>\n",
              "      <td>-18</td>\n",
              "      <td>-9</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-3</td>\n",
              "      <td>-5</td>\n",
              "      <td>-13</td>\n",
              "      <td>-23</td>\n",
              "      <td>-39</td>\n",
              "      <td>-53</td>\n",
              "      <td>-59</td>\n",
              "      <td>...</td>\n",
              "      <td>45</td>\n",
              "      <td>55</td>\n",
              "      <td>60</td>\n",
              "      <td>69</td>\n",
              "      <td>68</td>\n",
              "      <td>58</td>\n",
              "      <td>54</td>\n",
              "      <td>44</td>\n",
              "      <td>40</td>\n",
              "      <td>38</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>32</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>25</td>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>-18</td>\n",
              "      <td>-37</td>\n",
              "      <td>-47</td>\n",
              "      <td>-48</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11496</th>\n",
              "      <td>X19.V1.354</td>\n",
              "      <td>-47</td>\n",
              "      <td>-11</td>\n",
              "      <td>28</td>\n",
              "      <td>77</td>\n",
              "      <td>141</td>\n",
              "      <td>211</td>\n",
              "      <td>246</td>\n",
              "      <td>240</td>\n",
              "      <td>193</td>\n",
              "      <td>136</td>\n",
              "      <td>78</td>\n",
              "      <td>8</td>\n",
              "      <td>-66</td>\n",
              "      <td>-132</td>\n",
              "      <td>-180</td>\n",
              "      <td>-210</td>\n",
              "      <td>-227</td>\n",
              "      <td>-225</td>\n",
              "      <td>-212</td>\n",
              "      <td>-192</td>\n",
              "      <td>-168</td>\n",
              "      <td>-144</td>\n",
              "      <td>-117</td>\n",
              "      <td>-88</td>\n",
              "      <td>-54</td>\n",
              "      <td>-21</td>\n",
              "      <td>6</td>\n",
              "      <td>29</td>\n",
              "      <td>46</td>\n",
              "      <td>60</td>\n",
              "      <td>76</td>\n",
              "      <td>92</td>\n",
              "      <td>110</td>\n",
              "      <td>128</td>\n",
              "      <td>152</td>\n",
              "      <td>171</td>\n",
              "      <td>150</td>\n",
              "      <td>91</td>\n",
              "      <td>21</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>38</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>75</td>\n",
              "      <td>165</td>\n",
              "      <td>260</td>\n",
              "      <td>343</td>\n",
              "      <td>406</td>\n",
              "      <td>456</td>\n",
              "      <td>471</td>\n",
              "      <td>461</td>\n",
              "      <td>412</td>\n",
              "      <td>319</td>\n",
              "      <td>175</td>\n",
              "      <td>-5</td>\n",
              "      <td>-171</td>\n",
              "      <td>-293</td>\n",
              "      <td>-357</td>\n",
              "      <td>-378</td>\n",
              "      <td>-370</td>\n",
              "      <td>-346</td>\n",
              "      <td>-316</td>\n",
              "      <td>-278</td>\n",
              "      <td>-241</td>\n",
              "      <td>-201</td>\n",
              "      <td>-162</td>\n",
              "      <td>-126</td>\n",
              "      <td>-94</td>\n",
              "      <td>-65</td>\n",
              "      <td>-33</td>\n",
              "      <td>-7</td>\n",
              "      <td>14</td>\n",
              "      <td>27</td>\n",
              "      <td>48</td>\n",
              "      <td>77</td>\n",
              "      <td>117</td>\n",
              "      <td>170</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11497</th>\n",
              "      <td>X8.V1.28</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>-13</td>\n",
              "      <td>-16</td>\n",
              "      <td>10</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>-9</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>-1</td>\n",
              "      <td>-10</td>\n",
              "      <td>14</td>\n",
              "      <td>44</td>\n",
              "      <td>77</td>\n",
              "      <td>61</td>\n",
              "      <td>42</td>\n",
              "      <td>32</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "      <td>26</td>\n",
              "      <td>35</td>\n",
              "      <td>81</td>\n",
              "      <td>66</td>\n",
              "      <td>50</td>\n",
              "      <td>57</td>\n",
              "      <td>91</td>\n",
              "      <td>121</td>\n",
              "      <td>111</td>\n",
              "      <td>73</td>\n",
              "      <td>38</td>\n",
              "      <td>23</td>\n",
              "      <td>35</td>\n",
              "      <td>21</td>\n",
              "      <td>11</td>\n",
              "      <td>-12</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>61</td>\n",
              "      <td>...</td>\n",
              "      <td>-90</td>\n",
              "      <td>-62</td>\n",
              "      <td>-38</td>\n",
              "      <td>-40</td>\n",
              "      <td>-21</td>\n",
              "      <td>-23</td>\n",
              "      <td>-11</td>\n",
              "      <td>-4</td>\n",
              "      <td>-9</td>\n",
              "      <td>-22</td>\n",
              "      <td>-42</td>\n",
              "      <td>-49</td>\n",
              "      <td>-48</td>\n",
              "      <td>-40</td>\n",
              "      <td>-40</td>\n",
              "      <td>-46</td>\n",
              "      <td>-43</td>\n",
              "      <td>-67</td>\n",
              "      <td>-67</td>\n",
              "      <td>-50</td>\n",
              "      <td>-18</td>\n",
              "      <td>-14</td>\n",
              "      <td>-39</td>\n",
              "      <td>-74</td>\n",
              "      <td>-86</td>\n",
              "      <td>-75</td>\n",
              "      <td>-68</td>\n",
              "      <td>-57</td>\n",
              "      <td>-78</td>\n",
              "      <td>-42</td>\n",
              "      <td>-65</td>\n",
              "      <td>-48</td>\n",
              "      <td>-61</td>\n",
              "      <td>-62</td>\n",
              "      <td>-67</td>\n",
              "      <td>-30</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11498</th>\n",
              "      <td>X10.V1.932</td>\n",
              "      <td>-40</td>\n",
              "      <td>-25</td>\n",
              "      <td>-9</td>\n",
              "      <td>-12</td>\n",
              "      <td>-2</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>22</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>-28</td>\n",
              "      <td>-37</td>\n",
              "      <td>-35</td>\n",
              "      <td>-35</td>\n",
              "      <td>-45</td>\n",
              "      <td>-64</td>\n",
              "      <td>-105</td>\n",
              "      <td>-140</td>\n",
              "      <td>-157</td>\n",
              "      <td>-157</td>\n",
              "      <td>-147</td>\n",
              "      <td>-153</td>\n",
              "      <td>-147</td>\n",
              "      <td>-126</td>\n",
              "      <td>-112</td>\n",
              "      <td>-83</td>\n",
              "      <td>-56</td>\n",
              "      <td>-41</td>\n",
              "      <td>-40</td>\n",
              "      <td>-38</td>\n",
              "      <td>-34</td>\n",
              "      <td>-47</td>\n",
              "      <td>-41</td>\n",
              "      <td>-40</td>\n",
              "      <td>-42</td>\n",
              "      <td>-49</td>\n",
              "      <td>...</td>\n",
              "      <td>-98</td>\n",
              "      <td>-77</td>\n",
              "      <td>-60</td>\n",
              "      <td>-73</td>\n",
              "      <td>-88</td>\n",
              "      <td>-97</td>\n",
              "      <td>-118</td>\n",
              "      <td>-108</td>\n",
              "      <td>-100</td>\n",
              "      <td>-97</td>\n",
              "      <td>-91</td>\n",
              "      <td>-109</td>\n",
              "      <td>-122</td>\n",
              "      <td>-134</td>\n",
              "      <td>-137</td>\n",
              "      <td>-107</td>\n",
              "      <td>-95</td>\n",
              "      <td>-67</td>\n",
              "      <td>-54</td>\n",
              "      <td>-40</td>\n",
              "      <td>-31</td>\n",
              "      <td>-19</td>\n",
              "      <td>7</td>\n",
              "      <td>22</td>\n",
              "      <td>46</td>\n",
              "      <td>68</td>\n",
              "      <td>87</td>\n",
              "      <td>97</td>\n",
              "      <td>105</td>\n",
              "      <td>114</td>\n",
              "      <td>121</td>\n",
              "      <td>135</td>\n",
              "      <td>148</td>\n",
              "      <td>143</td>\n",
              "      <td>116</td>\n",
              "      <td>86</td>\n",
              "      <td>68</td>\n",
              "      <td>59</td>\n",
              "      <td>55</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11499</th>\n",
              "      <td>X16.V1.210</td>\n",
              "      <td>29</td>\n",
              "      <td>41</td>\n",
              "      <td>57</td>\n",
              "      <td>72</td>\n",
              "      <td>74</td>\n",
              "      <td>62</td>\n",
              "      <td>54</td>\n",
              "      <td>43</td>\n",
              "      <td>31</td>\n",
              "      <td>23</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>-3</td>\n",
              "      <td>-5</td>\n",
              "      <td>-9</td>\n",
              "      <td>-14</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>60</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>50</td>\n",
              "      <td>33</td>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>-5</td>\n",
              "      <td>-4</td>\n",
              "      <td>-8</td>\n",
              "      <td>-15</td>\n",
              "      <td>-13</td>\n",
              "      <td>-2</td>\n",
              "      <td>21</td>\n",
              "      <td>39</td>\n",
              "      <td>48</td>\n",
              "      <td>37</td>\n",
              "      <td>10</td>\n",
              "      <td>-23</td>\n",
              "      <td>-47</td>\n",
              "      <td>...</td>\n",
              "      <td>-108</td>\n",
              "      <td>-83</td>\n",
              "      <td>-46</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>39</td>\n",
              "      <td>44</td>\n",
              "      <td>33</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>-13</td>\n",
              "      <td>-33</td>\n",
              "      <td>-61</td>\n",
              "      <td>-70</td>\n",
              "      <td>-75</td>\n",
              "      <td>-74</td>\n",
              "      <td>-58</td>\n",
              "      <td>-18</td>\n",
              "      <td>19</td>\n",
              "      <td>54</td>\n",
              "      <td>71</td>\n",
              "      <td>76</td>\n",
              "      <td>74</td>\n",
              "      <td>65</td>\n",
              "      <td>56</td>\n",
              "      <td>18</td>\n",
              "      <td>-28</td>\n",
              "      <td>-75</td>\n",
              "      <td>-98</td>\n",
              "      <td>-94</td>\n",
              "      <td>-59</td>\n",
              "      <td>-25</td>\n",
              "      <td>-4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>-2</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11500 rows × 180 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0   X1   X2   X3   X4   X5  ...  X174  X175  X176  X177  X178  y\n",
              "0      X21.V1.791  135  190  229  223  192  ...  -103  -127  -116   -83   -51  4\n",
              "1      X15.V1.924  386  382  356  331  320  ...   157   156   154   143   129  1\n",
              "2         X8.V1.1  -32  -39  -47  -37  -32  ...   -12   -30   -35   -35   -36  5\n",
              "3       X16.V1.60 -105 -101  -96  -92  -89  ...   -85   -77   -72   -69   -65  5\n",
              "4       X20.V1.54   -9  -65  -98 -102  -78  ...   -41   -65   -83   -89   -73  5\n",
              "...           ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ... ..\n",
              "11495  X22.V1.114  -22  -22  -23  -26  -36  ...    -1   -18   -37   -47   -48  2\n",
              "11496  X19.V1.354  -47  -11   28   77  141  ...    27    48    77   117   170  1\n",
              "11497    X8.V1.28   14    6  -13  -16   10  ...   -67   -30    -2    -1    -8  5\n",
              "11498  X10.V1.932  -40  -25   -9  -12   -2  ...   116    86    68    59    55  3\n",
              "11499  X16.V1.210   29   41   57   72   74  ...     5     4    -2     2    20  4\n",
              "\n",
              "[11500 rows x 180 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tudu50uC0Qt6",
        "colab_type": "code",
        "outputId": "1d7031ad-de75-492f-ffe1-0d7ff1352c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print (\"We have \",len(df.columns), \" attributes.\")\n",
        "for i in range(0, len(df.columns)):\n",
        "    print('{:<10}{:<40}{:<10}{:<20}'.format(str(i+1), str(df.columns[i]),\"type: \", str(df.dtypes[df.columns[i]])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have  180  attributes.\n",
            "1         Unnamed: 0                              type:     object              \n",
            "2         X1                                      type:     int64               \n",
            "3         X2                                      type:     int64               \n",
            "4         X3                                      type:     int64               \n",
            "5         X4                                      type:     int64               \n",
            "6         X5                                      type:     int64               \n",
            "7         X6                                      type:     int64               \n",
            "8         X7                                      type:     int64               \n",
            "9         X8                                      type:     int64               \n",
            "10        X9                                      type:     int64               \n",
            "11        X10                                     type:     int64               \n",
            "12        X11                                     type:     int64               \n",
            "13        X12                                     type:     int64               \n",
            "14        X13                                     type:     int64               \n",
            "15        X14                                     type:     int64               \n",
            "16        X15                                     type:     int64               \n",
            "17        X16                                     type:     int64               \n",
            "18        X17                                     type:     int64               \n",
            "19        X18                                     type:     int64               \n",
            "20        X19                                     type:     int64               \n",
            "21        X20                                     type:     int64               \n",
            "22        X21                                     type:     int64               \n",
            "23        X22                                     type:     int64               \n",
            "24        X23                                     type:     int64               \n",
            "25        X24                                     type:     int64               \n",
            "26        X25                                     type:     int64               \n",
            "27        X26                                     type:     int64               \n",
            "28        X27                                     type:     int64               \n",
            "29        X28                                     type:     int64               \n",
            "30        X29                                     type:     int64               \n",
            "31        X30                                     type:     int64               \n",
            "32        X31                                     type:     int64               \n",
            "33        X32                                     type:     int64               \n",
            "34        X33                                     type:     int64               \n",
            "35        X34                                     type:     int64               \n",
            "36        X35                                     type:     int64               \n",
            "37        X36                                     type:     int64               \n",
            "38        X37                                     type:     int64               \n",
            "39        X38                                     type:     int64               \n",
            "40        X39                                     type:     int64               \n",
            "41        X40                                     type:     int64               \n",
            "42        X41                                     type:     int64               \n",
            "43        X42                                     type:     int64               \n",
            "44        X43                                     type:     int64               \n",
            "45        X44                                     type:     int64               \n",
            "46        X45                                     type:     int64               \n",
            "47        X46                                     type:     int64               \n",
            "48        X47                                     type:     int64               \n",
            "49        X48                                     type:     int64               \n",
            "50        X49                                     type:     int64               \n",
            "51        X50                                     type:     int64               \n",
            "52        X51                                     type:     int64               \n",
            "53        X52                                     type:     int64               \n",
            "54        X53                                     type:     int64               \n",
            "55        X54                                     type:     int64               \n",
            "56        X55                                     type:     int64               \n",
            "57        X56                                     type:     int64               \n",
            "58        X57                                     type:     int64               \n",
            "59        X58                                     type:     int64               \n",
            "60        X59                                     type:     int64               \n",
            "61        X60                                     type:     int64               \n",
            "62        X61                                     type:     int64               \n",
            "63        X62                                     type:     int64               \n",
            "64        X63                                     type:     int64               \n",
            "65        X64                                     type:     int64               \n",
            "66        X65                                     type:     int64               \n",
            "67        X66                                     type:     int64               \n",
            "68        X67                                     type:     int64               \n",
            "69        X68                                     type:     int64               \n",
            "70        X69                                     type:     int64               \n",
            "71        X70                                     type:     int64               \n",
            "72        X71                                     type:     int64               \n",
            "73        X72                                     type:     int64               \n",
            "74        X73                                     type:     int64               \n",
            "75        X74                                     type:     int64               \n",
            "76        X75                                     type:     int64               \n",
            "77        X76                                     type:     int64               \n",
            "78        X77                                     type:     int64               \n",
            "79        X78                                     type:     int64               \n",
            "80        X79                                     type:     int64               \n",
            "81        X80                                     type:     int64               \n",
            "82        X81                                     type:     int64               \n",
            "83        X82                                     type:     int64               \n",
            "84        X83                                     type:     int64               \n",
            "85        X84                                     type:     int64               \n",
            "86        X85                                     type:     int64               \n",
            "87        X86                                     type:     int64               \n",
            "88        X87                                     type:     int64               \n",
            "89        X88                                     type:     int64               \n",
            "90        X89                                     type:     int64               \n",
            "91        X90                                     type:     int64               \n",
            "92        X91                                     type:     int64               \n",
            "93        X92                                     type:     int64               \n",
            "94        X93                                     type:     int64               \n",
            "95        X94                                     type:     int64               \n",
            "96        X95                                     type:     int64               \n",
            "97        X96                                     type:     int64               \n",
            "98        X97                                     type:     int64               \n",
            "99        X98                                     type:     int64               \n",
            "100       X99                                     type:     int64               \n",
            "101       X100                                    type:     int64               \n",
            "102       X101                                    type:     int64               \n",
            "103       X102                                    type:     int64               \n",
            "104       X103                                    type:     int64               \n",
            "105       X104                                    type:     int64               \n",
            "106       X105                                    type:     int64               \n",
            "107       X106                                    type:     int64               \n",
            "108       X107                                    type:     int64               \n",
            "109       X108                                    type:     int64               \n",
            "110       X109                                    type:     int64               \n",
            "111       X110                                    type:     int64               \n",
            "112       X111                                    type:     int64               \n",
            "113       X112                                    type:     int64               \n",
            "114       X113                                    type:     int64               \n",
            "115       X114                                    type:     int64               \n",
            "116       X115                                    type:     int64               \n",
            "117       X116                                    type:     int64               \n",
            "118       X117                                    type:     int64               \n",
            "119       X118                                    type:     int64               \n",
            "120       X119                                    type:     int64               \n",
            "121       X120                                    type:     int64               \n",
            "122       X121                                    type:     int64               \n",
            "123       X122                                    type:     int64               \n",
            "124       X123                                    type:     int64               \n",
            "125       X124                                    type:     int64               \n",
            "126       X125                                    type:     int64               \n",
            "127       X126                                    type:     int64               \n",
            "128       X127                                    type:     int64               \n",
            "129       X128                                    type:     int64               \n",
            "130       X129                                    type:     int64               \n",
            "131       X130                                    type:     int64               \n",
            "132       X131                                    type:     int64               \n",
            "133       X132                                    type:     int64               \n",
            "134       X133                                    type:     int64               \n",
            "135       X134                                    type:     int64               \n",
            "136       X135                                    type:     int64               \n",
            "137       X136                                    type:     int64               \n",
            "138       X137                                    type:     int64               \n",
            "139       X138                                    type:     int64               \n",
            "140       X139                                    type:     int64               \n",
            "141       X140                                    type:     int64               \n",
            "142       X141                                    type:     int64               \n",
            "143       X142                                    type:     int64               \n",
            "144       X143                                    type:     int64               \n",
            "145       X144                                    type:     int64               \n",
            "146       X145                                    type:     int64               \n",
            "147       X146                                    type:     int64               \n",
            "148       X147                                    type:     int64               \n",
            "149       X148                                    type:     int64               \n",
            "150       X149                                    type:     int64               \n",
            "151       X150                                    type:     int64               \n",
            "152       X151                                    type:     int64               \n",
            "153       X152                                    type:     int64               \n",
            "154       X153                                    type:     int64               \n",
            "155       X154                                    type:     int64               \n",
            "156       X155                                    type:     int64               \n",
            "157       X156                                    type:     int64               \n",
            "158       X157                                    type:     int64               \n",
            "159       X158                                    type:     int64               \n",
            "160       X159                                    type:     int64               \n",
            "161       X160                                    type:     int64               \n",
            "162       X161                                    type:     int64               \n",
            "163       X162                                    type:     int64               \n",
            "164       X163                                    type:     int64               \n",
            "165       X164                                    type:     int64               \n",
            "166       X165                                    type:     int64               \n",
            "167       X166                                    type:     int64               \n",
            "168       X167                                    type:     int64               \n",
            "169       X168                                    type:     int64               \n",
            "170       X169                                    type:     int64               \n",
            "171       X170                                    type:     int64               \n",
            "172       X171                                    type:     int64               \n",
            "173       X172                                    type:     int64               \n",
            "174       X173                                    type:     int64               \n",
            "175       X174                                    type:     int64               \n",
            "176       X175                                    type:     int64               \n",
            "177       X176                                    type:     int64               \n",
            "178       X177                                    type:     int64               \n",
            "179       X178                                    type:     int64               \n",
            "180       y                                       type:     int64               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcm_GRAbqP4f",
        "colab_type": "text"
      },
      "source": [
        "5. Διαγράφουμε την πρώτη κολώνα, ώστε όλες οι κολώνες εκτός της τελευταίας να περιέχουν τιμές των χαρακτηριστικών, με την τελευταία να περιέχει τις ετικέτες."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSj6XEFTplQq",
        "colab_type": "code",
        "outputId": "115e0efb-1ce1-4316-c8c9-48d9a2dd2ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "df = df.drop(df.columns[[0]], axis=1)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>X11</th>\n",
              "      <th>X12</th>\n",
              "      <th>X13</th>\n",
              "      <th>X14</th>\n",
              "      <th>X15</th>\n",
              "      <th>X16</th>\n",
              "      <th>X17</th>\n",
              "      <th>X18</th>\n",
              "      <th>X19</th>\n",
              "      <th>X20</th>\n",
              "      <th>X21</th>\n",
              "      <th>X22</th>\n",
              "      <th>X23</th>\n",
              "      <th>X24</th>\n",
              "      <th>X25</th>\n",
              "      <th>X26</th>\n",
              "      <th>X27</th>\n",
              "      <th>X28</th>\n",
              "      <th>X29</th>\n",
              "      <th>X30</th>\n",
              "      <th>X31</th>\n",
              "      <th>X32</th>\n",
              "      <th>X33</th>\n",
              "      <th>X34</th>\n",
              "      <th>X35</th>\n",
              "      <th>X36</th>\n",
              "      <th>X37</th>\n",
              "      <th>X38</th>\n",
              "      <th>X39</th>\n",
              "      <th>X40</th>\n",
              "      <th>...</th>\n",
              "      <th>X140</th>\n",
              "      <th>X141</th>\n",
              "      <th>X142</th>\n",
              "      <th>X143</th>\n",
              "      <th>X144</th>\n",
              "      <th>X145</th>\n",
              "      <th>X146</th>\n",
              "      <th>X147</th>\n",
              "      <th>X148</th>\n",
              "      <th>X149</th>\n",
              "      <th>X150</th>\n",
              "      <th>X151</th>\n",
              "      <th>X152</th>\n",
              "      <th>X153</th>\n",
              "      <th>X154</th>\n",
              "      <th>X155</th>\n",
              "      <th>X156</th>\n",
              "      <th>X157</th>\n",
              "      <th>X158</th>\n",
              "      <th>X159</th>\n",
              "      <th>X160</th>\n",
              "      <th>X161</th>\n",
              "      <th>X162</th>\n",
              "      <th>X163</th>\n",
              "      <th>X164</th>\n",
              "      <th>X165</th>\n",
              "      <th>X166</th>\n",
              "      <th>X167</th>\n",
              "      <th>X168</th>\n",
              "      <th>X169</th>\n",
              "      <th>X170</th>\n",
              "      <th>X171</th>\n",
              "      <th>X172</th>\n",
              "      <th>X173</th>\n",
              "      <th>X174</th>\n",
              "      <th>X175</th>\n",
              "      <th>X176</th>\n",
              "      <th>X177</th>\n",
              "      <th>X178</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>135</td>\n",
              "      <td>190</td>\n",
              "      <td>229</td>\n",
              "      <td>223</td>\n",
              "      <td>192</td>\n",
              "      <td>125</td>\n",
              "      <td>55</td>\n",
              "      <td>-9</td>\n",
              "      <td>-33</td>\n",
              "      <td>-38</td>\n",
              "      <td>-10</td>\n",
              "      <td>35</td>\n",
              "      <td>64</td>\n",
              "      <td>113</td>\n",
              "      <td>152</td>\n",
              "      <td>164</td>\n",
              "      <td>127</td>\n",
              "      <td>50</td>\n",
              "      <td>-47</td>\n",
              "      <td>-121</td>\n",
              "      <td>-138</td>\n",
              "      <td>-125</td>\n",
              "      <td>-101</td>\n",
              "      <td>-50</td>\n",
              "      <td>11</td>\n",
              "      <td>39</td>\n",
              "      <td>24</td>\n",
              "      <td>48</td>\n",
              "      <td>64</td>\n",
              "      <td>46</td>\n",
              "      <td>13</td>\n",
              "      <td>-19</td>\n",
              "      <td>-61</td>\n",
              "      <td>-96</td>\n",
              "      <td>-130</td>\n",
              "      <td>-132</td>\n",
              "      <td>-116</td>\n",
              "      <td>-115</td>\n",
              "      <td>-71</td>\n",
              "      <td>-14</td>\n",
              "      <td>...</td>\n",
              "      <td>54</td>\n",
              "      <td>90</td>\n",
              "      <td>111</td>\n",
              "      <td>107</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>18</td>\n",
              "      <td>-25</td>\n",
              "      <td>-69</td>\n",
              "      <td>-65</td>\n",
              "      <td>-44</td>\n",
              "      <td>-33</td>\n",
              "      <td>-57</td>\n",
              "      <td>-88</td>\n",
              "      <td>-114</td>\n",
              "      <td>-130</td>\n",
              "      <td>-114</td>\n",
              "      <td>-83</td>\n",
              "      <td>-53</td>\n",
              "      <td>-79</td>\n",
              "      <td>-72</td>\n",
              "      <td>-85</td>\n",
              "      <td>-109</td>\n",
              "      <td>-98</td>\n",
              "      <td>-72</td>\n",
              "      <td>-65</td>\n",
              "      <td>-63</td>\n",
              "      <td>-11</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>-17</td>\n",
              "      <td>-15</td>\n",
              "      <td>-31</td>\n",
              "      <td>-77</td>\n",
              "      <td>-103</td>\n",
              "      <td>-127</td>\n",
              "      <td>-116</td>\n",
              "      <td>-83</td>\n",
              "      <td>-51</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>386</td>\n",
              "      <td>382</td>\n",
              "      <td>356</td>\n",
              "      <td>331</td>\n",
              "      <td>320</td>\n",
              "      <td>315</td>\n",
              "      <td>307</td>\n",
              "      <td>272</td>\n",
              "      <td>244</td>\n",
              "      <td>232</td>\n",
              "      <td>237</td>\n",
              "      <td>258</td>\n",
              "      <td>212</td>\n",
              "      <td>2</td>\n",
              "      <td>-267</td>\n",
              "      <td>-605</td>\n",
              "      <td>-850</td>\n",
              "      <td>-1001</td>\n",
              "      <td>-1109</td>\n",
              "      <td>-1090</td>\n",
              "      <td>-967</td>\n",
              "      <td>-746</td>\n",
              "      <td>-464</td>\n",
              "      <td>-152</td>\n",
              "      <td>118</td>\n",
              "      <td>318</td>\n",
              "      <td>427</td>\n",
              "      <td>473</td>\n",
              "      <td>485</td>\n",
              "      <td>447</td>\n",
              "      <td>397</td>\n",
              "      <td>339</td>\n",
              "      <td>312</td>\n",
              "      <td>314</td>\n",
              "      <td>326</td>\n",
              "      <td>335</td>\n",
              "      <td>332</td>\n",
              "      <td>324</td>\n",
              "      <td>310</td>\n",
              "      <td>312</td>\n",
              "      <td>...</td>\n",
              "      <td>27</td>\n",
              "      <td>146</td>\n",
              "      <td>229</td>\n",
              "      <td>269</td>\n",
              "      <td>297</td>\n",
              "      <td>307</td>\n",
              "      <td>303</td>\n",
              "      <td>305</td>\n",
              "      <td>306</td>\n",
              "      <td>307</td>\n",
              "      <td>280</td>\n",
              "      <td>231</td>\n",
              "      <td>159</td>\n",
              "      <td>85</td>\n",
              "      <td>51</td>\n",
              "      <td>43</td>\n",
              "      <td>62</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>89</td>\n",
              "      <td>123</td>\n",
              "      <td>136</td>\n",
              "      <td>127</td>\n",
              "      <td>102</td>\n",
              "      <td>95</td>\n",
              "      <td>105</td>\n",
              "      <td>131</td>\n",
              "      <td>163</td>\n",
              "      <td>168</td>\n",
              "      <td>164</td>\n",
              "      <td>150</td>\n",
              "      <td>146</td>\n",
              "      <td>152</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>154</td>\n",
              "      <td>143</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-32</td>\n",
              "      <td>-39</td>\n",
              "      <td>-47</td>\n",
              "      <td>-37</td>\n",
              "      <td>-32</td>\n",
              "      <td>-36</td>\n",
              "      <td>-57</td>\n",
              "      <td>-73</td>\n",
              "      <td>-85</td>\n",
              "      <td>-94</td>\n",
              "      <td>-99</td>\n",
              "      <td>-94</td>\n",
              "      <td>-96</td>\n",
              "      <td>-104</td>\n",
              "      <td>-103</td>\n",
              "      <td>-92</td>\n",
              "      <td>-75</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-53</td>\n",
              "      <td>-37</td>\n",
              "      <td>-14</td>\n",
              "      <td>-10</td>\n",
              "      <td>-39</td>\n",
              "      <td>-78</td>\n",
              "      <td>-102</td>\n",
              "      <td>-98</td>\n",
              "      <td>-80</td>\n",
              "      <td>-54</td>\n",
              "      <td>-40</td>\n",
              "      <td>-35</td>\n",
              "      <td>-39</td>\n",
              "      <td>-32</td>\n",
              "      <td>-13</td>\n",
              "      <td>7</td>\n",
              "      <td>34</td>\n",
              "      <td>41</td>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>-15</td>\n",
              "      <td>...</td>\n",
              "      <td>-82</td>\n",
              "      <td>-107</td>\n",
              "      <td>-126</td>\n",
              "      <td>-124</td>\n",
              "      <td>-108</td>\n",
              "      <td>-84</td>\n",
              "      <td>-68</td>\n",
              "      <td>-61</td>\n",
              "      <td>-56</td>\n",
              "      <td>-63</td>\n",
              "      <td>-62</td>\n",
              "      <td>-33</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>45</td>\n",
              "      <td>37</td>\n",
              "      <td>48</td>\n",
              "      <td>62</td>\n",
              "      <td>80</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>-11</td>\n",
              "      <td>-39</td>\n",
              "      <td>-44</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-48</td>\n",
              "      <td>-42</td>\n",
              "      <td>-6</td>\n",
              "      <td>29</td>\n",
              "      <td>57</td>\n",
              "      <td>64</td>\n",
              "      <td>48</td>\n",
              "      <td>19</td>\n",
              "      <td>-12</td>\n",
              "      <td>-30</td>\n",
              "      <td>-35</td>\n",
              "      <td>-35</td>\n",
              "      <td>-36</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-105</td>\n",
              "      <td>-101</td>\n",
              "      <td>-96</td>\n",
              "      <td>-92</td>\n",
              "      <td>-89</td>\n",
              "      <td>-95</td>\n",
              "      <td>-102</td>\n",
              "      <td>-100</td>\n",
              "      <td>-87</td>\n",
              "      <td>-79</td>\n",
              "      <td>-72</td>\n",
              "      <td>-68</td>\n",
              "      <td>-74</td>\n",
              "      <td>-80</td>\n",
              "      <td>-83</td>\n",
              "      <td>-73</td>\n",
              "      <td>-68</td>\n",
              "      <td>-61</td>\n",
              "      <td>-58</td>\n",
              "      <td>-59</td>\n",
              "      <td>-64</td>\n",
              "      <td>-79</td>\n",
              "      <td>-84</td>\n",
              "      <td>-97</td>\n",
              "      <td>-94</td>\n",
              "      <td>-84</td>\n",
              "      <td>-77</td>\n",
              "      <td>-75</td>\n",
              "      <td>-72</td>\n",
              "      <td>-68</td>\n",
              "      <td>-76</td>\n",
              "      <td>-76</td>\n",
              "      <td>-72</td>\n",
              "      <td>-67</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-67</td>\n",
              "      <td>-68</td>\n",
              "      <td>-69</td>\n",
              "      <td>...</td>\n",
              "      <td>-69</td>\n",
              "      <td>-66</td>\n",
              "      <td>-74</td>\n",
              "      <td>-69</td>\n",
              "      <td>-61</td>\n",
              "      <td>-51</td>\n",
              "      <td>-45</td>\n",
              "      <td>-45</td>\n",
              "      <td>-49</td>\n",
              "      <td>-58</td>\n",
              "      <td>-64</td>\n",
              "      <td>-78</td>\n",
              "      <td>-80</td>\n",
              "      <td>-90</td>\n",
              "      <td>-87</td>\n",
              "      <td>-83</td>\n",
              "      <td>-78</td>\n",
              "      <td>-64</td>\n",
              "      <td>-38</td>\n",
              "      <td>-22</td>\n",
              "      <td>-29</td>\n",
              "      <td>-42</td>\n",
              "      <td>-51</td>\n",
              "      <td>-68</td>\n",
              "      <td>-71</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-74</td>\n",
              "      <td>-74</td>\n",
              "      <td>-80</td>\n",
              "      <td>-82</td>\n",
              "      <td>-81</td>\n",
              "      <td>-80</td>\n",
              "      <td>-77</td>\n",
              "      <td>-85</td>\n",
              "      <td>-77</td>\n",
              "      <td>-72</td>\n",
              "      <td>-69</td>\n",
              "      <td>-65</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9</td>\n",
              "      <td>-65</td>\n",
              "      <td>-98</td>\n",
              "      <td>-102</td>\n",
              "      <td>-78</td>\n",
              "      <td>-48</td>\n",
              "      <td>-16</td>\n",
              "      <td>0</td>\n",
              "      <td>-21</td>\n",
              "      <td>-59</td>\n",
              "      <td>-90</td>\n",
              "      <td>-103</td>\n",
              "      <td>-84</td>\n",
              "      <td>-43</td>\n",
              "      <td>-9</td>\n",
              "      <td>3</td>\n",
              "      <td>-21</td>\n",
              "      <td>-60</td>\n",
              "      <td>-96</td>\n",
              "      <td>-103</td>\n",
              "      <td>-75</td>\n",
              "      <td>-29</td>\n",
              "      <td>14</td>\n",
              "      <td>55</td>\n",
              "      <td>78</td>\n",
              "      <td>73</td>\n",
              "      <td>28</td>\n",
              "      <td>-13</td>\n",
              "      <td>-43</td>\n",
              "      <td>-68</td>\n",
              "      <td>-78</td>\n",
              "      <td>-75</td>\n",
              "      <td>-55</td>\n",
              "      <td>-41</td>\n",
              "      <td>-19</td>\n",
              "      <td>-20</td>\n",
              "      <td>-29</td>\n",
              "      <td>-36</td>\n",
              "      <td>-20</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>38</td>\n",
              "      <td>26</td>\n",
              "      <td>10</td>\n",
              "      <td>-4</td>\n",
              "      <td>-13</td>\n",
              "      <td>-8</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>29</td>\n",
              "      <td>57</td>\n",
              "      <td>63</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "      <td>-13</td>\n",
              "      <td>-23</td>\n",
              "      <td>-9</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>-12</td>\n",
              "      <td>-32</td>\n",
              "      <td>-41</td>\n",
              "      <td>-65</td>\n",
              "      <td>-83</td>\n",
              "      <td>-89</td>\n",
              "      <td>-73</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11495</th>\n",
              "      <td>-22</td>\n",
              "      <td>-22</td>\n",
              "      <td>-23</td>\n",
              "      <td>-26</td>\n",
              "      <td>-36</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-49</td>\n",
              "      <td>-57</td>\n",
              "      <td>-64</td>\n",
              "      <td>-73</td>\n",
              "      <td>-79</td>\n",
              "      <td>-76</td>\n",
              "      <td>-70</td>\n",
              "      <td>-63</td>\n",
              "      <td>-57</td>\n",
              "      <td>-57</td>\n",
              "      <td>-50</td>\n",
              "      <td>-45</td>\n",
              "      <td>-34</td>\n",
              "      <td>-33</td>\n",
              "      <td>-32</td>\n",
              "      <td>-30</td>\n",
              "      <td>-24</td>\n",
              "      <td>-24</td>\n",
              "      <td>-18</td>\n",
              "      <td>-9</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-3</td>\n",
              "      <td>-5</td>\n",
              "      <td>-13</td>\n",
              "      <td>-23</td>\n",
              "      <td>-39</td>\n",
              "      <td>-53</td>\n",
              "      <td>-59</td>\n",
              "      <td>-63</td>\n",
              "      <td>...</td>\n",
              "      <td>45</td>\n",
              "      <td>55</td>\n",
              "      <td>60</td>\n",
              "      <td>69</td>\n",
              "      <td>68</td>\n",
              "      <td>58</td>\n",
              "      <td>54</td>\n",
              "      <td>44</td>\n",
              "      <td>40</td>\n",
              "      <td>38</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>32</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>25</td>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>-18</td>\n",
              "      <td>-37</td>\n",
              "      <td>-47</td>\n",
              "      <td>-48</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11496</th>\n",
              "      <td>-47</td>\n",
              "      <td>-11</td>\n",
              "      <td>28</td>\n",
              "      <td>77</td>\n",
              "      <td>141</td>\n",
              "      <td>211</td>\n",
              "      <td>246</td>\n",
              "      <td>240</td>\n",
              "      <td>193</td>\n",
              "      <td>136</td>\n",
              "      <td>78</td>\n",
              "      <td>8</td>\n",
              "      <td>-66</td>\n",
              "      <td>-132</td>\n",
              "      <td>-180</td>\n",
              "      <td>-210</td>\n",
              "      <td>-227</td>\n",
              "      <td>-225</td>\n",
              "      <td>-212</td>\n",
              "      <td>-192</td>\n",
              "      <td>-168</td>\n",
              "      <td>-144</td>\n",
              "      <td>-117</td>\n",
              "      <td>-88</td>\n",
              "      <td>-54</td>\n",
              "      <td>-21</td>\n",
              "      <td>6</td>\n",
              "      <td>29</td>\n",
              "      <td>46</td>\n",
              "      <td>60</td>\n",
              "      <td>76</td>\n",
              "      <td>92</td>\n",
              "      <td>110</td>\n",
              "      <td>128</td>\n",
              "      <td>152</td>\n",
              "      <td>171</td>\n",
              "      <td>150</td>\n",
              "      <td>91</td>\n",
              "      <td>21</td>\n",
              "      <td>-29</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>38</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>75</td>\n",
              "      <td>165</td>\n",
              "      <td>260</td>\n",
              "      <td>343</td>\n",
              "      <td>406</td>\n",
              "      <td>456</td>\n",
              "      <td>471</td>\n",
              "      <td>461</td>\n",
              "      <td>412</td>\n",
              "      <td>319</td>\n",
              "      <td>175</td>\n",
              "      <td>-5</td>\n",
              "      <td>-171</td>\n",
              "      <td>-293</td>\n",
              "      <td>-357</td>\n",
              "      <td>-378</td>\n",
              "      <td>-370</td>\n",
              "      <td>-346</td>\n",
              "      <td>-316</td>\n",
              "      <td>-278</td>\n",
              "      <td>-241</td>\n",
              "      <td>-201</td>\n",
              "      <td>-162</td>\n",
              "      <td>-126</td>\n",
              "      <td>-94</td>\n",
              "      <td>-65</td>\n",
              "      <td>-33</td>\n",
              "      <td>-7</td>\n",
              "      <td>14</td>\n",
              "      <td>27</td>\n",
              "      <td>48</td>\n",
              "      <td>77</td>\n",
              "      <td>117</td>\n",
              "      <td>170</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11497</th>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>-13</td>\n",
              "      <td>-16</td>\n",
              "      <td>10</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>-9</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>-1</td>\n",
              "      <td>-10</td>\n",
              "      <td>14</td>\n",
              "      <td>44</td>\n",
              "      <td>77</td>\n",
              "      <td>61</td>\n",
              "      <td>42</td>\n",
              "      <td>32</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "      <td>26</td>\n",
              "      <td>35</td>\n",
              "      <td>81</td>\n",
              "      <td>66</td>\n",
              "      <td>50</td>\n",
              "      <td>57</td>\n",
              "      <td>91</td>\n",
              "      <td>121</td>\n",
              "      <td>111</td>\n",
              "      <td>73</td>\n",
              "      <td>38</td>\n",
              "      <td>23</td>\n",
              "      <td>35</td>\n",
              "      <td>21</td>\n",
              "      <td>11</td>\n",
              "      <td>-12</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>61</td>\n",
              "      <td>88</td>\n",
              "      <td>...</td>\n",
              "      <td>-90</td>\n",
              "      <td>-62</td>\n",
              "      <td>-38</td>\n",
              "      <td>-40</td>\n",
              "      <td>-21</td>\n",
              "      <td>-23</td>\n",
              "      <td>-11</td>\n",
              "      <td>-4</td>\n",
              "      <td>-9</td>\n",
              "      <td>-22</td>\n",
              "      <td>-42</td>\n",
              "      <td>-49</td>\n",
              "      <td>-48</td>\n",
              "      <td>-40</td>\n",
              "      <td>-40</td>\n",
              "      <td>-46</td>\n",
              "      <td>-43</td>\n",
              "      <td>-67</td>\n",
              "      <td>-67</td>\n",
              "      <td>-50</td>\n",
              "      <td>-18</td>\n",
              "      <td>-14</td>\n",
              "      <td>-39</td>\n",
              "      <td>-74</td>\n",
              "      <td>-86</td>\n",
              "      <td>-75</td>\n",
              "      <td>-68</td>\n",
              "      <td>-57</td>\n",
              "      <td>-78</td>\n",
              "      <td>-42</td>\n",
              "      <td>-65</td>\n",
              "      <td>-48</td>\n",
              "      <td>-61</td>\n",
              "      <td>-62</td>\n",
              "      <td>-67</td>\n",
              "      <td>-30</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11498</th>\n",
              "      <td>-40</td>\n",
              "      <td>-25</td>\n",
              "      <td>-9</td>\n",
              "      <td>-12</td>\n",
              "      <td>-2</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>22</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>-28</td>\n",
              "      <td>-37</td>\n",
              "      <td>-35</td>\n",
              "      <td>-35</td>\n",
              "      <td>-45</td>\n",
              "      <td>-64</td>\n",
              "      <td>-105</td>\n",
              "      <td>-140</td>\n",
              "      <td>-157</td>\n",
              "      <td>-157</td>\n",
              "      <td>-147</td>\n",
              "      <td>-153</td>\n",
              "      <td>-147</td>\n",
              "      <td>-126</td>\n",
              "      <td>-112</td>\n",
              "      <td>-83</td>\n",
              "      <td>-56</td>\n",
              "      <td>-41</td>\n",
              "      <td>-40</td>\n",
              "      <td>-38</td>\n",
              "      <td>-34</td>\n",
              "      <td>-47</td>\n",
              "      <td>-41</td>\n",
              "      <td>-40</td>\n",
              "      <td>-42</td>\n",
              "      <td>-49</td>\n",
              "      <td>-56</td>\n",
              "      <td>...</td>\n",
              "      <td>-98</td>\n",
              "      <td>-77</td>\n",
              "      <td>-60</td>\n",
              "      <td>-73</td>\n",
              "      <td>-88</td>\n",
              "      <td>-97</td>\n",
              "      <td>-118</td>\n",
              "      <td>-108</td>\n",
              "      <td>-100</td>\n",
              "      <td>-97</td>\n",
              "      <td>-91</td>\n",
              "      <td>-109</td>\n",
              "      <td>-122</td>\n",
              "      <td>-134</td>\n",
              "      <td>-137</td>\n",
              "      <td>-107</td>\n",
              "      <td>-95</td>\n",
              "      <td>-67</td>\n",
              "      <td>-54</td>\n",
              "      <td>-40</td>\n",
              "      <td>-31</td>\n",
              "      <td>-19</td>\n",
              "      <td>7</td>\n",
              "      <td>22</td>\n",
              "      <td>46</td>\n",
              "      <td>68</td>\n",
              "      <td>87</td>\n",
              "      <td>97</td>\n",
              "      <td>105</td>\n",
              "      <td>114</td>\n",
              "      <td>121</td>\n",
              "      <td>135</td>\n",
              "      <td>148</td>\n",
              "      <td>143</td>\n",
              "      <td>116</td>\n",
              "      <td>86</td>\n",
              "      <td>68</td>\n",
              "      <td>59</td>\n",
              "      <td>55</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11499</th>\n",
              "      <td>29</td>\n",
              "      <td>41</td>\n",
              "      <td>57</td>\n",
              "      <td>72</td>\n",
              "      <td>74</td>\n",
              "      <td>62</td>\n",
              "      <td>54</td>\n",
              "      <td>43</td>\n",
              "      <td>31</td>\n",
              "      <td>23</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>-3</td>\n",
              "      <td>-5</td>\n",
              "      <td>-9</td>\n",
              "      <td>-14</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>60</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>50</td>\n",
              "      <td>33</td>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>-5</td>\n",
              "      <td>-4</td>\n",
              "      <td>-8</td>\n",
              "      <td>-15</td>\n",
              "      <td>-13</td>\n",
              "      <td>-2</td>\n",
              "      <td>21</td>\n",
              "      <td>39</td>\n",
              "      <td>48</td>\n",
              "      <td>37</td>\n",
              "      <td>10</td>\n",
              "      <td>-23</td>\n",
              "      <td>-47</td>\n",
              "      <td>-71</td>\n",
              "      <td>...</td>\n",
              "      <td>-108</td>\n",
              "      <td>-83</td>\n",
              "      <td>-46</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>39</td>\n",
              "      <td>44</td>\n",
              "      <td>33</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>-13</td>\n",
              "      <td>-33</td>\n",
              "      <td>-61</td>\n",
              "      <td>-70</td>\n",
              "      <td>-75</td>\n",
              "      <td>-74</td>\n",
              "      <td>-58</td>\n",
              "      <td>-18</td>\n",
              "      <td>19</td>\n",
              "      <td>54</td>\n",
              "      <td>71</td>\n",
              "      <td>76</td>\n",
              "      <td>74</td>\n",
              "      <td>65</td>\n",
              "      <td>56</td>\n",
              "      <td>18</td>\n",
              "      <td>-28</td>\n",
              "      <td>-75</td>\n",
              "      <td>-98</td>\n",
              "      <td>-94</td>\n",
              "      <td>-59</td>\n",
              "      <td>-25</td>\n",
              "      <td>-4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>-2</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11500 rows × 179 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        X1   X2   X3   X4   X5   X6   X7  ...  X173  X174  X175  X176  X177  X178  y\n",
              "0      135  190  229  223  192  125   55  ...   -77  -103  -127  -116   -83   -51  4\n",
              "1      386  382  356  331  320  315  307  ...   152   157   156   154   143   129  1\n",
              "2      -32  -39  -47  -37  -32  -36  -57  ...    19   -12   -30   -35   -35   -36  5\n",
              "3     -105 -101  -96  -92  -89  -95 -102  ...   -77   -85   -77   -72   -69   -65  5\n",
              "4       -9  -65  -98 -102  -78  -48  -16  ...   -32   -41   -65   -83   -89   -73  5\n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ...   ... ..\n",
              "11495  -22  -22  -23  -26  -36  -42  -45  ...     5    -1   -18   -37   -47   -48  2\n",
              "11496  -47  -11   28   77  141  211  246  ...    14    27    48    77   117   170  1\n",
              "11497   14    6  -13  -16   10   26   27  ...   -62   -67   -30    -2    -1    -8  5\n",
              "11498  -40  -25   -9  -12   -2   12    7  ...   143   116    86    68    59    55  3\n",
              "11499   29   41   57   72   74   62   54  ...     2     5     4    -2     2    20  4\n",
              "\n",
              "[11500 rows x 179 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRFK2k4GqnHQ",
        "colab_type": "text"
      },
      "source": [
        "6. Δεν υπάρχουν απουσιάζουσες τιμές.\n",
        "7. Χρησιμοποιούμε την bincount για να μετρήσουμε τη συχνότητα των κατηγοριών. Παρατηρούμε οτι έχουμε ενα εξαιρετικά ισορροπημένο dataset. Και οι 5 κατηγορίες είναι ισοπληθείς. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1haboerrVVO",
        "colab_type": "code",
        "outputId": "c3ea0b86-bfb0-4672-8ce7-c1343e50ffb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels = df.iloc[:, 178]\n",
        "df = df.iloc[:, 0:178]   #remove lables from set\n",
        "print(\"frequencies:\", np.bincount(labels)[1:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequencies: [2300 2300 2300 2300 2300]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rSqNc93uKNc",
        "colab_type": "text"
      },
      "source": [
        "8. Διαχωρίζουμε σε train και test set. Οι τιμές των χαρακτηριστικών αφορούν τα εγκεφαλικά σήματα (τάσεις), άρα είναι διατεταγμένα."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSBGq46YuZ0K",
        "colab_type": "code",
        "outputId": "2e3afda5-06b3-46db-c719-5b2b66f25d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test, train_labels, test_labels = train_test_split(df, labels, test_size=0.3)\n",
        "print(len(train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjCK0y1KwrOX",
        "colab_type": "text"
      },
      "source": [
        "# Γ. Baseline Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Im4uxp-MXUd",
        "colab_type": "text"
      },
      "source": [
        "##### Dummy Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxApc9Auw5eR",
        "colab_type": "text"
      },
      "source": [
        "Εκπαιδεύουμε τους classifiers με τις default τιμές για να δούμε συγκρίνουμε τα αποτέλεσματα πριν και μετά την προεργασία. <br>\n",
        "\n",
        "Αρχίζουμε με τους Dummy Classifiers. Παρατηρούμε οτι επιτυγχάνουμε σε όλους περίπου 20% επιτυχία, όπως ήταν αναμενόμενο καθώς έχουμε 5 κατηγορίες."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm5JMFaGxRSV",
        "colab_type": "code",
        "outputId": "ea09751f-9405-4c0c-fb05-13c0103a8417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "dc_uniform = DummyClassifier(strategy=\"uniform\")\n",
        "dc_constant_1 = DummyClassifier(strategy=\"constant\", constant=1)\n",
        "dc_constant_2 = DummyClassifier(strategy=\"constant\", constant=2)\n",
        "dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
        "dc_stratified = DummyClassifier(strategy=\"stratified\")\n",
        "\n",
        "#using fit to train the classifiers\n",
        "model_uniform = dc_uniform.fit(train, train_labels)\n",
        "model_constant_1 = dc_constant_1.fit(train, train_labels)\n",
        "model_constant_2 = dc_constant_2.fit(train, train_labels)\n",
        "model_most_frequent = dc_most_frequent.fit(train, train_labels)\n",
        "model_stratified = dc_stratified.fit(train, train_labels)\n",
        "\n",
        "#now we make our predictions\n",
        "preds_uniform = dc_uniform.predict(test)\n",
        "preds_constant_1 = dc_constant_1.predict(test)\n",
        "preds_constant_2 = dc_constant_2.predict(test)\n",
        "preds_most_frequent = dc_most_frequent.predict(test)\n",
        "preds_stratified = dc_stratified.predict(test)\n",
        "\n",
        "#print prediction accuracy\n",
        "accuracy = {}\n",
        "print(\"Uniform Classifier: \", accuracy_score(test_labels, preds_uniform))\n",
        "print(\"Constant Classifier (1): \", accuracy_score(test_labels, preds_constant_1))\n",
        "print(\"Constant Classifier (2): \", accuracy_score(test_labels, preds_constant_2))\n",
        "print(\"Most Frequent Classifier: \", accuracy_score(test_labels, preds_most_frequent))\n",
        "print(\"Stratified Classifier: \", accuracy_score(test_labels, preds_stratified))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uniform Classifier:  0.2063768115942029\n",
            "Constant Classifier (1):  0.20318840579710146\n",
            "Constant Classifier (2):  0.20492753623188406\n",
            "Most Frequent Classifier:  0.19014492753623188\n",
            "Stratified Classifier:  0.19942028985507246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDrfn2dg6OgQ",
        "colab_type": "text"
      },
      "source": [
        "Εκτυπώνουμε τον confusion matrix. Ο $C$ είναι ο πίνακας για τον οποίο ισχύει οτι $C_{i, j}$ είναι τα δείγματα της κατηγορίας $i$ που ταξινομήθηκαν στην $j$. Όπως φαίνεται οι Uniform και Stratified προβλέπουν οποιαδήποτε κατηγορία, ενώ οι άλλοι 3 είτε επιλέγουν σταθερά μία κατηγορία είτε αυτή με τα περισσότερα δείγματα. Μάλιστα, από τη στιγμή που τα δείγματα στο αρχικό data set είναι ίσα μεταξύ τους, τα πολυπληθέστερα δείγματα στο train set θα είναι τα λιγότερο πολυπληθή στο test set. Άρα ο classifier αυτός θα έχει χειρότερη επίδοση από τους constant classifiers, όπως φαίνεται και από τον confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMuRq4wD53zy",
        "colab_type": "code",
        "outputId": "5cfedcb1-3c13-42ab-beb3-984d81707e06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#produce confusion matrices\n",
        "cnf_matrix_uniform = confusion_matrix(test_labels, preds_uniform)\n",
        "cnf_matrix_constant_1 = confusion_matrix(test_labels, preds_constant_1)\n",
        "cnf_matrix_constant_2 = confusion_matrix(test_labels, preds_constant_2)\n",
        "cnf_matrix_most_frequent = confusion_matrix(test_labels, preds_most_frequent)\n",
        "cnf_matrix_stratified = confusion_matrix(test_labels, preds_stratified)\n",
        "\n",
        "#print confusion matrices\n",
        "print(\"Uniform Classifier Confusion Matrix\\n\")\n",
        "print(cnf_matrix_uniform, \"\\n\")\n",
        "print(\"Constant Classifier (1) Confusion Matrix\\n\")\n",
        "print(cnf_matrix_constant_1, \"\\n\")\n",
        "print(\"Constant Classifier (2) Confusion Matrix\\n\")\n",
        "print(cnf_matrix_constant_2, \"\\n\")\n",
        "print(\"Most Frequent Classifier Confusion Matrix\\n\")\n",
        "print(cnf_matrix_most_frequent, \"\\n\")\n",
        "print(\"Stratified Classifier Confusion Matrix\\n\")\n",
        "print(cnf_matrix_stratified, \"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uniform Classifier Confusion Matrix\n",
            "\n",
            "[[149 142 124 145 141]\n",
            " [131 148 149 141 138]\n",
            " [158 143 136 135 113]\n",
            " [139 131 138 148 145]\n",
            " [128 129 135 133 131]] \n",
            "\n",
            "Constant Classifier (1) Confusion Matrix\n",
            "\n",
            "[[701   0   0   0   0]\n",
            " [707   0   0   0   0]\n",
            " [685   0   0   0   0]\n",
            " [701   0   0   0   0]\n",
            " [656   0   0   0   0]] \n",
            "\n",
            "Constant Classifier (2) Confusion Matrix\n",
            "\n",
            "[[  0 701   0   0   0]\n",
            " [  0 707   0   0   0]\n",
            " [  0 685   0   0   0]\n",
            " [  0 701   0   0   0]\n",
            " [  0 656   0   0   0]] \n",
            "\n",
            "Most Frequent Classifier Confusion Matrix\n",
            "\n",
            "[[  0   0   0   0 701]\n",
            " [  0   0   0   0 707]\n",
            " [  0   0   0   0 685]\n",
            " [  0   0   0   0 701]\n",
            " [  0   0   0   0 656]] \n",
            "\n",
            "Stratified Classifier Confusion Matrix\n",
            "\n",
            "[[157 119 157 127 141]\n",
            " [147 146 137 141 136]\n",
            " [137 137 141 145 125]\n",
            " [145 145 135 124 152]\n",
            " [144 138 133 121 120]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-GmyVk19rYV",
        "colab_type": "text"
      },
      "source": [
        "Εκτύπωση f1-micro average και f1-macro average.\n",
        "\n",
        "Η ακρίβεια αφορά την ικανότητα του εκτιμητή να εκτιμά ως δείγματα του test set που ανήκουν στη θετική κλάση μόνο αυτά που όντως ανήκουν.<br>\n",
        "Precision: $$P = \\frac{T_p}{T_p+F_p}$$\n",
        "\n",
        "Η ανάκληση αφορά την ικανότητα του εκτιμητή να εντοπίζει όλα τα δείγματα που ανήκουν στη θετική κλάση.<br>\n",
        "Recall: $$R = \\frac{T_p}{T_p + F_n}$$\n",
        "\n",
        "F1 score είναι ο αρμονικός μέσος όρος αυτών των δύο.<br>\n",
        "F1: $$F1 = 2\\frac{P \\times R}{P+R}$$\n",
        "\n",
        "Macro average: υπολογίζει f1 ξεχωριστά για κάθε κλάση και παίρνει τον μέσο όρο. Άρα κάθε κλάση αντιμετωπίζεται ισότιμα.\n",
        "\n",
        "Micro average: ενσωματώνει την πληροφορία για τον αριθμό των δειγμάτων που ανήκουν σε κάθε κλάση, χρησιμοποιώντας τις πραγματικές ποσότητες $T_p$, $F_p$, $F_n$ στον συνολικό υπολογισμό. Άρα είναι προτιμότερη όταν μία κλάση περιέχει αρκετά περισσότερα δείγματα."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXpKTfVv3xY6",
        "colab_type": "code",
        "outputId": "ea9a3a76-5e80-4a76-e61f-afc173c1c9f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#f1-micro\n",
        "print('\\033[1m' + \"f1-micro\" + '\\033[0m')\n",
        "print(\"Uniform Classifier: \", precision_recall_fscore_support(test_labels, preds_uniform, average='micro'))\n",
        "print(\"Constant Classifier (1): \", precision_recall_fscore_support(test_labels, preds_constant_1, average='micro'))\n",
        "print(\"Constant Classifier (2): \", precision_recall_fscore_support(test_labels, preds_constant_2, average='micro'))\n",
        "print(\"Most Frequent Classifier: \", precision_recall_fscore_support(test_labels, preds_most_frequent, average='micro'))\n",
        "print(\"Stratified Classifier: \", precision_recall_fscore_support(test_labels, preds_stratified, average='micro'), \"\\n\")\n",
        "\n",
        "\n",
        "#f1-macro\n",
        "print('\\033[1m' + \"f1-macro\" + '\\033[0m')\n",
        "print(\"Uniform Classifier: \", precision_recall_fscore_support(test_labels, preds_uniform, average='macro'))\n",
        "print(\"Constant Classifier (1): \", precision_recall_fscore_support(test_labels, preds_constant_1, average='macro'))\n",
        "print(\"Constant Classifier (2): \", precision_recall_fscore_support(test_labels, preds_constant_2, average='macro'))\n",
        "print(\"Most Frequent Classifier: \", precision_recall_fscore_support(test_labels, preds_most_frequent, average='macro'))\n",
        "print(\"Stratified Classifier: \", precision_recall_fscore_support(test_labels, preds_stratified, average='macro'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mf1-micro\u001b[0m\n",
            "Uniform Classifier:  (0.2063768115942029, 0.2063768115942029, 0.20637681159420293, None)\n",
            "Constant Classifier (1):  (0.20318840579710146, 0.20318840579710146, 0.20318840579710148, None)\n",
            "Constant Classifier (2):  (0.20492753623188406, 0.20492753623188406, 0.20492753623188406, None)\n",
            "Most Frequent Classifier:  (0.19014492753623188, 0.19014492753623188, 0.19014492753623188, None)\n",
            "Stratified Classifier:  (0.19942028985507246, 0.19942028985507246, 0.19942028985507246, None) \n",
            "\n",
            "\u001b[1mf1-macro\u001b[0m\n",
            "Uniform Classifier:  (0.20625184325762577, 0.2062501887327116, 0.20624297944388664, None)\n",
            "Constant Classifier (1):  (0.04063768115942029, 0.2, 0.0675499879547097, None)\n",
            "Constant Classifier (2):  (0.04098550724637681, 0.2, 0.0680298292037527, None)\n",
            "Most Frequent Classifier:  (0.03802898550724638, 0.2, 0.06390647832440331, None)\n",
            "Stratified Classifier:  (0.19905351207515368, 0.1992257060726032, 0.1990610737217901, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9DNzplOMs95",
        "colab_type": "text"
      },
      "source": [
        "##### Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1oeCSNONCxB",
        "colab_type": "text"
      },
      "source": [
        "Ο Gaussian Nauve Bayes υποθέτει οτι τα χαρακτηριστικά είναι ανεξάρτητα μεταξύ τους. Έτσι συνδέει κάθε χαρακτηριστικό $x_i$ με κάθε κλάση $y$ με την πιθανότητα $P(x_i \\mid y)$, η οποία υποθέτει πως ακολουθεί γκαουσιανή κατανομή. Χρησιμοποιεί τα δεδομένα προκειμένου για κάθε κλάση και χαρακτηριστικό, το οποίο παίρνει συνεχείς τιμές, να βρει τη μέση τιμή $\\mu_y$ και τη διακύμανση $\\sigma^2_y$ κάθε χαρακτηριστικού για τη κλάση $y$. Στην φάση του testing λαμβάνει υπόψην του τα γινόμενα των παραπάνω πιθανοτήτων των χαρακτηριστικών για κάθε κλάση, καθώς και την πιθανότητα της ίδιας της κλάσης και αναθέτει στο δείγμα την κλάση που μεγιστοποιεί το τελικό γινόμενο.\n",
        "\n",
        "Παρατηρούμε πως η ενσωμάτωση πληροφορίας, ακόμα και όταν έχουμε κάνει τις παραπάνω υποθέσεις υπερδιπλασιάζει την ακρίβεια των προβλέψεών μας.\n",
        "\n",
        "Επίσης, όπως φαίνεται από το confusion matrix υπάρχει αναθέτει πολλά δείγματα στην πέμπτη κλάση. Ωστόσο επιτυγχάνει σε μεγάλο βαθμό να εντοπίσει τις επιληπτικές κρίσεις (πρώτη κλάση)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej7lvLW_O8sm",
        "colab_type": "code",
        "outputId": "5d4bf250-a08e-4cf0-ab36-4d54c8d61e95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "\n",
        "#finding mean values and variations\n",
        "model_GNB = gnb.fit(train, train_labels)\n",
        "\n",
        "#making predictions\n",
        "preds = {}\n",
        "preds[\"Gaussian Naive Bayes\"] = gnb.predict(test)\n",
        "\n",
        "#calculate and print prediction accuracy\n",
        "accuracy = {}\n",
        "accuracy[\"Gaussian Naive Bayes\"] = accuracy_score(test_labels, preds[\"Gaussian Naive Bayes\"])\n",
        "print(\"Gaussian Naive Bayes: \", accuracy[\"Gaussian Naive Bayes\"], \"\\n\")\n",
        "\n",
        "#produce and print confusion matrix\n",
        "cnf_matrix_GNB = confusion_matrix(test_labels, preds[\"Gaussian Naive Bayes\"])\n",
        "print('\\033[1m' + \"Gaussian Naive Bayes - Confusion Matrix\" + '\\033[0m')\n",
        "print(cnf_matrix_GNB, \"\\n\")\n",
        "\n",
        "#f1-micro/macro\n",
        "print('\\033[1m' + \"f1-micro\" + '\\033[0m')\n",
        "print(\"Gaussian Naive Bayes: \", precision_recall_fscore_support(test_labels, preds[\"Gaussian Naive Bayes\"], average='micro'))\n",
        "print('\\033[1m' + \"f1-macro\" + '\\033[0m')\n",
        "print(\"Gaussian Naive Bayes: \", precision_recall_fscore_support(test_labels, preds[\"Gaussian Naive Bayes\"], average='macro'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gaussian Naive Bayes:  0.43130434782608695 \n",
            "\n",
            "\u001b[1mGaussian Naive Bayes - Confusion Matrix\u001b[0m\n",
            "[[578 118   1   4   0]\n",
            " [ 56 110  92 102 347]\n",
            " [  1  95 116 110 363]\n",
            " [  0 153 155 204 189]\n",
            " [  0  31  84  61 480]] \n",
            "\n",
            "\u001b[1mf1-micro\u001b[0m\n",
            "Gaussian Naive Bayes:  (0.43130434782608695, 0.43130434782608695, 0.4313043478260869, None)\n",
            "\u001b[1mf1-macro\u001b[0m\n",
            "Gaussian Naive Bayes:  (0.4316644116587467, 0.43443731708866384, 0.4136353631709154, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTnReOvNU069",
        "colab_type": "text"
      },
      "source": [
        "##### kNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NTWOpQ3U8mN",
        "colab_type": "text"
      },
      "source": [
        "Ο kNN υπολογίζει, για κάθε δείγμα του test set, τους k κοντινότερους γείτονές του, οι οποίοι είναι δείγματα του train set, στον n-διάστατο χώρο διαστάσεων των χαρακτηριστικών εισόδου. Αποφασίζει την κλάση του νέου δείγματα παίρνοντας είτε την πλειοψηφία των γειτόνων είτε λαμβάνοντας υπόψην και τις αποστάσεις του από αυτούς. Ως συνάρτηση απόστασης χρησιμοποιείται κυρίως η ευκλείδια. <br>\n",
        "Εξαιρετικά σημαντική για την απόδοσή του είναι η υπερπαράμετρος k. \n",
        "\n",
        "Το γεγονός οτι πρέπει να συγκρίνουμε την απόσταση κάθε νέου δείγματος στο train set με το νέο δείγμα καθιστά τη διαδικασία πρόβλεψης πολύ χρονοβόρα.\n",
        "Ωστόσο, η μεγάλη διαφορά από τον GNB είναι οτι δεν κάνει υποθέσεις για τις εξαρτήσεις των χαρακτηριστικών και τις κατανομές των πιθανοτήτων.\n",
        "\n",
        "Παρατηρούμε οτι επιτυγχάνει καλύτερες προβλέψεις από τον kNN, ωστόσο το ποσοστό είναι ακόμα χαμηλό."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6CGWaoHypKR",
        "colab_type": "code",
        "outputId": "594c1623-5782-4cbd-a8b4-4c8e64c27c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5) #setting k to 5\n",
        "\n",
        "#saves training samples and their labels\n",
        "knn.fit(train, train_labels)\n",
        "\n",
        "#making predictions\n",
        "preds[\"kNN\"] = knn.predict(test)\n",
        "\n",
        "#calculate and print prediction accuracy\n",
        "accuracy[\"kNN\"] = accuracy_score(test_labels, preds[\"kNN\"])\n",
        "print(\"kNN: \", accuracy[\"kNN\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kNN:  0.45855072463768115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T80Gv0FLXxkP",
        "colab_type": "code",
        "outputId": "16f53374-709b-4f16-b9aa-56c4dd770339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#produce and print confusion matrix\n",
        "cnf_matrix_GNB = confusion_matrix(test_labels, preds[\"kNN\"])\n",
        "print('\\033[1m' + \"kNN - Confusion Matrix\" + '\\033[0m')\n",
        "print(cnf_matrix_GNB, \"\\n\")\n",
        "\n",
        "#f1-micro/macro\n",
        "print('\\033[1m' + \"f1-micro\" + '\\033[0m')\n",
        "print(\"kNN: \", precision_recall_fscore_support(test_labels, preds[\"kNN\"], average='micro'))\n",
        "print('\\033[1m' + \"f1-macro\" + '\\033[0m')\n",
        "print(\"kNN: \", precision_recall_fscore_support(test_labels, preds[\"kNN\"], average='macro'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mkNN - Confusion Matrix\u001b[0m\n",
            "[[456 123  84  27  11]\n",
            " [  4 454 241   3   5]\n",
            " [  0 265 407   0  13]\n",
            " [  0 173 187 208 133]\n",
            " [  0 305 288   6  57]] \n",
            "\n",
            "\u001b[1mf1-micro\u001b[0m\n",
            "kNN:  (0.45855072463768115, 0.45855072463768115, 0.45855072463768115, None)\n",
            "\u001b[1mf1-macro\u001b[0m\n",
            "kNN:  (0.5570352798722996, 0.4540838033503577, 0.4468424535535377, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHUP3bqgYgPZ",
        "colab_type": "text"
      },
      "source": [
        "##### Multi Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpMovT_TYxWN",
        "colab_type": "text"
      },
      "source": [
        "Ένα MLP περιέχει το input layer, το οποίο δέχεται τις εισόδους, 1 ή περισσότερα ενδιάμεσα επίπεδα, τα οποία αποτελούνται από νευρώνες που δέχονται εισόδους από τους νευρώνες του προηγούμενου επιπέδου, εφαρμόζουν βάρη σε αυτές και τις προσθέτουν μαζί με ένα bias. Μετά εφαρμόζουν στο αποτέλεσμα μία μη γραμμική συνάρτηση δημιουργώντας έτσι την έξοδο που προωθείται στο επόμενο επίπεδο. Στο τέλος έχουν ένα output layer, το οποίο κάνει και την τελική απόφαση.\n",
        "\n",
        "Κατά την εκπαίδευσή τους, ελαχιστοποιούν ένα κριτήριο αλλάζοντας τις τιμές των βαρών και των biases τους. \n",
        "\n",
        "Παρατηρούμε οτι δεν αποδίδει καλύτερα ούτε από τους Dummy Classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EI0siWOYybR",
        "colab_type": "code",
        "outputId": "20887ef6-4d4d-452f-c17e-ece3397b1a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,), random_state=1)\n",
        "\n",
        "#training\n",
        "clf.fit(train, train_labels)\n",
        "\n",
        "#predicting\n",
        "preds[\"Multi Layer Perceptron\"] = clf.predict(test)\n",
        "\n",
        "#calculate and print prediction accuracy\n",
        "accuracy[\"Multi Layer Perceptron\"] = accuracy_score(test_labels, preds[\"Multi Layer Perceptron\"])\n",
        "print(\"Multi Layer Perceptron: \", accuracy[\"Multi Layer Perceptron\"])\n",
        "\n",
        "#produce and print confusion matrix\n",
        "cnf_matrix_GNB = confusion_matrix(test_labels, preds[\"Multi Layer Perceptron\"])\n",
        "print('\\033[1m' + \"Multi Layer Perceptron - Confusion Matrix\" + '\\033[0m')\n",
        "print(cnf_matrix_GNB, \"\\n\")\n",
        "\n",
        "#f1-micro/macro\n",
        "print('\\033[1m' + \"f1-micro\" + '\\033[0m')\n",
        "print(\"Multi Layer Perceptron: \", precision_recall_fscore_support(test_labels, preds[\"Multi Layer Perceptron\"], average='micro'))\n",
        "print('\\033[1m' + \"f1-macro\" + '\\033[0m')\n",
        "print(\"Multi Layer Perceptron: \", precision_recall_fscore_support(test_labels, preds[\"Multi Layer Perceptron\"], average='macro'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multi Layer Perceptron:  0.19217391304347825\n",
            "\u001b[1mMulti Layer Perceptron - Confusion Matrix\u001b[0m\n",
            "[[196 271  39 165  30]\n",
            " [200 251  17 221  18]\n",
            " [177 245  11 233  19]\n",
            " [164 304  19 183  31]\n",
            " [189 247  31 167  22]] \n",
            "\n",
            "\u001b[1mf1-micro\u001b[0m\n",
            "Multi Layer Perceptron:  (0.19217391304347825, 0.19217391304347825, 0.19217391304347822, None)\n",
            "\u001b[1mf1-macro\u001b[0m\n",
            "Multi Layer Perceptron:  (0.173661608833437, 0.189054480270924, 0.15842591967535605, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T02fDOdhs5p",
        "colab_type": "text"
      },
      "source": [
        "# Δ. Βελτιστοποίηση Ταξινομητών"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSSO7UFShzfL",
        "colab_type": "text"
      },
      "source": [
        "Χρησιμοποιούμε την διαδικασία pipeline για την εφαρμογή διαδοχικών δεν υπάρχει μεγάλη ανάγκη για εφαρμογή oversampling ή undersampling. Αυτό επιβεβαιώθηκε όταν κάναμε τις ανάλογες δοκιμές. \n",
        "\n",
        "* Λόγω του ισορροπημένου dataset, όπως φαίνεται και παρακάτω, δεν χρειάζεται να χρησιμοποιήσουμε oversampler ή undersampler.\n",
        "\n",
        "* Διαστατικότητα: Χρησιμοποιούμε τον μετασχηματιστή VarianceThreshold, ο οποίος μειώνει τον αριθμό των χαρακτηριστικών με βάση την διακύμανση των τιμών του στα δείγματα (επιλογή χαρακτηριστικών). Όταν η διακύμανση είναι μικρή θεωρούμε οτι το χαρακτηριστικό δεν προσφέρει πολλή πληροφορία για την κατηγοριοποίηση. <br>\n",
        "Επίσης χρησιμοποιούμε τον PCA για την ανάλυση των δεδομένων σε κύριες συνιστώσες και την χρήση των συνιστωσών με την περισσότερη διακύμανση (εξαγωγή χαρακτηριστικών), δηλαδή πληροφορία. \n",
        "\n",
        "* Κανονικοποίηση: Αμβλύνουμε τις διαφορές μεταξύ των τιμών των χαρακτηριστικών. Αν ένα χαρακτηριστικό έχει πολύ μεγαλύτερες τιμές από ένα άλλο η σημασία του σε εκτιμητές όπως ο kNN, που μετρά τις αποστάσεις από τα χαρακτηριστικά, είναι μεγαλύτερη χωρίς αυτό να σημαίνει οτι παρέχει περισσότερη πληροφορία για την κατηγοριοποίηση. Χρησιμοποιούμε δύο μετασχηματιστές κανονικοποίησης, τον scaler και τον min_max_scaler. \n",
        "\n",
        "Η σειρά που ακολουθείται είναι η εξής:\n",
        "0. minmax αν VarianceThreshold για να μην επηρεαστεί η επιλογή από τις τιμές των χαρακτηριστικών\n",
        "1. Κανονικοποίηση (minmax ή z-score)\n",
        "2. PCA\n",
        "3. Εκτιμητής\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkD2OagKoBRj",
        "colab_type": "text"
      },
      "source": [
        "Χρήση grid search για την βελτιστοποίηση των υπερπαραμέτρων. Φτιάχνουμε σύνολο πιθανών συνδυασμών τιμών των παραμέτρων για να βρόυμε τον βέλτιστο. Υπολογίζεται ο μέσος όρος σε όλα τα folds (5 εδώ) του cross-validation με βάση της f1 μετρικές. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sI7f6mNqLbz",
        "colab_type": "code",
        "outputId": "debefc7d-2681-4a44-dfc7-268e0352ca72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"train frequencies:\", np.bincount(train_labels)[1:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train frequencies: [1599 1593 1615 1599 1644]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edhYR-AZqf5x",
        "colab_type": "text"
      },
      "source": [
        "Εκτυπώνουμε την διακύμανση αφού έχουμε εφαρμόσει minmax για να υπολογίσουμε σωστά τα thresholds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptC32mF7pdBB",
        "colab_type": "code",
        "outputId": "1c77d2de-c0d2-4a65-9830-05470f0e36d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler \n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_train_minmax = min_max_scaler.fit_transform(train)\n",
        "train_variance = X_train_minmax.var(axis=0)\n",
        "print(np.max(train_variance))\n",
        "print(np.min(train_variance))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.003971821528023166\n",
            "0.0016382821264597236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH8IBIt_6iFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.decomposition import PCA\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqsotbyW6vHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def GridSearch(data, preprocessing_steps, parameters, classifier, Scoring):\n",
        "  (train, train_labels, test, test_labels) = data\n",
        "  dictionary = {} #dictionary for Gridsearch grid\n",
        "\n",
        "  #checking for sampling condition\n",
        "  if parameters[\"sampling_strategy\"] < 0 or parameters[\"sampling_strategy\"] > 1:\n",
        "    parameters[\"sampling_strategy\"] = 0\n",
        "  if preprocessing_steps[\"sampling\"] == \"Over\":\n",
        "    ros = RandomOverSampler(parameters[\"sampling_strategy\"])\n",
        "  elif preprocessing_steps[\"sampling\"] == \"Under\":\n",
        "    ros = RandomUnderSampler(parameters[\"sampling_strategy\"])\n",
        "  else:\n",
        "    ros = None\n",
        "\n",
        "  #checking for Variance Threshold selector\n",
        "  if preprocessing_steps[\"selector\"] == \"VT\":\n",
        "    preprocessing_steps[\"scaler\"] == None   #no need for a scaler since we will use minmax in the beginning\n",
        "    scaler_minmax = MinMaxScaler()   #minmax is applied before VT\n",
        "    selector = VarianceThreshold()\n",
        "    dictionary[\"selector__threshold\"] = parameters[\"vthreshold\"]\n",
        "  else:\n",
        "    scaler_minmax = None\n",
        "    selector = None\n",
        "\n",
        "  #checking for the use of a scaler\n",
        "  if preprocessing_steps[\"scaler\"] == \"minmax\":\n",
        "    scaler = MinMaxScaler()\n",
        "  elif preprocessing_steps[\"scaler\"] == \"zscore\":\n",
        "    scaler = StandardScaler()\n",
        "  else:\n",
        "    scaler = None\n",
        "\n",
        "  #checking for the use of PCA\n",
        "  if preprocessing_steps[\"extractor\"] == \"PCA\":\n",
        "    pca = PCA()\n",
        "    dictionary[\"pca__n_components\"] = parameters[\"n_components\"]\n",
        "  else:\n",
        "    pca = None\n",
        "  \n",
        "  #creating estimator\n",
        "  if classifier == \"GNB\":\n",
        "    clf = GaussianNB()\n",
        "  elif classifier == \"kNN\":\n",
        "    clf = KNeighborsClassifier()\n",
        "    dictionary[\"kNN__n_neighbors\"] = parameters[\"k\"]\n",
        "    dictionary[\"kNN__weights\"] = parameters[\"weights\"]\n",
        "    dictionary[\"kNN__metric\"] = parameters[\"metrics\"]\n",
        "  elif classifier == \"MLP\":\n",
        "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,), random_state=1)\n",
        "    dictionary[\"MLP__solver\"] = parameters[\"solver\"]\n",
        "    dictionary[\"MLP__max_iter\"] = parameters[\"max_iter\"]\n",
        "    dictionary[\"MLP__alpha\"] = parameters[\"alpha\"]\n",
        "    dictionary[\"MLP__hidden_layer_sizes\"] = parameters[\"hidden_layer_sizes\"]\n",
        "    dictionary[\"MLP__activation\"] = parameters[\"activation\"]\n",
        "    dictionary[\"MLP__learning_rate\"] = parameters[\"learning_rate\"]\n",
        "\n",
        "\n",
        "  #create pipeline, using memory so that transformed data is saved and not recomputed with each fold change\n",
        "  pipe = Pipeline(steps=[('sampler', ros), ('minmax_scaler', scaler_minmax), ('selector', selector), ('scaler', scaler), ('pca', pca), (classifier, clf)], memory = 'tmp')  \n",
        "\n",
        "  #create estimator\n",
        "  estimator = GridSearchCV(pipe, dictionary, cv=5, scoring=Scoring, n_jobs=-1) #number of folds is 5\n",
        "\n",
        "  #fit and predict\n",
        "  start_time = time.time()\n",
        "  estimator.fit(train, train_labels)\n",
        "  preds = estimator.predict(test)\n",
        "  t = time.time() - start_time\n",
        "  print(\"Συνολικός χρόνος fit και predict: %s seconds\" % t)\n",
        "  accuracy = accuracy_score(test_labels, preds)\n",
        "  print(\"Accuracy: \", accuracy)\n",
        "  print(\"Precision_Recall_fscore: \", precision_recall_fscore_support(test_labels, preds, average='micro'))\n",
        "  print(\"Precision_Recall_fscore: \", precision_recall_fscore_support(test_labels, preds, average='macro'))\n",
        "\n",
        "  #print(estimator.best_estimator_)\n",
        "  print(estimator.best_params_, \"\\n\")\n",
        "\n",
        "  return preds, t, precision_recall_fscore_support(test_labels, preds, average='micro')[2], precision_recall_fscore_support(test_labels, preds, average='macro')[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OWvQV2vr1Sl",
        "colab_type": "text"
      },
      "source": [
        "##### Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbDPNvE6iWzP",
        "colab_type": "code",
        "outputId": "c5bbb63a-5b4d-4841-aa98-7a8a4f42188f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "classifier = \"GNB\"\n",
        "\n",
        "#setting up parameters\n",
        "data = (train, train_labels, test, test_labels)\n",
        "vthreshold = [0, 0.0017, 0.002, 0.0023] \n",
        "n_components = [10, 20, 30, 40, 50, 60, 70]\n",
        "\n",
        "preprocessing_steps = {\"sampling\" : None, \"selector\" : None, \"scaler\" : None, \"extractor\" : None}\n",
        "parameters = {\"sampling_strategy\" : 0, \"vthreshold\" : vthreshold, \"n_components\" : n_components}\n",
        "\n",
        "#f1-micro\n",
        "best_GNB_micro = 0\n",
        "for selector in (None, \"VT\"):\n",
        "  for scaler in (None, \"minmax\", \"zscore\"):\n",
        "    for extractor in (None, \"PCA\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-micro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_micro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_micro > best_GNB_micro:\n",
        "        print(\"Best so far:\", f1_micro, \"\\n\")\n",
        "        best_GNB_micro_time = t\n",
        "        best_GNB_micro_preds = preds\n",
        "        best_GNB_micro = f1_micro\n",
        "\n",
        "\n",
        "#f1-macro\n",
        "best_GNB_macro = 0\n",
        "for selector in (None, \"VT\"):\n",
        "  for scaler in (None, \"minmax\", \"zscore\"):\n",
        "    for extractor in (None, \"PCA\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-macro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_macro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_macro > best_GNB_macro:\n",
        "        print(\"Best so far:\", f1_macro, \"\\n\")\n",
        "        best_GNB_macro_time = t\n",
        "        best_GNB_macro_preds = preds\n",
        "        best_GNB_macro = f1_macro\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.354567527770996 seconds\n",
            "Accuracy:  0.43130434782608695\n",
            "Precision_Recall_fscore:  (0.43130434782608695, 0.43130434782608695, 0.4313043478260869, None)\n",
            "Precision_Recall_fscore:  (0.4316644116587467, 0.43443731708866384, 0.4136353631709154, None)\n",
            "{} \n",
            "\n",
            "Best so far: 0.4313043478260869 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.3495450019836426 seconds\n",
            "Accuracy:  0.6495652173913044\n",
            "Precision_Recall_fscore:  (0.6495652173913044, 0.6495652173913044, 0.6495652173913044, None)\n",
            "Precision_Recall_fscore:  (0.6560462131103352, 0.6512415669320786, 0.6414919223518931, None)\n",
            "{'pca__n_components': 50} \n",
            "\n",
            "Best so far: 0.6495652173913044 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 0.41468286514282227 seconds\n",
            "Accuracy:  0.43130434782608695\n",
            "Precision_Recall_fscore:  (0.43130434782608695, 0.43130434782608695, 0.4313043478260869, None)\n",
            "Precision_Recall_fscore:  (0.4316644116587467, 0.43443731708866384, 0.4136353631709154, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.8990659713745117 seconds\n",
            "Accuracy:  0.638840579710145\n",
            "Precision_Recall_fscore:  (0.638840579710145, 0.638840579710145, 0.638840579710145, None)\n",
            "Precision_Recall_fscore:  (0.6435877265874386, 0.6405561240128226, 0.6295900143265658, None)\n",
            "{'pca__n_components': 50} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 0.36335325241088867 seconds\n",
            "Accuracy:  0.43130434782608695\n",
            "Precision_Recall_fscore:  (0.43130434782608695, 0.43130434782608695, 0.4313043478260869, None)\n",
            "Precision_Recall_fscore:  (0.4316644116587467, 0.43443731708866384, 0.4136353631709154, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.8701770305633545 seconds\n",
            "Accuracy:  0.652463768115942\n",
            "Precision_Recall_fscore:  (0.652463768115942, 0.652463768115942, 0.652463768115942, None)\n",
            "Precision_Recall_fscore:  (0.6584646915065246, 0.6541146262737907, 0.6437928939694869, None)\n",
            "{'pca__n_components': 50} \n",
            "\n",
            "Best so far: 0.652463768115942 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.426276445388794 seconds\n",
            "Accuracy:  0.43130434782608695\n",
            "Precision_Recall_fscore:  (0.43130434782608695, 0.43130434782608695, 0.4313043478260869, None)\n",
            "Precision_Recall_fscore:  (0.4316644116587467, 0.43443731708866384, 0.4136353631709154, None)\n",
            "{'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 8.70852541923523 seconds\n",
            "Accuracy:  0.638840579710145\n",
            "Precision_Recall_fscore:  (0.638840579710145, 0.638840579710145, 0.638840579710145, None)\n",
            "Precision_Recall_fscore:  (0.6435877265874386, 0.6405561240128226, 0.6295900143265658, None)\n",
            "{'pca__n_components': 50, 'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.5531957149505615 seconds\n",
            "Accuracy:  0.43130434782608695\n",
            "Precision_Recall_fscore:  (0.43130434782608695, 0.43130434782608695, 0.4313043478260869, None)\n",
            "Precision_Recall_fscore:  (0.4316644116587467, 0.43443731708866384, 0.4136353631709154, None)\n",
            "{'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 10.369499444961548 seconds\n",
            "Accuracy:  0.638840579710145\n",
            "Precision_Recall_fscore:  (0.638840579710145, 0.638840579710145, 0.638840579710145, None)\n",
            "Precision_Recall_fscore:  (0.6435877265874386, 0.6405561240128226, 0.6295900143265658, None)\n",
            "{'pca__n_components': 50, 'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.5450599193572998 seconds\n",
            "Accuracy:  0.43130434782608695\n",
            "Precision_Recall_fscore:  (0.43130434782608695, 0.43130434782608695, 0.4313043478260869, None)\n",
            "Precision_Recall_fscore:  (0.4316644116587467, 0.43443731708866384, 0.4136353631709154, None)\n",
            "{'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 10.422586679458618 seconds\n",
            "Accuracy:  0.652463768115942\n",
            "Precision_Recall_fscore:  (0.652463768115942, 0.652463768115942, 0.652463768115942, None)\n",
            "Precision_Recall_fscore:  (0.6584646915065246, 0.6541146262737907, 0.6437928939694869, None)\n",
            "{'pca__n_components': 50, 'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 0.23821616172790527 seconds\n",
            "Accuracy:  0.43130434782608695\n",
            "Precision_Recall_fscore:  (0.43130434782608695, 0.43130434782608695, 0.4313043478260869, None)\n",
            "Precision_Recall_fscore:  (0.4316644116587467, 0.43443731708866384, 0.4136353631709154, None)\n",
            "{} \n",
            "\n",
            "Best so far: 0.4136353631709154 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.246727466583252 seconds\n",
            "Accuracy:  0.6495652173913044\n",
            "Precision_Recall_fscore:  (0.6495652173913044, 0.6495652173913044, 0.6495652173913044, None)\n",
            "Precision_Recall_fscore:  (0.6560462131103352, 0.6512415669320786, 0.6414919223518931, None)\n",
            "{'pca__n_components': 50} \n",
            "\n",
            "Best so far: 0.6414919223518931 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 0.407757043838501 seconds\n",
            "Accuracy:  0.43130434782608695\n",
            "Precision_Recall_fscore:  (0.43130434782608695, 0.43130434782608695, 0.4313043478260869, None)\n",
            "Precision_Recall_fscore:  (0.4316644116587467, 0.43443731708866384, 0.4136353631709154, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.802894115447998 seconds\n",
            "Accuracy:  0.638840579710145\n",
            "Precision_Recall_fscore:  (0.638840579710145, 0.638840579710145, 0.638840579710145, None)\n",
            "Precision_Recall_fscore:  (0.6435877265874386, 0.6405561240128226, 0.6295900143265658, None)\n",
            "{'pca__n_components': 50} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 0.41364431381225586 seconds\n",
            "Accuracy:  0.43130434782608695\n",
            "Precision_Recall_fscore:  (0.43130434782608695, 0.43130434782608695, 0.4313043478260869, None)\n",
            "Precision_Recall_fscore:  (0.4316644116587467, 0.43443731708866384, 0.4136353631709154, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.7876121997833252 seconds\n",
            "Accuracy:  0.652463768115942\n",
            "Precision_Recall_fscore:  (0.652463768115942, 0.652463768115942, 0.652463768115942, None)\n",
            "Precision_Recall_fscore:  (0.6584646915065246, 0.6541146262737907, 0.6437928939694869, None)\n",
            "{'pca__n_components': 50} \n",
            "\n",
            "Best so far: 0.6437928939694869 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.354238748550415 seconds\n",
            "Accuracy:  0.43130434782608695\n",
            "Precision_Recall_fscore:  (0.43130434782608695, 0.43130434782608695, 0.4313043478260869, None)\n",
            "Precision_Recall_fscore:  (0.4316644116587467, 0.43443731708866384, 0.4136353631709154, None)\n",
            "{'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 8.496694326400757 seconds\n",
            "Accuracy:  0.638840579710145\n",
            "Precision_Recall_fscore:  (0.638840579710145, 0.638840579710145, 0.638840579710145, None)\n",
            "Precision_Recall_fscore:  (0.6435877265874386, 0.6405561240128226, 0.6295900143265658, None)\n",
            "{'pca__n_components': 50, 'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.640578269958496 seconds\n",
            "Accuracy:  0.43130434782608695\n",
            "Precision_Recall_fscore:  (0.43130434782608695, 0.43130434782608695, 0.4313043478260869, None)\n",
            "Precision_Recall_fscore:  (0.4316644116587467, 0.43443731708866384, 0.4136353631709154, None)\n",
            "{'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 10.32491421699524 seconds\n",
            "Accuracy:  0.638840579710145\n",
            "Precision_Recall_fscore:  (0.638840579710145, 0.638840579710145, 0.638840579710145, None)\n",
            "Precision_Recall_fscore:  (0.6435877265874386, 0.6405561240128226, 0.6295900143265658, None)\n",
            "{'pca__n_components': 50, 'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.5656371116638184 seconds\n",
            "Accuracy:  0.43130434782608695\n",
            "Precision_Recall_fscore:  (0.43130434782608695, 0.43130434782608695, 0.4313043478260869, None)\n",
            "Precision_Recall_fscore:  (0.4316644116587467, 0.43443731708866384, 0.4136353631709154, None)\n",
            "{'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 10.462294340133667 seconds\n",
            "Accuracy:  0.652463768115942\n",
            "Precision_Recall_fscore:  (0.652463768115942, 0.652463768115942, 0.652463768115942, None)\n",
            "Precision_Recall_fscore:  (0.6584646915065246, 0.6541146262737907, 0.6437928939694869, None)\n",
            "{'pca__n_components': 50, 'selector__threshold': 0} \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDTTV3ZthFz3",
        "colab_type": "text"
      },
      "source": [
        "##### kNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6yOtJGLfXwm",
        "colab_type": "text"
      },
      "source": [
        "Η αποτελεσματικότητα του kNN, εκτός από το k, εξαρτάται και από την ύπαρξη βαρών στον υπολογισμό των γειτόνων, δηλαδή από το αν οι κοντινοί γείτονες αποκτούν μεγαλύτερη σημασία από τους μακρινότερους. Εφαρμόζουμε 2 περιπτώσεις:\n",
        "* uniform: όλοι οι γείτονες έχουν την ίδια σημασία\n",
        "* distance: η σημασία είναι αντιστρόφως ανάλογη της απόστασης\n",
        "\n",
        "Εκτός αυτού σημασία έχει και ο τρόπος υπολογισμού της απόστασης. Εφαρμόζουμε 2 τρόπους υπολογισμού:\n",
        "* manhattan\n",
        "* euclidean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ_nsn7bVpIo",
        "colab_type": "code",
        "outputId": "665ea9ae-ba9b-43c9-87f0-11616af0efe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "classifier = \"kNN\"\n",
        "\n",
        "#setting up parameters\n",
        "data = (train, train_labels, test, test_labels)\n",
        "vthreshold = [0, 0.0017, 0.002, 0.0023] \n",
        "n_components = [10, 15, 20, 25, 30, 35]\n",
        "k = [1, 2, 3]\n",
        "weights = [\"uniform\", \"distance\"]\n",
        "metrics = [\"euclidean\", \"manhattan\"]\n",
        "\n",
        "preprocessing_steps = {\"sampling\" : None, \"selector\" : None, \"scaler\" : None, \"extractor\" : None}\n",
        "parameters = {\"sampling_strategy\" : 0, \"vthreshold\" : vthreshold, \"n_components\" : n_components, \"k\" : k, \"weights\" : weights, \"metrics\" : metrics}\n",
        "\n",
        "#f1-micro\n",
        "best_kNN_micro = 0\n",
        "for selector in (None, \"VT\"):\n",
        "  for scaler in (None, \"minmax\", \"zscore\"):\n",
        "    for extractor in (None, \"PCA\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-micro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_micro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_micro > best_kNN_micro:\n",
        "        print(\"Best so far:\", f1_micro, \"\\n\")\n",
        "        best_kNN_micro_time = t\n",
        "        best_kNN_micro_preds = preds\n",
        "        best_kNN_micro = f1_micro\n",
        "\n",
        "#f1-macro\n",
        "best_kNN_macro = 0\n",
        "for selector in (None, \"VT\"):\n",
        "  for scaler in (None, \"minmax\", \"zscore\"):\n",
        "    for extractor in (None, \"PCA\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-macro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_macro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_macro > best_kNN_macro:\n",
        "        print(\"Best so far:\", f1_micro, \"\\n\")\n",
        "        best_kNN_macro_time = t\n",
        "        best_kNN_macro_preds = preds\n",
        "        best_kNN_macro = f1_macro"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 141.56341934204102 seconds\n",
            "Accuracy:  0.532463768115942\n",
            "Precision_Recall_fscore:  (0.532463768115942, 0.532463768115942, 0.532463768115942, None)\n",
            "Precision_Recall_fscore:  (0.604010798682817, 0.5288032666697338, 0.5291041512727788, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform'} \n",
            "\n",
            "Best so far: 0.532463768115942 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 148.8557472229004 seconds\n",
            "Accuracy:  0.5646376811594203\n",
            "Precision_Recall_fscore:  (0.5646376811594203, 0.5646376811594203, 0.5646376811594203, None)\n",
            "Precision_Recall_fscore:  (0.6118578747309078, 0.5623405990887819, 0.5702577325514038, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 25} \n",
            "\n",
            "Best so far: 0.5646376811594203 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 142.35431694984436 seconds\n",
            "Accuracy:  0.5321739130434783\n",
            "Precision_Recall_fscore:  (0.5321739130434783, 0.5321739130434783, 0.5321739130434783, None)\n",
            "Precision_Recall_fscore:  (0.6024290407470148, 0.5285173602433164, 0.5284123402761527, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform'} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 152.59211254119873 seconds\n",
            "Accuracy:  0.5617391304347826\n",
            "Precision_Recall_fscore:  (0.5617391304347826, 0.5617391304347826, 0.5617391304347826, None)\n",
            "Precision_Recall_fscore:  (0.6144611749000595, 0.5591232682983994, 0.5649025124545896, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 30} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 141.75564074516296 seconds\n",
            "Accuracy:  0.5353623188405797\n",
            "Precision_Recall_fscore:  (0.5353623188405797, 0.5353623188405797, 0.5353623188405797, None)\n",
            "Precision_Recall_fscore:  (0.6092685194151466, 0.5315830510229442, 0.5320451140999946, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform'} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 154.91746020317078 seconds\n",
            "Accuracy:  0.5608695652173913\n",
            "Precision_Recall_fscore:  (0.5608695652173913, 0.5608695652173913, 0.5608695652173913, None)\n",
            "Precision_Recall_fscore:  (0.6135277361632832, 0.5585775731245005, 0.5637698236335847, None)\n",
            "{'kNN__metric': 'manhattan', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 30} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 491.39270782470703 seconds\n",
            "Accuracy:  0.5371014492753623\n",
            "Precision_Recall_fscore:  (0.5371014492753623, 0.5371014492753623, 0.5371014492753623, None)\n",
            "Precision_Recall_fscore:  (0.6018065504169484, 0.533500193057607, 0.5328505337561329, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'selector__threshold': 0.002} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 613.7273440361023 seconds\n",
            "Accuracy:  0.5602898550724638\n",
            "Precision_Recall_fscore:  (0.5602898550724638, 0.5602898550724638, 0.5602898550724638, None)\n",
            "Precision_Recall_fscore:  (0.6050080086985128, 0.5577553219905382, 0.5650625753563421, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 25, 'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 504.46527886390686 seconds\n",
            "Accuracy:  0.5371014492753623\n",
            "Precision_Recall_fscore:  (0.5371014492753623, 0.5371014492753623, 0.5371014492753623, None)\n",
            "Precision_Recall_fscore:  (0.6018065504169484, 0.533500193057607, 0.5328505337561329, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'selector__threshold': 0.002} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 634.3140950202942 seconds\n",
            "Accuracy:  0.56\n",
            "Precision_Recall_fscore:  (0.56, 0.56, 0.56, None)\n",
            "Precision_Recall_fscore:  (0.6019550663793493, 0.5576071934654873, 0.5646143414750173, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 25, 'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 501.6430616378784 seconds\n",
            "Accuracy:  0.5315942028985507\n",
            "Precision_Recall_fscore:  (0.5315942028985507, 0.5315942028985507, 0.5315942028985507, None)\n",
            "Precision_Recall_fscore:  (0.6018150631120458, 0.5279854685714835, 0.5283806884740961, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'selector__threshold': 0.002} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 640.5545461177826 seconds\n",
            "Accuracy:  0.5530434782608695\n",
            "Precision_Recall_fscore:  (0.5530434782608695, 0.5530434782608695, 0.5530434782608695, None)\n",
            "Precision_Recall_fscore:  (0.586351211857205, 0.5511069238385783, 0.5587906911704835, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 20, 'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 146.82562279701233 seconds\n",
            "Accuracy:  0.532463768115942\n",
            "Precision_Recall_fscore:  (0.532463768115942, 0.532463768115942, 0.532463768115942, None)\n",
            "Precision_Recall_fscore:  (0.604010798682817, 0.5288032666697338, 0.5291041512727788, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform'} \n",
            "\n",
            "Best so far: 0.532463768115942 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 148.71218848228455 seconds\n",
            "Accuracy:  0.5646376811594203\n",
            "Precision_Recall_fscore:  (0.5646376811594203, 0.5646376811594203, 0.5646376811594203, None)\n",
            "Precision_Recall_fscore:  (0.6118578747309078, 0.5623405990887819, 0.5702577325514038, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 25} \n",
            "\n",
            "Best so far: 0.5646376811594203 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 148.7602653503418 seconds\n",
            "Accuracy:  0.5321739130434783\n",
            "Precision_Recall_fscore:  (0.5321739130434783, 0.5321739130434783, 0.5321739130434783, None)\n",
            "Precision_Recall_fscore:  (0.6024290407470148, 0.5285173602433164, 0.5284123402761527, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform'} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 151.65905094146729 seconds\n",
            "Accuracy:  0.5643478260869565\n",
            "Precision_Recall_fscore:  (0.5643478260869565, 0.5643478260869565, 0.5643478260869565, None)\n",
            "Precision_Recall_fscore:  (0.6076986238817612, 0.561948551449805, 0.5689667992836894, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 25} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 144.43978691101074 seconds\n",
            "Accuracy:  0.5353623188405797\n",
            "Precision_Recall_fscore:  (0.5353623188405797, 0.5353623188405797, 0.5353623188405797, None)\n",
            "Precision_Recall_fscore:  (0.6092685194151466, 0.5315830510229442, 0.5320451140999946, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform'} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 153.44919276237488 seconds\n",
            "Accuracy:  0.5588405797101449\n",
            "Precision_Recall_fscore:  (0.5588405797101449, 0.5588405797101449, 0.5588405797101449, None)\n",
            "Precision_Recall_fscore:  (0.6035022393696553, 0.556413115833326, 0.5639917057848033, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 25} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 491.7919023036957 seconds\n",
            "Accuracy:  0.5371014492753623\n",
            "Precision_Recall_fscore:  (0.5371014492753623, 0.5371014492753623, 0.5371014492753623, None)\n",
            "Precision_Recall_fscore:  (0.6018065504169484, 0.533500193057607, 0.5328505337561329, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'selector__threshold': 0.002} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 613.6838512420654 seconds\n",
            "Accuracy:  0.5602898550724638\n",
            "Precision_Recall_fscore:  (0.5602898550724638, 0.5602898550724638, 0.5602898550724638, None)\n",
            "Precision_Recall_fscore:  (0.6050080086985128, 0.5577553219905382, 0.5650625753563421, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 25, 'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 499.72370433807373 seconds\n",
            "Accuracy:  0.5371014492753623\n",
            "Precision_Recall_fscore:  (0.5371014492753623, 0.5371014492753623, 0.5371014492753623, None)\n",
            "Precision_Recall_fscore:  (0.6018065504169484, 0.533500193057607, 0.5328505337561329, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'selector__threshold': 0.002} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 630.5207135677338 seconds\n",
            "Accuracy:  0.56\n",
            "Precision_Recall_fscore:  (0.56, 0.56, 0.56, None)\n",
            "Precision_Recall_fscore:  (0.6019550663793493, 0.5576071934654873, 0.5646143414750173, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 25, 'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 502.67240023612976 seconds\n",
            "Accuracy:  0.5315942028985507\n",
            "Precision_Recall_fscore:  (0.5315942028985507, 0.5315942028985507, 0.5315942028985507, None)\n",
            "Precision_Recall_fscore:  (0.6018150631120458, 0.5279854685714835, 0.5283806884740961, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'selector__threshold': 0.002} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 636.6770257949829 seconds\n",
            "Accuracy:  0.5530434782608695\n",
            "Precision_Recall_fscore:  (0.5530434782608695, 0.5530434782608695, 0.5530434782608695, None)\n",
            "Precision_Recall_fscore:  (0.586351211857205, 0.5511069238385783, 0.5587906911704835, None)\n",
            "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 20, 'selector__threshold': 0} \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkBFYLyIhOs_",
        "colab_type": "text"
      },
      "source": [
        "##### Multi Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VarcbdPXvDT7",
        "colab_type": "text"
      },
      "source": [
        "Οι παράμετροι που εξετάζουμε είναι οι παρακάτω:\n",
        "* Ο αριθμός των νευρώνων στον κρυμμένο επίπεδο.\n",
        "* Η μη γραμμική συνάρτηση που εφαρμόζεται. Μπορεί να εφαρμοστεί η σιγμοειδής, η υπερβολική εφαπτομένη ή η relu.\n",
        "* Ο τρόπος ενημέρωσης των βαρών. Εφαρμόσαμε μία quasi-Newton method και την stochastic gradient descent.\n",
        "* alpha: Η παράμετρος για την F2 κανονικοποίηση, η οποία βοηθά στην αποφυγή του overfitting, φροντίζοντας τα βάρη να μη μαθαίνουν τις ιδιομορφίες του dataset.\n",
        "* Μέγιστος αριθμός επαναλήψεων που επιτρέπουμε στον αλγόρθμο.\n",
        "* Το learing rate, το οποίο αφορά την \"ώθηση\" που δίνουμε σε κάθε ενημέρωση των παραμέτρων."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI9d2ybbhQcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "85f5d534-4d9f-4bca-ff20-51c1dfbc0fe0"
      },
      "source": [
        "classifier = \"MLP\"\n",
        "\n",
        "#setting up parameters\n",
        "data = (train.iloc[1:1000, :], train_labels[1:1000], test, test_labels)\n",
        "vthreshold = [0.0017, 0.002, 0.0023] \n",
        "n_components = [20, 30, 40, 50]\n",
        "\n",
        "hidden_layer_sizes = [(5, ), (10, ), (15, )]\n",
        "activation = [\"tanh\", \"relu\"]\n",
        "solver = [\"lbfgs\", \"sgd\"]\n",
        "max_iter = [40, 80, 120]\n",
        "alpha = [0.00001, 0.0001, 0.001]\n",
        "learning_rate = [\"constant\", \"invscaling\"]\n",
        "\n",
        "preprocessing_steps = {\"sampling\" : None, \"selector\" : None, \"scaler\" : None, \"extractor\" : None}\n",
        "parameters = {\"sampling_strategy\" : 0, \"vthreshold\" : vthreshold, \"n_components\" : n_components, \"solver\": solver, \"max_iter\": max_iter, \"alpha\": alpha, \"hidden_layer_sizes\": hidden_layer_sizes, \"activation\": activation, \"learning_rate\" : learning_rate}\n",
        "\n",
        "#f1-micro\n",
        "best_MLP_micro = 0\n",
        "for scaler in (None, \"minmax\", \"zscore\"):\n",
        "  for extractor in (None, \"PCA\"):\n",
        "    for selector in (None, \"VT\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-micro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_micro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_micro > best_MLP_micro:\n",
        "        print(\"Best so far:\", f1_micro, \"\\n\")\n",
        "        best_MLP_micro_time = t\n",
        "        best_MLP_micro_preds = preds\n",
        "        best_MLP_micro = f1_micro\n",
        "\n",
        "#f1-macro\n",
        "best_MLP_macro = 0\n",
        "for scaler in (None, \"minmax\", \"zscore\"):\n",
        "  for extractor in (None, \"PCA\"):\n",
        "    for selector in (None, \"VT\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-macro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_macro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_macro > best_MLP_macro:\n",
        "        print(\"Best so far:\", f1_macro, \"\\n\")\n",
        "        best_MLP_macro_time = t\n",
        "        best_MLP_macro_preds = preds\n",
        "        best_MLP_macro = f1_macro"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.264472484588623 seconds\n",
            "Accuracy:  0.2072463768115942\n",
            "Precision_Recall_fscore:  (0.2072463768115942, 0.2072463768115942, 0.2072463768115942, None)\n",
            "Precision_Recall_fscore:  (0.20669457180298415, 0.20464242468294747, 0.15687703244186774, None)\n",
            "{} \n",
            "\n",
            "Best so far: 0.2072463768115942 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 3.3253095149993896 seconds\n",
            "Accuracy:  0.263768115942029\n",
            "Precision_Recall_fscore:  (0.263768115942029, 0.263768115942029, 0.263768115942029, None)\n",
            "Precision_Recall_fscore:  (0.2322638302011136, 0.26646069992908916, 0.2322121667402866, None)\n",
            "{'selector__threshold': 0.0017} \n",
            "\n",
            "Best so far: 0.263768115942029 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 0.3351709842681885 seconds\n",
            "Accuracy:  0.20579710144927535\n",
            "Precision_Recall_fscore:  (0.20579710144927535, 0.20579710144927535, 0.20579710144927535, None)\n",
            "Precision_Recall_fscore:  (0.2060965203421145, 0.20495274548140435, 0.18083104184051677, None)\n",
            "{'pca__n_components': 30} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 7.92978835105896 seconds\n",
            "Accuracy:  0.4420289855072464\n",
            "Precision_Recall_fscore:  (0.4420289855072464, 0.4420289855072464, 0.4420289855072464, None)\n",
            "Precision_Recall_fscore:  (0.4725259782779296, 0.44148172513455763, 0.42207034168858903, None)\n",
            "{'pca__n_components': 40, 'selector__threshold': 0.0017} \n",
            "\n",
            "Best so far: 0.4420289855072464 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.3206782341003418 seconds\n",
            "Accuracy:  0.263768115942029\n",
            "Precision_Recall_fscore:  (0.263768115942029, 0.263768115942029, 0.263768115942029, None)\n",
            "Precision_Recall_fscore:  (0.2322638302011136, 0.26646069992908916, 0.2322121667402866, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 3.2970759868621826 seconds\n",
            "Accuracy:  0.26492753623188403\n",
            "Precision_Recall_fscore:  (0.26492753623188403, 0.26492753623188403, 0.26492753623188403, None)\n",
            "Precision_Recall_fscore:  (0.22748584923634135, 0.2624068991325671, 0.2388451115715295, None)\n",
            "{'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 2.716512680053711 seconds\n",
            "Accuracy:  0.4420289855072464\n",
            "Precision_Recall_fscore:  (0.4420289855072464, 0.4420289855072464, 0.4420289855072464, None)\n",
            "Precision_Recall_fscore:  (0.4725259782779296, 0.44148172513455763, 0.42207034168858903, None)\n",
            "{'pca__n_components': 40} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 8.264225959777832 seconds\n",
            "Accuracy:  0.44173913043478263\n",
            "Precision_Recall_fscore:  (0.44173913043478263, 0.44173913043478263, 0.44173913043478263, None)\n",
            "Precision_Recall_fscore:  (0.45261391816873786, 0.44157346635360967, 0.4247070330473077, None)\n",
            "{'pca__n_components': 40, 'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.3863716125488281 seconds\n",
            "Accuracy:  0.4252173913043478\n",
            "Precision_Recall_fscore:  (0.4252173913043478, 0.4252173913043478, 0.4252173913043478, None)\n",
            "Precision_Recall_fscore:  (0.4334679603501154, 0.42726396282954787, 0.3984135983338845, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 3.410987615585327 seconds\n",
            "Accuracy:  0.4252173913043478\n",
            "Precision_Recall_fscore:  (0.4252173913043478, 0.4252173913043478, 0.4252173913043478, None)\n",
            "Precision_Recall_fscore:  (0.4334679603501154, 0.42726396282954787, 0.3984135983338845, None)\n",
            "{'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 2.7743351459503174 seconds\n",
            "Accuracy:  0.46115942028985507\n",
            "Precision_Recall_fscore:  (0.46115942028985507, 0.46115942028985507, 0.46115942028985507, None)\n",
            "Precision_Recall_fscore:  (0.46345262226408074, 0.46110985902358886, 0.4439463829173791, None)\n",
            "{'pca__n_components': 40} \n",
            "\n",
            "Best so far: 0.46115942028985507 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 8.282499551773071 seconds\n",
            "Accuracy:  0.44028985507246376\n",
            "Precision_Recall_fscore:  (0.44028985507246376, 0.44028985507246376, 0.44028985507246376, None)\n",
            "Precision_Recall_fscore:  (0.44822042973389564, 0.44352959246099666, 0.4047838078153852, None)\n",
            "{'pca__n_components': 30, 'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 0.10782647132873535 seconds\n",
            "Accuracy:  0.2072463768115942\n",
            "Precision_Recall_fscore:  (0.2072463768115942, 0.2072463768115942, 0.2072463768115942, None)\n",
            "Precision_Recall_fscore:  (0.20669457180298415, 0.20464242468294747, 0.15687703244186774, None)\n",
            "{} \n",
            "\n",
            "Best so far: 0.15687703244186774 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 3.319530487060547 seconds\n",
            "Accuracy:  0.263768115942029\n",
            "Precision_Recall_fscore:  (0.263768115942029, 0.263768115942029, 0.263768115942029, None)\n",
            "Precision_Recall_fscore:  (0.2322638302011136, 0.26646069992908916, 0.2322121667402866, None)\n",
            "{'selector__threshold': 0.0017} \n",
            "\n",
            "Best so far: 0.2322121667402866 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 0.3242967128753662 seconds\n",
            "Accuracy:  0.20579710144927535\n",
            "Precision_Recall_fscore:  (0.20579710144927535, 0.20579710144927535, 0.20579710144927535, None)\n",
            "Precision_Recall_fscore:  (0.2060965203421145, 0.20495274548140435, 0.18083104184051677, None)\n",
            "{'pca__n_components': 30} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 8.112226963043213 seconds\n",
            "Accuracy:  0.4420289855072464\n",
            "Precision_Recall_fscore:  (0.4420289855072464, 0.4420289855072464, 0.4420289855072464, None)\n",
            "Precision_Recall_fscore:  (0.4725259782779296, 0.44148172513455763, 0.42207034168858903, None)\n",
            "{'pca__n_components': 40, 'selector__threshold': 0.0017} \n",
            "\n",
            "Best so far: 0.42207034168858903 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.3667676448822021 seconds\n",
            "Accuracy:  0.263768115942029\n",
            "Precision_Recall_fscore:  (0.263768115942029, 0.263768115942029, 0.263768115942029, None)\n",
            "Precision_Recall_fscore:  (0.2322638302011136, 0.26646069992908916, 0.2322121667402866, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 3.284442663192749 seconds\n",
            "Accuracy:  0.26492753623188403\n",
            "Precision_Recall_fscore:  (0.26492753623188403, 0.26492753623188403, 0.26492753623188403, None)\n",
            "Precision_Recall_fscore:  (0.22748584923634135, 0.2624068991325671, 0.2388451115715295, None)\n",
            "{'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 2.7495789527893066 seconds\n",
            "Accuracy:  0.4420289855072464\n",
            "Precision_Recall_fscore:  (0.4420289855072464, 0.4420289855072464, 0.4420289855072464, None)\n",
            "Precision_Recall_fscore:  (0.4725259782779296, 0.44148172513455763, 0.42207034168858903, None)\n",
            "{'pca__n_components': 40} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 8.21409559249878 seconds\n",
            "Accuracy:  0.44173913043478263\n",
            "Precision_Recall_fscore:  (0.44173913043478263, 0.44173913043478263, 0.44173913043478263, None)\n",
            "Precision_Recall_fscore:  (0.45261391816873786, 0.44157346635360967, 0.4247070330473077, None)\n",
            "{'pca__n_components': 40, 'selector__threshold': 0.0017} \n",
            "\n",
            "Best so far: 0.4247070330473077 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.4100892543792725 seconds\n",
            "Accuracy:  0.4252173913043478\n",
            "Precision_Recall_fscore:  (0.4252173913043478, 0.4252173913043478, 0.4252173913043478, None)\n",
            "Precision_Recall_fscore:  (0.4334679603501154, 0.42726396282954787, 0.3984135983338845, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 3.4662716388702393 seconds\n",
            "Accuracy:  0.4252173913043478\n",
            "Precision_Recall_fscore:  (0.4252173913043478, 0.4252173913043478, 0.4252173913043478, None)\n",
            "Precision_Recall_fscore:  (0.4334679603501154, 0.42726396282954787, 0.3984135983338845, None)\n",
            "{'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 2.901143789291382 seconds\n",
            "Accuracy:  0.46115942028985507\n",
            "Precision_Recall_fscore:  (0.46115942028985507, 0.46115942028985507, 0.46115942028985507, None)\n",
            "Precision_Recall_fscore:  (0.46345262226408074, 0.46110985902358886, 0.4439463829173791, None)\n",
            "{'pca__n_components': 40} \n",
            "\n",
            "Best so far: 0.4439463829173791 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 8.39951467514038 seconds\n",
            "Accuracy:  0.44028985507246376\n",
            "Precision_Recall_fscore:  (0.44028985507246376, 0.44028985507246376, 0.44028985507246376, None)\n",
            "Precision_Recall_fscore:  (0.44822042973389564, 0.44352959246099666, 0.4047838078153852, None)\n",
            "{'pca__n_components': 30, 'selector__threshold': 0.0017} \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRRNeK8JXU9a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b780d413-8cd5-4f41-d362-a13b0c672672"
      },
      "source": [
        "classifier = \"MLP\"\n",
        "\n",
        "#setting up parameters\n",
        "data = (train, train_labels, test, test_labels)\n",
        "vthreshold = [0.0017, 0.002, 0.0023] \n",
        "n_components = [20, 30, 40, 50]\n",
        "\n",
        "hidden_layer_sizes = [(5, ), (10, ), (15, )]\n",
        "activation = [\"tanh\", \"relu\"]\n",
        "solver = [\"lbfgs\", \"sgd\"]\n",
        "max_iter = [40, 80, 120]\n",
        "alpha = [0.00001, 0.0001, 0.001]\n",
        "learning_rate = [\"constant\", \"invscaling\"]\n",
        "\n",
        "preprocessing_steps = {\"sampling\" : None, \"selector\" : None, \"scaler\" : None, \"extractor\" : None}\n",
        "parameters = {\"sampling_strategy\" : 0, \"vthreshold\" : vthreshold, \"n_components\" : n_components, \"solver\": solver, \"max_iter\": max_iter, \"alpha\": alpha, \"hidden_layer_sizes\": hidden_layer_sizes, \"activation\": activation, \"learning_rate\" : learning_rate}\n",
        "\n",
        "#f1-micro\n",
        "best_MLP_micro_ = 0\n",
        "for scaler in (None, \"minmax\", \"zscore\"):\n",
        "  for extractor in (None, \"PCA\"):\n",
        "    for selector in (None, \"VT\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-micro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_micro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_micro > best_MLP_micro_:\n",
        "        print(\"Best so far:\", f1_micro, \"\\n\")\n",
        "        best_MLP_micro_time_ = t\n",
        "        best_MLP_micro_preds_ = preds\n",
        "        best_MLP_micro_ = f1_micro\n",
        "\n",
        "#f1-macro\n",
        "best_MLP_macro_ = 0\n",
        "for scaler in (None, \"minmax\", \"zscore\"):\n",
        "  for extractor in (None, \"PCA\"):\n",
        "    for selector in (None, \"VT\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-macro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_macro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_macro > best_MLP_macro_:\n",
        "        print(\"Best so far:\", f1_macro, \"\\n\")\n",
        "        best_MLP_macro_time_ = t\n",
        "        best_MLP_macro_preds_ = preds\n",
        "        best_MLP_macro_ = f1_macro"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.438046932220459 seconds\n",
            "Accuracy:  0.19217391304347825\n",
            "Precision_Recall_fscore:  (0.19217391304347825, 0.19217391304347825, 0.19217391304347822, None)\n",
            "Precision_Recall_fscore:  (0.173661608833437, 0.189054480270924, 0.15842591967535605, None)\n",
            "{} \n",
            "\n",
            "Best so far: 0.19217391304347822 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 13.919405221939087 seconds\n",
            "Accuracy:  0.3492753623188406\n",
            "Precision_Recall_fscore:  (0.3492753623188406, 0.3492753623188406, 0.3492753623188406, None)\n",
            "Precision_Recall_fscore:  (0.3009665579121359, 0.35283085632776556, 0.30048866090997445, None)\n",
            "{'selector__threshold': 0.0023} \n",
            "\n",
            "Best so far: 0.3492753623188406 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.415391206741333 seconds\n",
            "Accuracy:  0.19710144927536233\n",
            "Precision_Recall_fscore:  (0.19710144927536233, 0.19710144927536233, 0.1971014492753623, None)\n",
            "Precision_Recall_fscore:  (0.20363859114858923, 0.19542508693145827, 0.1598770712019094, None)\n",
            "{'pca__n_components': 20} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 36.2814998626709 seconds\n",
            "Accuracy:  0.423768115942029\n",
            "Precision_Recall_fscore:  (0.423768115942029, 0.423768115942029, 0.423768115942029, None)\n",
            "Precision_Recall_fscore:  (0.423307036465015, 0.42512396932354923, 0.40645434598953933, None)\n",
            "{'pca__n_components': 40, 'selector__threshold': 0.0017} \n",
            "\n",
            "Best so far: 0.423768115942029 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 7.074357748031616 seconds\n",
            "Accuracy:  0.2591304347826087\n",
            "Precision_Recall_fscore:  (0.2591304347826087, 0.2591304347826087, 0.2591304347826087, None)\n",
            "Precision_Recall_fscore:  (0.15591989008270438, 0.261855450401865, 0.19370734617580299, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 13.971986293792725 seconds\n",
            "Accuracy:  0.34608695652173915\n",
            "Precision_Recall_fscore:  (0.34608695652173915, 0.34608695652173915, 0.34608695652173915, None)\n",
            "Precision_Recall_fscore:  (0.2986744773655693, 0.3500797155571357, 0.3028553574978619, None)\n",
            "{'selector__threshold': 0.0023} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 13.668610334396362 seconds\n",
            "Accuracy:  0.43478260869565216\n",
            "Precision_Recall_fscore:  (0.43478260869565216, 0.43478260869565216, 0.43478260869565216, None)\n",
            "Precision_Recall_fscore:  (0.4378275961702016, 0.43644551351478345, 0.42186578542943864, None)\n",
            "{'pca__n_components': 40} \n",
            "\n",
            "Best so far: 0.43478260869565216 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 37.72758078575134 seconds\n",
            "Accuracy:  0.4226086956521739\n",
            "Precision_Recall_fscore:  (0.4226086956521739, 0.4226086956521739, 0.4226086956521739, None)\n",
            "Precision_Recall_fscore:  (0.41972339230559486, 0.42445103177496657, 0.40240304424691065, None)\n",
            "{'pca__n_components': 40, 'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 7.477983474731445 seconds\n",
            "Accuracy:  0.5063768115942029\n",
            "Precision_Recall_fscore:  (0.5063768115942029, 0.5063768115942029, 0.5063768115942029, None)\n",
            "Precision_Recall_fscore:  (0.5173837490256248, 0.5065868514340074, 0.5004418596634751, None)\n",
            "{} \n",
            "\n",
            "Best so far: 0.5063768115942029 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 16.736778497695923 seconds\n",
            "Accuracy:  0.4936231884057971\n",
            "Precision_Recall_fscore:  (0.4936231884057971, 0.4936231884057971, 0.4936231884057971, None)\n",
            "Precision_Recall_fscore:  (0.5069968337217918, 0.49305795494899146, 0.49374958851607, None)\n",
            "{'selector__threshold': 0.0023} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 13.491577386856079 seconds\n",
            "Accuracy:  0.524927536231884\n",
            "Precision_Recall_fscore:  (0.524927536231884, 0.524927536231884, 0.524927536231884, None)\n",
            "Precision_Recall_fscore:  (0.5324474457299717, 0.5255574298189087, 0.5200537561513122, None)\n",
            "{'pca__n_components': 30} \n",
            "\n",
            "Best so far: 0.524927536231884 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 38.72675371170044 seconds\n",
            "Accuracy:  0.4927536231884058\n",
            "Precision_Recall_fscore:  (0.4927536231884058, 0.4927536231884058, 0.4927536231884058, None)\n",
            "Precision_Recall_fscore:  (0.5022562173952909, 0.4927640640959884, 0.4925484809889527, None)\n",
            "{'pca__n_components': 30, 'selector__threshold': 0.002} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 0.32022881507873535 seconds\n",
            "Accuracy:  0.19217391304347825\n",
            "Precision_Recall_fscore:  (0.19217391304347825, 0.19217391304347825, 0.19217391304347822, None)\n",
            "Precision_Recall_fscore:  (0.173661608833437, 0.189054480270924, 0.15842591967535605, None)\n",
            "{} \n",
            "\n",
            "Best so far: 0.15842591967535605 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 12.627766609191895 seconds\n",
            "Accuracy:  0.19014492753623188\n",
            "Precision_Recall_fscore:  (0.19014492753623188, 0.19014492753623188, 0.19014492753623188, None)\n",
            "Precision_Recall_fscore:  (0.03802898550724638, 0.2, 0.06390647832440331, None)\n",
            "{'selector__threshold': 0.002} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.460355281829834 seconds\n",
            "Accuracy:  0.22086956521739132\n",
            "Precision_Recall_fscore:  (0.22086956521739132, 0.22086956521739132, 0.22086956521739132, None)\n",
            "Precision_Recall_fscore:  (0.22359815496792854, 0.218542930273688, 0.2051731991842965, None)\n",
            "{'pca__n_components': 40} \n",
            "\n",
            "Best so far: 0.2051731991842965 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 35.87826633453369 seconds\n",
            "Accuracy:  0.423768115942029\n",
            "Precision_Recall_fscore:  (0.423768115942029, 0.423768115942029, 0.423768115942029, None)\n",
            "Precision_Recall_fscore:  (0.423307036465015, 0.42512396932354923, 0.40645434598953933, None)\n",
            "{'pca__n_components': 40, 'selector__threshold': 0.0017} \n",
            "\n",
            "Best so far: 0.40645434598953933 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 7.088186502456665 seconds\n",
            "Accuracy:  0.2591304347826087\n",
            "Precision_Recall_fscore:  (0.2591304347826087, 0.2591304347826087, 0.2591304347826087, None)\n",
            "Precision_Recall_fscore:  (0.15591989008270438, 0.261855450401865, 0.19370734617580299, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 12.765308141708374 seconds\n",
            "Accuracy:  0.19014492753623188\n",
            "Precision_Recall_fscore:  (0.19014492753623188, 0.19014492753623188, 0.19014492753623188, None)\n",
            "Precision_Recall_fscore:  (0.03802898550724638, 0.2, 0.06390647832440331, None)\n",
            "{'selector__threshold': 0.002} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 12.711086750030518 seconds\n",
            "Accuracy:  0.43478260869565216\n",
            "Precision_Recall_fscore:  (0.43478260869565216, 0.43478260869565216, 0.43478260869565216, None)\n",
            "Precision_Recall_fscore:  (0.4378275961702016, 0.43644551351478345, 0.42186578542943864, None)\n",
            "{'pca__n_components': 40} \n",
            "\n",
            "Best so far: 0.42186578542943864 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 36.79632830619812 seconds\n",
            "Accuracy:  0.4226086956521739\n",
            "Precision_Recall_fscore:  (0.4226086956521739, 0.4226086956521739, 0.4226086956521739, None)\n",
            "Precision_Recall_fscore:  (0.41972339230559486, 0.42445103177496657, 0.40240304424691065, None)\n",
            "{'pca__n_components': 40, 'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 7.597143173217773 seconds\n",
            "Accuracy:  0.5063768115942029\n",
            "Precision_Recall_fscore:  (0.5063768115942029, 0.5063768115942029, 0.5063768115942029, None)\n",
            "Precision_Recall_fscore:  (0.5173837490256248, 0.5065868514340074, 0.5004418596634751, None)\n",
            "{} \n",
            "\n",
            "Best so far: 0.5004418596634751 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 16.420273542404175 seconds\n",
            "Accuracy:  0.4936231884057971\n",
            "Precision_Recall_fscore:  (0.4936231884057971, 0.4936231884057971, 0.4936231884057971, None)\n",
            "Precision_Recall_fscore:  (0.5069968337217918, 0.49305795494899146, 0.49374958851607, None)\n",
            "{'selector__threshold': 0.0023} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 12.940834760665894 seconds\n",
            "Accuracy:  0.524927536231884\n",
            "Precision_Recall_fscore:  (0.524927536231884, 0.524927536231884, 0.524927536231884, None)\n",
            "Precision_Recall_fscore:  (0.5324474457299717, 0.5255574298189087, 0.5200537561513122, None)\n",
            "{'pca__n_components': 30} \n",
            "\n",
            "Best so far: 0.5200537561513122 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 37.579594135284424 seconds\n",
            "Accuracy:  0.4927536231884058\n",
            "Precision_Recall_fscore:  (0.4927536231884058, 0.4927536231884058, 0.4927536231884058, None)\n",
            "Precision_Recall_fscore:  (0.5022562173952909, 0.4927640640959884, 0.4925484809889527, None)\n",
            "{'pca__n_components': 30, 'selector__threshold': 0.002} \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}