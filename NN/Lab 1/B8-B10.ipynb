{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Lab 1 Big - NN .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgeaidinis/NTUA/blob/master/NN/Lab%201/B8-B10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNutqQMbsGh5",
        "colab_type": "text"
      },
      "source": [
        "Αϊδίνης Γιώργος 03116031\n",
        "\n",
        "Κολιός Παναγιώτης 03116100\n",
        "\n",
        "---\n",
        "\n",
        "Ομάδα M.B.8\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Lab 1: Επιβλεπόμενη Μάθηση - Ταξινόμηση - Μεγάλο Dataset (B10 - Epileptic Seizure Recognition)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbhZAASZwUlT",
        "colab_type": "code",
        "outputId": "16f607ae-e1f0-4c4f-c93a-a21d03c844bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install --upgrade pip #upgrade pip package installer\n",
        "!pip install scikit-learn --upgrade #upgrade scikit-learn package\n",
        "!pip install numpy --upgrade #upgrade numpy package\n",
        "!pip install pandas --upgrade #--upgrade #upgrade pandas package"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n",
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.4)\n",
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTTsqj4VMGvH",
        "colab_type": "text"
      },
      "source": [
        "# Β. Εισαγωγή του Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZREGY83HPNia",
        "colab_type": "text"
      },
      "source": [
        "Multiclass Classification: Το συγκεκριμένο dataset χρησιμοποιείται και για multiclass και για binary (1 vs 2-5) classification. Λόγω του παραπάνω, και καθώς στο small dataset κάναμε binary classification επιλέξαμε να κάνουμε multiclass σε αυτό.\n",
        "\n",
        "1. Έγινε καταγραφή της δραστηριότητας του εγκεφάλου 500 ατόμων για 23.6 δευτερόλεπτα/καταγραφή. Στόχος είναι η λήψη σωστής απόφασης περί του αν το άτομο βρίσκεται σε επιληπτική κρίση ή όχι. Έγινε δειγματοληψία κάθε καταγραφής, η οποία οδήγησε σε 4097 δείγματα. Τα 4097 δείγματα χωρίστηκαν σε 23 κομμάτια, με το καθένα να περιέχει 178 σημεία, που αντιστοιχούν σε 1 δευτερόλεπτο καταγραφής. Έτσι δημιουργήθηκαν 23*500 = 11500 γραμμές-δείγματα, καθένα από τα οποία αποτελείται από 178 σημεία που αντιστοιχούν σε 1 δευτερόλεπτο και αποτελόυν τη διάσταση των δεδομένων εισόδου. Η τελευταία στήλη περιέχει τις ετικέτες, οι οποίες παίρνουν τιμές 1-5, με την περίπτωση 1 να αφορά τις περιπτώσεις όπου το άτομο είχε επιληπτική κρίση και τις 2-5 τις περιπτώσεις όπου δεν είχε. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivFpi5Y6qs5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def download(url, file):\n",
        "    if not os.path.isfile(file):\n",
        "        print(\"Download file... \" + file + \" ...\")\n",
        "        urlretrieve(url,file)\n",
        "        print(\"File downloaded\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO7sxOv9uQ-O",
        "colab_type": "code",
        "outputId": "836b2cd4-b312-4b52-ff85-11b7db2c5d22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "download(\"http://archive.ics.uci.edu/ml/machine-learning-databases/00388/data.csv\",\"ESR.csv\")\n",
        "print(\"All the files are downloaded\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All the files are downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atJR4ULlNnLD",
        "colab_type": "code",
        "outputId": "9d6e728b-f671-4001-ed48-8abe0e28c081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ESR.csv  sample_data  tmp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUP2fM13N0nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"ESR.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZZ3Jz97vZso",
        "colab_type": "text"
      },
      "source": [
        "2. Όπως είπαμε παραπάνω και όπως φαίνεται παρακάτω, υπάρχουν 11500 δείγματα, το καθένα με 178 χαρακτηριστικά, τα οποία αφορούν τις μεταβολές της ηλεκτρικής τάσης των σημάτων στους νευρώνες του ανθρωπίνου εγκεφάλου. Συνεπώς είναι διατεταγμένα. Επίσης είναι ακέραιοι αριθμοί.\n",
        "3. Υπάρχουν επικεφαλίδες στην πρώτη γραμμή και στοιχεία για το εκάστοτε δείγμα στην πρώτη στήλη, οι οποίες θα πρέπει να αφαιρεθούν. Επίσης υπάρχουν χαρακτηριστικά των δειγμάτων στην πρώτη κολώνα, τα οποία αφαιρούμε παρακάτω."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8vWCNtEOjBR",
        "colab_type": "code",
        "outputId": "8a488320-6f45-40ff-e238-651bf4d3feee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11500, 180)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DPxsuXoW0QDt",
        "outputId": "44253e28-12ff-498a-fa52-a179c2ac9edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "source": [
        "df #print the dataset"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>X11</th>\n",
              "      <th>X12</th>\n",
              "      <th>X13</th>\n",
              "      <th>X14</th>\n",
              "      <th>X15</th>\n",
              "      <th>X16</th>\n",
              "      <th>X17</th>\n",
              "      <th>X18</th>\n",
              "      <th>X19</th>\n",
              "      <th>X20</th>\n",
              "      <th>X21</th>\n",
              "      <th>X22</th>\n",
              "      <th>X23</th>\n",
              "      <th>X24</th>\n",
              "      <th>X25</th>\n",
              "      <th>X26</th>\n",
              "      <th>X27</th>\n",
              "      <th>X28</th>\n",
              "      <th>X29</th>\n",
              "      <th>X30</th>\n",
              "      <th>X31</th>\n",
              "      <th>X32</th>\n",
              "      <th>X33</th>\n",
              "      <th>X34</th>\n",
              "      <th>X35</th>\n",
              "      <th>X36</th>\n",
              "      <th>X37</th>\n",
              "      <th>X38</th>\n",
              "      <th>X39</th>\n",
              "      <th>...</th>\n",
              "      <th>X140</th>\n",
              "      <th>X141</th>\n",
              "      <th>X142</th>\n",
              "      <th>X143</th>\n",
              "      <th>X144</th>\n",
              "      <th>X145</th>\n",
              "      <th>X146</th>\n",
              "      <th>X147</th>\n",
              "      <th>X148</th>\n",
              "      <th>X149</th>\n",
              "      <th>X150</th>\n",
              "      <th>X151</th>\n",
              "      <th>X152</th>\n",
              "      <th>X153</th>\n",
              "      <th>X154</th>\n",
              "      <th>X155</th>\n",
              "      <th>X156</th>\n",
              "      <th>X157</th>\n",
              "      <th>X158</th>\n",
              "      <th>X159</th>\n",
              "      <th>X160</th>\n",
              "      <th>X161</th>\n",
              "      <th>X162</th>\n",
              "      <th>X163</th>\n",
              "      <th>X164</th>\n",
              "      <th>X165</th>\n",
              "      <th>X166</th>\n",
              "      <th>X167</th>\n",
              "      <th>X168</th>\n",
              "      <th>X169</th>\n",
              "      <th>X170</th>\n",
              "      <th>X171</th>\n",
              "      <th>X172</th>\n",
              "      <th>X173</th>\n",
              "      <th>X174</th>\n",
              "      <th>X175</th>\n",
              "      <th>X176</th>\n",
              "      <th>X177</th>\n",
              "      <th>X178</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>X21.V1.791</td>\n",
              "      <td>135</td>\n",
              "      <td>190</td>\n",
              "      <td>229</td>\n",
              "      <td>223</td>\n",
              "      <td>192</td>\n",
              "      <td>125</td>\n",
              "      <td>55</td>\n",
              "      <td>-9</td>\n",
              "      <td>-33</td>\n",
              "      <td>-38</td>\n",
              "      <td>-10</td>\n",
              "      <td>35</td>\n",
              "      <td>64</td>\n",
              "      <td>113</td>\n",
              "      <td>152</td>\n",
              "      <td>164</td>\n",
              "      <td>127</td>\n",
              "      <td>50</td>\n",
              "      <td>-47</td>\n",
              "      <td>-121</td>\n",
              "      <td>-138</td>\n",
              "      <td>-125</td>\n",
              "      <td>-101</td>\n",
              "      <td>-50</td>\n",
              "      <td>11</td>\n",
              "      <td>39</td>\n",
              "      <td>24</td>\n",
              "      <td>48</td>\n",
              "      <td>64</td>\n",
              "      <td>46</td>\n",
              "      <td>13</td>\n",
              "      <td>-19</td>\n",
              "      <td>-61</td>\n",
              "      <td>-96</td>\n",
              "      <td>-130</td>\n",
              "      <td>-132</td>\n",
              "      <td>-116</td>\n",
              "      <td>-115</td>\n",
              "      <td>-71</td>\n",
              "      <td>...</td>\n",
              "      <td>54</td>\n",
              "      <td>90</td>\n",
              "      <td>111</td>\n",
              "      <td>107</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>18</td>\n",
              "      <td>-25</td>\n",
              "      <td>-69</td>\n",
              "      <td>-65</td>\n",
              "      <td>-44</td>\n",
              "      <td>-33</td>\n",
              "      <td>-57</td>\n",
              "      <td>-88</td>\n",
              "      <td>-114</td>\n",
              "      <td>-130</td>\n",
              "      <td>-114</td>\n",
              "      <td>-83</td>\n",
              "      <td>-53</td>\n",
              "      <td>-79</td>\n",
              "      <td>-72</td>\n",
              "      <td>-85</td>\n",
              "      <td>-109</td>\n",
              "      <td>-98</td>\n",
              "      <td>-72</td>\n",
              "      <td>-65</td>\n",
              "      <td>-63</td>\n",
              "      <td>-11</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>-17</td>\n",
              "      <td>-15</td>\n",
              "      <td>-31</td>\n",
              "      <td>-77</td>\n",
              "      <td>-103</td>\n",
              "      <td>-127</td>\n",
              "      <td>-116</td>\n",
              "      <td>-83</td>\n",
              "      <td>-51</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>X15.V1.924</td>\n",
              "      <td>386</td>\n",
              "      <td>382</td>\n",
              "      <td>356</td>\n",
              "      <td>331</td>\n",
              "      <td>320</td>\n",
              "      <td>315</td>\n",
              "      <td>307</td>\n",
              "      <td>272</td>\n",
              "      <td>244</td>\n",
              "      <td>232</td>\n",
              "      <td>237</td>\n",
              "      <td>258</td>\n",
              "      <td>212</td>\n",
              "      <td>2</td>\n",
              "      <td>-267</td>\n",
              "      <td>-605</td>\n",
              "      <td>-850</td>\n",
              "      <td>-1001</td>\n",
              "      <td>-1109</td>\n",
              "      <td>-1090</td>\n",
              "      <td>-967</td>\n",
              "      <td>-746</td>\n",
              "      <td>-464</td>\n",
              "      <td>-152</td>\n",
              "      <td>118</td>\n",
              "      <td>318</td>\n",
              "      <td>427</td>\n",
              "      <td>473</td>\n",
              "      <td>485</td>\n",
              "      <td>447</td>\n",
              "      <td>397</td>\n",
              "      <td>339</td>\n",
              "      <td>312</td>\n",
              "      <td>314</td>\n",
              "      <td>326</td>\n",
              "      <td>335</td>\n",
              "      <td>332</td>\n",
              "      <td>324</td>\n",
              "      <td>310</td>\n",
              "      <td>...</td>\n",
              "      <td>27</td>\n",
              "      <td>146</td>\n",
              "      <td>229</td>\n",
              "      <td>269</td>\n",
              "      <td>297</td>\n",
              "      <td>307</td>\n",
              "      <td>303</td>\n",
              "      <td>305</td>\n",
              "      <td>306</td>\n",
              "      <td>307</td>\n",
              "      <td>280</td>\n",
              "      <td>231</td>\n",
              "      <td>159</td>\n",
              "      <td>85</td>\n",
              "      <td>51</td>\n",
              "      <td>43</td>\n",
              "      <td>62</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>89</td>\n",
              "      <td>123</td>\n",
              "      <td>136</td>\n",
              "      <td>127</td>\n",
              "      <td>102</td>\n",
              "      <td>95</td>\n",
              "      <td>105</td>\n",
              "      <td>131</td>\n",
              "      <td>163</td>\n",
              "      <td>168</td>\n",
              "      <td>164</td>\n",
              "      <td>150</td>\n",
              "      <td>146</td>\n",
              "      <td>152</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>154</td>\n",
              "      <td>143</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>X8.V1.1</td>\n",
              "      <td>-32</td>\n",
              "      <td>-39</td>\n",
              "      <td>-47</td>\n",
              "      <td>-37</td>\n",
              "      <td>-32</td>\n",
              "      <td>-36</td>\n",
              "      <td>-57</td>\n",
              "      <td>-73</td>\n",
              "      <td>-85</td>\n",
              "      <td>-94</td>\n",
              "      <td>-99</td>\n",
              "      <td>-94</td>\n",
              "      <td>-96</td>\n",
              "      <td>-104</td>\n",
              "      <td>-103</td>\n",
              "      <td>-92</td>\n",
              "      <td>-75</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-53</td>\n",
              "      <td>-37</td>\n",
              "      <td>-14</td>\n",
              "      <td>-10</td>\n",
              "      <td>-39</td>\n",
              "      <td>-78</td>\n",
              "      <td>-102</td>\n",
              "      <td>-98</td>\n",
              "      <td>-80</td>\n",
              "      <td>-54</td>\n",
              "      <td>-40</td>\n",
              "      <td>-35</td>\n",
              "      <td>-39</td>\n",
              "      <td>-32</td>\n",
              "      <td>-13</td>\n",
              "      <td>7</td>\n",
              "      <td>34</td>\n",
              "      <td>41</td>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>-82</td>\n",
              "      <td>-107</td>\n",
              "      <td>-126</td>\n",
              "      <td>-124</td>\n",
              "      <td>-108</td>\n",
              "      <td>-84</td>\n",
              "      <td>-68</td>\n",
              "      <td>-61</td>\n",
              "      <td>-56</td>\n",
              "      <td>-63</td>\n",
              "      <td>-62</td>\n",
              "      <td>-33</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>45</td>\n",
              "      <td>37</td>\n",
              "      <td>48</td>\n",
              "      <td>62</td>\n",
              "      <td>80</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>-11</td>\n",
              "      <td>-39</td>\n",
              "      <td>-44</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-48</td>\n",
              "      <td>-42</td>\n",
              "      <td>-6</td>\n",
              "      <td>29</td>\n",
              "      <td>57</td>\n",
              "      <td>64</td>\n",
              "      <td>48</td>\n",
              "      <td>19</td>\n",
              "      <td>-12</td>\n",
              "      <td>-30</td>\n",
              "      <td>-35</td>\n",
              "      <td>-35</td>\n",
              "      <td>-36</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>X16.V1.60</td>\n",
              "      <td>-105</td>\n",
              "      <td>-101</td>\n",
              "      <td>-96</td>\n",
              "      <td>-92</td>\n",
              "      <td>-89</td>\n",
              "      <td>-95</td>\n",
              "      <td>-102</td>\n",
              "      <td>-100</td>\n",
              "      <td>-87</td>\n",
              "      <td>-79</td>\n",
              "      <td>-72</td>\n",
              "      <td>-68</td>\n",
              "      <td>-74</td>\n",
              "      <td>-80</td>\n",
              "      <td>-83</td>\n",
              "      <td>-73</td>\n",
              "      <td>-68</td>\n",
              "      <td>-61</td>\n",
              "      <td>-58</td>\n",
              "      <td>-59</td>\n",
              "      <td>-64</td>\n",
              "      <td>-79</td>\n",
              "      <td>-84</td>\n",
              "      <td>-97</td>\n",
              "      <td>-94</td>\n",
              "      <td>-84</td>\n",
              "      <td>-77</td>\n",
              "      <td>-75</td>\n",
              "      <td>-72</td>\n",
              "      <td>-68</td>\n",
              "      <td>-76</td>\n",
              "      <td>-76</td>\n",
              "      <td>-72</td>\n",
              "      <td>-67</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-67</td>\n",
              "      <td>-68</td>\n",
              "      <td>...</td>\n",
              "      <td>-69</td>\n",
              "      <td>-66</td>\n",
              "      <td>-74</td>\n",
              "      <td>-69</td>\n",
              "      <td>-61</td>\n",
              "      <td>-51</td>\n",
              "      <td>-45</td>\n",
              "      <td>-45</td>\n",
              "      <td>-49</td>\n",
              "      <td>-58</td>\n",
              "      <td>-64</td>\n",
              "      <td>-78</td>\n",
              "      <td>-80</td>\n",
              "      <td>-90</td>\n",
              "      <td>-87</td>\n",
              "      <td>-83</td>\n",
              "      <td>-78</td>\n",
              "      <td>-64</td>\n",
              "      <td>-38</td>\n",
              "      <td>-22</td>\n",
              "      <td>-29</td>\n",
              "      <td>-42</td>\n",
              "      <td>-51</td>\n",
              "      <td>-68</td>\n",
              "      <td>-71</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-74</td>\n",
              "      <td>-74</td>\n",
              "      <td>-80</td>\n",
              "      <td>-82</td>\n",
              "      <td>-81</td>\n",
              "      <td>-80</td>\n",
              "      <td>-77</td>\n",
              "      <td>-85</td>\n",
              "      <td>-77</td>\n",
              "      <td>-72</td>\n",
              "      <td>-69</td>\n",
              "      <td>-65</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>X20.V1.54</td>\n",
              "      <td>-9</td>\n",
              "      <td>-65</td>\n",
              "      <td>-98</td>\n",
              "      <td>-102</td>\n",
              "      <td>-78</td>\n",
              "      <td>-48</td>\n",
              "      <td>-16</td>\n",
              "      <td>0</td>\n",
              "      <td>-21</td>\n",
              "      <td>-59</td>\n",
              "      <td>-90</td>\n",
              "      <td>-103</td>\n",
              "      <td>-84</td>\n",
              "      <td>-43</td>\n",
              "      <td>-9</td>\n",
              "      <td>3</td>\n",
              "      <td>-21</td>\n",
              "      <td>-60</td>\n",
              "      <td>-96</td>\n",
              "      <td>-103</td>\n",
              "      <td>-75</td>\n",
              "      <td>-29</td>\n",
              "      <td>14</td>\n",
              "      <td>55</td>\n",
              "      <td>78</td>\n",
              "      <td>73</td>\n",
              "      <td>28</td>\n",
              "      <td>-13</td>\n",
              "      <td>-43</td>\n",
              "      <td>-68</td>\n",
              "      <td>-78</td>\n",
              "      <td>-75</td>\n",
              "      <td>-55</td>\n",
              "      <td>-41</td>\n",
              "      <td>-19</td>\n",
              "      <td>-20</td>\n",
              "      <td>-29</td>\n",
              "      <td>-36</td>\n",
              "      <td>-20</td>\n",
              "      <td>...</td>\n",
              "      <td>38</td>\n",
              "      <td>26</td>\n",
              "      <td>10</td>\n",
              "      <td>-4</td>\n",
              "      <td>-13</td>\n",
              "      <td>-8</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>29</td>\n",
              "      <td>57</td>\n",
              "      <td>63</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "      <td>-13</td>\n",
              "      <td>-23</td>\n",
              "      <td>-9</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>-12</td>\n",
              "      <td>-32</td>\n",
              "      <td>-41</td>\n",
              "      <td>-65</td>\n",
              "      <td>-83</td>\n",
              "      <td>-89</td>\n",
              "      <td>-73</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11495</th>\n",
              "      <td>X22.V1.114</td>\n",
              "      <td>-22</td>\n",
              "      <td>-22</td>\n",
              "      <td>-23</td>\n",
              "      <td>-26</td>\n",
              "      <td>-36</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-49</td>\n",
              "      <td>-57</td>\n",
              "      <td>-64</td>\n",
              "      <td>-73</td>\n",
              "      <td>-79</td>\n",
              "      <td>-76</td>\n",
              "      <td>-70</td>\n",
              "      <td>-63</td>\n",
              "      <td>-57</td>\n",
              "      <td>-57</td>\n",
              "      <td>-50</td>\n",
              "      <td>-45</td>\n",
              "      <td>-34</td>\n",
              "      <td>-33</td>\n",
              "      <td>-32</td>\n",
              "      <td>-30</td>\n",
              "      <td>-24</td>\n",
              "      <td>-24</td>\n",
              "      <td>-18</td>\n",
              "      <td>-9</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-3</td>\n",
              "      <td>-5</td>\n",
              "      <td>-13</td>\n",
              "      <td>-23</td>\n",
              "      <td>-39</td>\n",
              "      <td>-53</td>\n",
              "      <td>-59</td>\n",
              "      <td>...</td>\n",
              "      <td>45</td>\n",
              "      <td>55</td>\n",
              "      <td>60</td>\n",
              "      <td>69</td>\n",
              "      <td>68</td>\n",
              "      <td>58</td>\n",
              "      <td>54</td>\n",
              "      <td>44</td>\n",
              "      <td>40</td>\n",
              "      <td>38</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>32</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>25</td>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>-18</td>\n",
              "      <td>-37</td>\n",
              "      <td>-47</td>\n",
              "      <td>-48</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11496</th>\n",
              "      <td>X19.V1.354</td>\n",
              "      <td>-47</td>\n",
              "      <td>-11</td>\n",
              "      <td>28</td>\n",
              "      <td>77</td>\n",
              "      <td>141</td>\n",
              "      <td>211</td>\n",
              "      <td>246</td>\n",
              "      <td>240</td>\n",
              "      <td>193</td>\n",
              "      <td>136</td>\n",
              "      <td>78</td>\n",
              "      <td>8</td>\n",
              "      <td>-66</td>\n",
              "      <td>-132</td>\n",
              "      <td>-180</td>\n",
              "      <td>-210</td>\n",
              "      <td>-227</td>\n",
              "      <td>-225</td>\n",
              "      <td>-212</td>\n",
              "      <td>-192</td>\n",
              "      <td>-168</td>\n",
              "      <td>-144</td>\n",
              "      <td>-117</td>\n",
              "      <td>-88</td>\n",
              "      <td>-54</td>\n",
              "      <td>-21</td>\n",
              "      <td>6</td>\n",
              "      <td>29</td>\n",
              "      <td>46</td>\n",
              "      <td>60</td>\n",
              "      <td>76</td>\n",
              "      <td>92</td>\n",
              "      <td>110</td>\n",
              "      <td>128</td>\n",
              "      <td>152</td>\n",
              "      <td>171</td>\n",
              "      <td>150</td>\n",
              "      <td>91</td>\n",
              "      <td>21</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>38</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>75</td>\n",
              "      <td>165</td>\n",
              "      <td>260</td>\n",
              "      <td>343</td>\n",
              "      <td>406</td>\n",
              "      <td>456</td>\n",
              "      <td>471</td>\n",
              "      <td>461</td>\n",
              "      <td>412</td>\n",
              "      <td>319</td>\n",
              "      <td>175</td>\n",
              "      <td>-5</td>\n",
              "      <td>-171</td>\n",
              "      <td>-293</td>\n",
              "      <td>-357</td>\n",
              "      <td>-378</td>\n",
              "      <td>-370</td>\n",
              "      <td>-346</td>\n",
              "      <td>-316</td>\n",
              "      <td>-278</td>\n",
              "      <td>-241</td>\n",
              "      <td>-201</td>\n",
              "      <td>-162</td>\n",
              "      <td>-126</td>\n",
              "      <td>-94</td>\n",
              "      <td>-65</td>\n",
              "      <td>-33</td>\n",
              "      <td>-7</td>\n",
              "      <td>14</td>\n",
              "      <td>27</td>\n",
              "      <td>48</td>\n",
              "      <td>77</td>\n",
              "      <td>117</td>\n",
              "      <td>170</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11497</th>\n",
              "      <td>X8.V1.28</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>-13</td>\n",
              "      <td>-16</td>\n",
              "      <td>10</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>-9</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>-1</td>\n",
              "      <td>-10</td>\n",
              "      <td>14</td>\n",
              "      <td>44</td>\n",
              "      <td>77</td>\n",
              "      <td>61</td>\n",
              "      <td>42</td>\n",
              "      <td>32</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "      <td>26</td>\n",
              "      <td>35</td>\n",
              "      <td>81</td>\n",
              "      <td>66</td>\n",
              "      <td>50</td>\n",
              "      <td>57</td>\n",
              "      <td>91</td>\n",
              "      <td>121</td>\n",
              "      <td>111</td>\n",
              "      <td>73</td>\n",
              "      <td>38</td>\n",
              "      <td>23</td>\n",
              "      <td>35</td>\n",
              "      <td>21</td>\n",
              "      <td>11</td>\n",
              "      <td>-12</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>61</td>\n",
              "      <td>...</td>\n",
              "      <td>-90</td>\n",
              "      <td>-62</td>\n",
              "      <td>-38</td>\n",
              "      <td>-40</td>\n",
              "      <td>-21</td>\n",
              "      <td>-23</td>\n",
              "      <td>-11</td>\n",
              "      <td>-4</td>\n",
              "      <td>-9</td>\n",
              "      <td>-22</td>\n",
              "      <td>-42</td>\n",
              "      <td>-49</td>\n",
              "      <td>-48</td>\n",
              "      <td>-40</td>\n",
              "      <td>-40</td>\n",
              "      <td>-46</td>\n",
              "      <td>-43</td>\n",
              "      <td>-67</td>\n",
              "      <td>-67</td>\n",
              "      <td>-50</td>\n",
              "      <td>-18</td>\n",
              "      <td>-14</td>\n",
              "      <td>-39</td>\n",
              "      <td>-74</td>\n",
              "      <td>-86</td>\n",
              "      <td>-75</td>\n",
              "      <td>-68</td>\n",
              "      <td>-57</td>\n",
              "      <td>-78</td>\n",
              "      <td>-42</td>\n",
              "      <td>-65</td>\n",
              "      <td>-48</td>\n",
              "      <td>-61</td>\n",
              "      <td>-62</td>\n",
              "      <td>-67</td>\n",
              "      <td>-30</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11498</th>\n",
              "      <td>X10.V1.932</td>\n",
              "      <td>-40</td>\n",
              "      <td>-25</td>\n",
              "      <td>-9</td>\n",
              "      <td>-12</td>\n",
              "      <td>-2</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>22</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>-28</td>\n",
              "      <td>-37</td>\n",
              "      <td>-35</td>\n",
              "      <td>-35</td>\n",
              "      <td>-45</td>\n",
              "      <td>-64</td>\n",
              "      <td>-105</td>\n",
              "      <td>-140</td>\n",
              "      <td>-157</td>\n",
              "      <td>-157</td>\n",
              "      <td>-147</td>\n",
              "      <td>-153</td>\n",
              "      <td>-147</td>\n",
              "      <td>-126</td>\n",
              "      <td>-112</td>\n",
              "      <td>-83</td>\n",
              "      <td>-56</td>\n",
              "      <td>-41</td>\n",
              "      <td>-40</td>\n",
              "      <td>-38</td>\n",
              "      <td>-34</td>\n",
              "      <td>-47</td>\n",
              "      <td>-41</td>\n",
              "      <td>-40</td>\n",
              "      <td>-42</td>\n",
              "      <td>-49</td>\n",
              "      <td>...</td>\n",
              "      <td>-98</td>\n",
              "      <td>-77</td>\n",
              "      <td>-60</td>\n",
              "      <td>-73</td>\n",
              "      <td>-88</td>\n",
              "      <td>-97</td>\n",
              "      <td>-118</td>\n",
              "      <td>-108</td>\n",
              "      <td>-100</td>\n",
              "      <td>-97</td>\n",
              "      <td>-91</td>\n",
              "      <td>-109</td>\n",
              "      <td>-122</td>\n",
              "      <td>-134</td>\n",
              "      <td>-137</td>\n",
              "      <td>-107</td>\n",
              "      <td>-95</td>\n",
              "      <td>-67</td>\n",
              "      <td>-54</td>\n",
              "      <td>-40</td>\n",
              "      <td>-31</td>\n",
              "      <td>-19</td>\n",
              "      <td>7</td>\n",
              "      <td>22</td>\n",
              "      <td>46</td>\n",
              "      <td>68</td>\n",
              "      <td>87</td>\n",
              "      <td>97</td>\n",
              "      <td>105</td>\n",
              "      <td>114</td>\n",
              "      <td>121</td>\n",
              "      <td>135</td>\n",
              "      <td>148</td>\n",
              "      <td>143</td>\n",
              "      <td>116</td>\n",
              "      <td>86</td>\n",
              "      <td>68</td>\n",
              "      <td>59</td>\n",
              "      <td>55</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11499</th>\n",
              "      <td>X16.V1.210</td>\n",
              "      <td>29</td>\n",
              "      <td>41</td>\n",
              "      <td>57</td>\n",
              "      <td>72</td>\n",
              "      <td>74</td>\n",
              "      <td>62</td>\n",
              "      <td>54</td>\n",
              "      <td>43</td>\n",
              "      <td>31</td>\n",
              "      <td>23</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>-3</td>\n",
              "      <td>-5</td>\n",
              "      <td>-9</td>\n",
              "      <td>-14</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>60</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>50</td>\n",
              "      <td>33</td>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>-5</td>\n",
              "      <td>-4</td>\n",
              "      <td>-8</td>\n",
              "      <td>-15</td>\n",
              "      <td>-13</td>\n",
              "      <td>-2</td>\n",
              "      <td>21</td>\n",
              "      <td>39</td>\n",
              "      <td>48</td>\n",
              "      <td>37</td>\n",
              "      <td>10</td>\n",
              "      <td>-23</td>\n",
              "      <td>-47</td>\n",
              "      <td>...</td>\n",
              "      <td>-108</td>\n",
              "      <td>-83</td>\n",
              "      <td>-46</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>39</td>\n",
              "      <td>44</td>\n",
              "      <td>33</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>-13</td>\n",
              "      <td>-33</td>\n",
              "      <td>-61</td>\n",
              "      <td>-70</td>\n",
              "      <td>-75</td>\n",
              "      <td>-74</td>\n",
              "      <td>-58</td>\n",
              "      <td>-18</td>\n",
              "      <td>19</td>\n",
              "      <td>54</td>\n",
              "      <td>71</td>\n",
              "      <td>76</td>\n",
              "      <td>74</td>\n",
              "      <td>65</td>\n",
              "      <td>56</td>\n",
              "      <td>18</td>\n",
              "      <td>-28</td>\n",
              "      <td>-75</td>\n",
              "      <td>-98</td>\n",
              "      <td>-94</td>\n",
              "      <td>-59</td>\n",
              "      <td>-25</td>\n",
              "      <td>-4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>-2</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11500 rows × 180 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0   X1   X2   X3   X4   X5  ...  X174  X175  X176  X177  X178  y\n",
              "0      X21.V1.791  135  190  229  223  192  ...  -103  -127  -116   -83   -51  4\n",
              "1      X15.V1.924  386  382  356  331  320  ...   157   156   154   143   129  1\n",
              "2         X8.V1.1  -32  -39  -47  -37  -32  ...   -12   -30   -35   -35   -36  5\n",
              "3       X16.V1.60 -105 -101  -96  -92  -89  ...   -85   -77   -72   -69   -65  5\n",
              "4       X20.V1.54   -9  -65  -98 -102  -78  ...   -41   -65   -83   -89   -73  5\n",
              "...           ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ... ..\n",
              "11495  X22.V1.114  -22  -22  -23  -26  -36  ...    -1   -18   -37   -47   -48  2\n",
              "11496  X19.V1.354  -47  -11   28   77  141  ...    27    48    77   117   170  1\n",
              "11497    X8.V1.28   14    6  -13  -16   10  ...   -67   -30    -2    -1    -8  5\n",
              "11498  X10.V1.932  -40  -25   -9  -12   -2  ...   116    86    68    59    55  3\n",
              "11499  X16.V1.210   29   41   57   72   74  ...     5     4    -2     2    20  4\n",
              "\n",
              "[11500 rows x 180 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tudu50uC0Qt6",
        "colab_type": "code",
        "outputId": "58273afc-e151-4c1b-9c97-dcfd9af91b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print (\"We have \",len(df.columns), \" attributes.\")\n",
        "for i in range(0, len(df.columns)):\n",
        "    print('{:<10}{:<40}{:<10}{:<20}'.format(str(i+1), str(df.columns[i]),\"type: \", str(df.dtypes[df.columns[i]])))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have  180  attributes.\n",
            "1         Unnamed: 0                              type:     object              \n",
            "2         X1                                      type:     int64               \n",
            "3         X2                                      type:     int64               \n",
            "4         X3                                      type:     int64               \n",
            "5         X4                                      type:     int64               \n",
            "6         X5                                      type:     int64               \n",
            "7         X6                                      type:     int64               \n",
            "8         X7                                      type:     int64               \n",
            "9         X8                                      type:     int64               \n",
            "10        X9                                      type:     int64               \n",
            "11        X10                                     type:     int64               \n",
            "12        X11                                     type:     int64               \n",
            "13        X12                                     type:     int64               \n",
            "14        X13                                     type:     int64               \n",
            "15        X14                                     type:     int64               \n",
            "16        X15                                     type:     int64               \n",
            "17        X16                                     type:     int64               \n",
            "18        X17                                     type:     int64               \n",
            "19        X18                                     type:     int64               \n",
            "20        X19                                     type:     int64               \n",
            "21        X20                                     type:     int64               \n",
            "22        X21                                     type:     int64               \n",
            "23        X22                                     type:     int64               \n",
            "24        X23                                     type:     int64               \n",
            "25        X24                                     type:     int64               \n",
            "26        X25                                     type:     int64               \n",
            "27        X26                                     type:     int64               \n",
            "28        X27                                     type:     int64               \n",
            "29        X28                                     type:     int64               \n",
            "30        X29                                     type:     int64               \n",
            "31        X30                                     type:     int64               \n",
            "32        X31                                     type:     int64               \n",
            "33        X32                                     type:     int64               \n",
            "34        X33                                     type:     int64               \n",
            "35        X34                                     type:     int64               \n",
            "36        X35                                     type:     int64               \n",
            "37        X36                                     type:     int64               \n",
            "38        X37                                     type:     int64               \n",
            "39        X38                                     type:     int64               \n",
            "40        X39                                     type:     int64               \n",
            "41        X40                                     type:     int64               \n",
            "42        X41                                     type:     int64               \n",
            "43        X42                                     type:     int64               \n",
            "44        X43                                     type:     int64               \n",
            "45        X44                                     type:     int64               \n",
            "46        X45                                     type:     int64               \n",
            "47        X46                                     type:     int64               \n",
            "48        X47                                     type:     int64               \n",
            "49        X48                                     type:     int64               \n",
            "50        X49                                     type:     int64               \n",
            "51        X50                                     type:     int64               \n",
            "52        X51                                     type:     int64               \n",
            "53        X52                                     type:     int64               \n",
            "54        X53                                     type:     int64               \n",
            "55        X54                                     type:     int64               \n",
            "56        X55                                     type:     int64               \n",
            "57        X56                                     type:     int64               \n",
            "58        X57                                     type:     int64               \n",
            "59        X58                                     type:     int64               \n",
            "60        X59                                     type:     int64               \n",
            "61        X60                                     type:     int64               \n",
            "62        X61                                     type:     int64               \n",
            "63        X62                                     type:     int64               \n",
            "64        X63                                     type:     int64               \n",
            "65        X64                                     type:     int64               \n",
            "66        X65                                     type:     int64               \n",
            "67        X66                                     type:     int64               \n",
            "68        X67                                     type:     int64               \n",
            "69        X68                                     type:     int64               \n",
            "70        X69                                     type:     int64               \n",
            "71        X70                                     type:     int64               \n",
            "72        X71                                     type:     int64               \n",
            "73        X72                                     type:     int64               \n",
            "74        X73                                     type:     int64               \n",
            "75        X74                                     type:     int64               \n",
            "76        X75                                     type:     int64               \n",
            "77        X76                                     type:     int64               \n",
            "78        X77                                     type:     int64               \n",
            "79        X78                                     type:     int64               \n",
            "80        X79                                     type:     int64               \n",
            "81        X80                                     type:     int64               \n",
            "82        X81                                     type:     int64               \n",
            "83        X82                                     type:     int64               \n",
            "84        X83                                     type:     int64               \n",
            "85        X84                                     type:     int64               \n",
            "86        X85                                     type:     int64               \n",
            "87        X86                                     type:     int64               \n",
            "88        X87                                     type:     int64               \n",
            "89        X88                                     type:     int64               \n",
            "90        X89                                     type:     int64               \n",
            "91        X90                                     type:     int64               \n",
            "92        X91                                     type:     int64               \n",
            "93        X92                                     type:     int64               \n",
            "94        X93                                     type:     int64               \n",
            "95        X94                                     type:     int64               \n",
            "96        X95                                     type:     int64               \n",
            "97        X96                                     type:     int64               \n",
            "98        X97                                     type:     int64               \n",
            "99        X98                                     type:     int64               \n",
            "100       X99                                     type:     int64               \n",
            "101       X100                                    type:     int64               \n",
            "102       X101                                    type:     int64               \n",
            "103       X102                                    type:     int64               \n",
            "104       X103                                    type:     int64               \n",
            "105       X104                                    type:     int64               \n",
            "106       X105                                    type:     int64               \n",
            "107       X106                                    type:     int64               \n",
            "108       X107                                    type:     int64               \n",
            "109       X108                                    type:     int64               \n",
            "110       X109                                    type:     int64               \n",
            "111       X110                                    type:     int64               \n",
            "112       X111                                    type:     int64               \n",
            "113       X112                                    type:     int64               \n",
            "114       X113                                    type:     int64               \n",
            "115       X114                                    type:     int64               \n",
            "116       X115                                    type:     int64               \n",
            "117       X116                                    type:     int64               \n",
            "118       X117                                    type:     int64               \n",
            "119       X118                                    type:     int64               \n",
            "120       X119                                    type:     int64               \n",
            "121       X120                                    type:     int64               \n",
            "122       X121                                    type:     int64               \n",
            "123       X122                                    type:     int64               \n",
            "124       X123                                    type:     int64               \n",
            "125       X124                                    type:     int64               \n",
            "126       X125                                    type:     int64               \n",
            "127       X126                                    type:     int64               \n",
            "128       X127                                    type:     int64               \n",
            "129       X128                                    type:     int64               \n",
            "130       X129                                    type:     int64               \n",
            "131       X130                                    type:     int64               \n",
            "132       X131                                    type:     int64               \n",
            "133       X132                                    type:     int64               \n",
            "134       X133                                    type:     int64               \n",
            "135       X134                                    type:     int64               \n",
            "136       X135                                    type:     int64               \n",
            "137       X136                                    type:     int64               \n",
            "138       X137                                    type:     int64               \n",
            "139       X138                                    type:     int64               \n",
            "140       X139                                    type:     int64               \n",
            "141       X140                                    type:     int64               \n",
            "142       X141                                    type:     int64               \n",
            "143       X142                                    type:     int64               \n",
            "144       X143                                    type:     int64               \n",
            "145       X144                                    type:     int64               \n",
            "146       X145                                    type:     int64               \n",
            "147       X146                                    type:     int64               \n",
            "148       X147                                    type:     int64               \n",
            "149       X148                                    type:     int64               \n",
            "150       X149                                    type:     int64               \n",
            "151       X150                                    type:     int64               \n",
            "152       X151                                    type:     int64               \n",
            "153       X152                                    type:     int64               \n",
            "154       X153                                    type:     int64               \n",
            "155       X154                                    type:     int64               \n",
            "156       X155                                    type:     int64               \n",
            "157       X156                                    type:     int64               \n",
            "158       X157                                    type:     int64               \n",
            "159       X158                                    type:     int64               \n",
            "160       X159                                    type:     int64               \n",
            "161       X160                                    type:     int64               \n",
            "162       X161                                    type:     int64               \n",
            "163       X162                                    type:     int64               \n",
            "164       X163                                    type:     int64               \n",
            "165       X164                                    type:     int64               \n",
            "166       X165                                    type:     int64               \n",
            "167       X166                                    type:     int64               \n",
            "168       X167                                    type:     int64               \n",
            "169       X168                                    type:     int64               \n",
            "170       X169                                    type:     int64               \n",
            "171       X170                                    type:     int64               \n",
            "172       X171                                    type:     int64               \n",
            "173       X172                                    type:     int64               \n",
            "174       X173                                    type:     int64               \n",
            "175       X174                                    type:     int64               \n",
            "176       X175                                    type:     int64               \n",
            "177       X176                                    type:     int64               \n",
            "178       X177                                    type:     int64               \n",
            "179       X178                                    type:     int64               \n",
            "180       y                                       type:     int64               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcm_GRAbqP4f",
        "colab_type": "text"
      },
      "source": [
        "4. Όπως είπαμε οι ετικέτες αφορούν 5 περιπτώσεις και βρίσκονται στην τελευταία στήλη. Τις αφαιρούμε παρακάτω και δημιουργούμε τα labels. Οι κλάσεις 2-5 αφορούν περιπτώσεις όπως το αν το άτομο είχε ανοικτά ή κλειστά τα μάτια του κατά τη διάρκεια της εξέτασης.\n",
        "5. Διαγράφουμε την πρώτη κολώνα, ώστε όλες οι κολώνες εκτός της τελευταίας να περιέχουν τιμές των χαρακτηριστικών, με την τελευταία να περιέχει τις ετικέτες."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSj6XEFTplQq",
        "colab_type": "code",
        "outputId": "1ed58721-b85b-4e1c-80b2-9691d8808e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "labels = df.iloc[:, 179]\n",
        "df = df.iloc[:, 0:179]   #remove lables from set\n",
        "\n",
        "df = df.drop(df.columns[[0]], axis=1)\n",
        "df"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>X11</th>\n",
              "      <th>X12</th>\n",
              "      <th>X13</th>\n",
              "      <th>X14</th>\n",
              "      <th>X15</th>\n",
              "      <th>X16</th>\n",
              "      <th>X17</th>\n",
              "      <th>X18</th>\n",
              "      <th>X19</th>\n",
              "      <th>X20</th>\n",
              "      <th>X21</th>\n",
              "      <th>X22</th>\n",
              "      <th>X23</th>\n",
              "      <th>X24</th>\n",
              "      <th>X25</th>\n",
              "      <th>X26</th>\n",
              "      <th>X27</th>\n",
              "      <th>X28</th>\n",
              "      <th>X29</th>\n",
              "      <th>X30</th>\n",
              "      <th>X31</th>\n",
              "      <th>X32</th>\n",
              "      <th>X33</th>\n",
              "      <th>X34</th>\n",
              "      <th>X35</th>\n",
              "      <th>X36</th>\n",
              "      <th>X37</th>\n",
              "      <th>X38</th>\n",
              "      <th>X39</th>\n",
              "      <th>X40</th>\n",
              "      <th>...</th>\n",
              "      <th>X139</th>\n",
              "      <th>X140</th>\n",
              "      <th>X141</th>\n",
              "      <th>X142</th>\n",
              "      <th>X143</th>\n",
              "      <th>X144</th>\n",
              "      <th>X145</th>\n",
              "      <th>X146</th>\n",
              "      <th>X147</th>\n",
              "      <th>X148</th>\n",
              "      <th>X149</th>\n",
              "      <th>X150</th>\n",
              "      <th>X151</th>\n",
              "      <th>X152</th>\n",
              "      <th>X153</th>\n",
              "      <th>X154</th>\n",
              "      <th>X155</th>\n",
              "      <th>X156</th>\n",
              "      <th>X157</th>\n",
              "      <th>X158</th>\n",
              "      <th>X159</th>\n",
              "      <th>X160</th>\n",
              "      <th>X161</th>\n",
              "      <th>X162</th>\n",
              "      <th>X163</th>\n",
              "      <th>X164</th>\n",
              "      <th>X165</th>\n",
              "      <th>X166</th>\n",
              "      <th>X167</th>\n",
              "      <th>X168</th>\n",
              "      <th>X169</th>\n",
              "      <th>X170</th>\n",
              "      <th>X171</th>\n",
              "      <th>X172</th>\n",
              "      <th>X173</th>\n",
              "      <th>X174</th>\n",
              "      <th>X175</th>\n",
              "      <th>X176</th>\n",
              "      <th>X177</th>\n",
              "      <th>X178</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>135</td>\n",
              "      <td>190</td>\n",
              "      <td>229</td>\n",
              "      <td>223</td>\n",
              "      <td>192</td>\n",
              "      <td>125</td>\n",
              "      <td>55</td>\n",
              "      <td>-9</td>\n",
              "      <td>-33</td>\n",
              "      <td>-38</td>\n",
              "      <td>-10</td>\n",
              "      <td>35</td>\n",
              "      <td>64</td>\n",
              "      <td>113</td>\n",
              "      <td>152</td>\n",
              "      <td>164</td>\n",
              "      <td>127</td>\n",
              "      <td>50</td>\n",
              "      <td>-47</td>\n",
              "      <td>-121</td>\n",
              "      <td>-138</td>\n",
              "      <td>-125</td>\n",
              "      <td>-101</td>\n",
              "      <td>-50</td>\n",
              "      <td>11</td>\n",
              "      <td>39</td>\n",
              "      <td>24</td>\n",
              "      <td>48</td>\n",
              "      <td>64</td>\n",
              "      <td>46</td>\n",
              "      <td>13</td>\n",
              "      <td>-19</td>\n",
              "      <td>-61</td>\n",
              "      <td>-96</td>\n",
              "      <td>-130</td>\n",
              "      <td>-132</td>\n",
              "      <td>-116</td>\n",
              "      <td>-115</td>\n",
              "      <td>-71</td>\n",
              "      <td>-14</td>\n",
              "      <td>...</td>\n",
              "      <td>43</td>\n",
              "      <td>54</td>\n",
              "      <td>90</td>\n",
              "      <td>111</td>\n",
              "      <td>107</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>18</td>\n",
              "      <td>-25</td>\n",
              "      <td>-69</td>\n",
              "      <td>-65</td>\n",
              "      <td>-44</td>\n",
              "      <td>-33</td>\n",
              "      <td>-57</td>\n",
              "      <td>-88</td>\n",
              "      <td>-114</td>\n",
              "      <td>-130</td>\n",
              "      <td>-114</td>\n",
              "      <td>-83</td>\n",
              "      <td>-53</td>\n",
              "      <td>-79</td>\n",
              "      <td>-72</td>\n",
              "      <td>-85</td>\n",
              "      <td>-109</td>\n",
              "      <td>-98</td>\n",
              "      <td>-72</td>\n",
              "      <td>-65</td>\n",
              "      <td>-63</td>\n",
              "      <td>-11</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>-17</td>\n",
              "      <td>-15</td>\n",
              "      <td>-31</td>\n",
              "      <td>-77</td>\n",
              "      <td>-103</td>\n",
              "      <td>-127</td>\n",
              "      <td>-116</td>\n",
              "      <td>-83</td>\n",
              "      <td>-51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>386</td>\n",
              "      <td>382</td>\n",
              "      <td>356</td>\n",
              "      <td>331</td>\n",
              "      <td>320</td>\n",
              "      <td>315</td>\n",
              "      <td>307</td>\n",
              "      <td>272</td>\n",
              "      <td>244</td>\n",
              "      <td>232</td>\n",
              "      <td>237</td>\n",
              "      <td>258</td>\n",
              "      <td>212</td>\n",
              "      <td>2</td>\n",
              "      <td>-267</td>\n",
              "      <td>-605</td>\n",
              "      <td>-850</td>\n",
              "      <td>-1001</td>\n",
              "      <td>-1109</td>\n",
              "      <td>-1090</td>\n",
              "      <td>-967</td>\n",
              "      <td>-746</td>\n",
              "      <td>-464</td>\n",
              "      <td>-152</td>\n",
              "      <td>118</td>\n",
              "      <td>318</td>\n",
              "      <td>427</td>\n",
              "      <td>473</td>\n",
              "      <td>485</td>\n",
              "      <td>447</td>\n",
              "      <td>397</td>\n",
              "      <td>339</td>\n",
              "      <td>312</td>\n",
              "      <td>314</td>\n",
              "      <td>326</td>\n",
              "      <td>335</td>\n",
              "      <td>332</td>\n",
              "      <td>324</td>\n",
              "      <td>310</td>\n",
              "      <td>312</td>\n",
              "      <td>...</td>\n",
              "      <td>-136</td>\n",
              "      <td>27</td>\n",
              "      <td>146</td>\n",
              "      <td>229</td>\n",
              "      <td>269</td>\n",
              "      <td>297</td>\n",
              "      <td>307</td>\n",
              "      <td>303</td>\n",
              "      <td>305</td>\n",
              "      <td>306</td>\n",
              "      <td>307</td>\n",
              "      <td>280</td>\n",
              "      <td>231</td>\n",
              "      <td>159</td>\n",
              "      <td>85</td>\n",
              "      <td>51</td>\n",
              "      <td>43</td>\n",
              "      <td>62</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>89</td>\n",
              "      <td>123</td>\n",
              "      <td>136</td>\n",
              "      <td>127</td>\n",
              "      <td>102</td>\n",
              "      <td>95</td>\n",
              "      <td>105</td>\n",
              "      <td>131</td>\n",
              "      <td>163</td>\n",
              "      <td>168</td>\n",
              "      <td>164</td>\n",
              "      <td>150</td>\n",
              "      <td>146</td>\n",
              "      <td>152</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>154</td>\n",
              "      <td>143</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-32</td>\n",
              "      <td>-39</td>\n",
              "      <td>-47</td>\n",
              "      <td>-37</td>\n",
              "      <td>-32</td>\n",
              "      <td>-36</td>\n",
              "      <td>-57</td>\n",
              "      <td>-73</td>\n",
              "      <td>-85</td>\n",
              "      <td>-94</td>\n",
              "      <td>-99</td>\n",
              "      <td>-94</td>\n",
              "      <td>-96</td>\n",
              "      <td>-104</td>\n",
              "      <td>-103</td>\n",
              "      <td>-92</td>\n",
              "      <td>-75</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-53</td>\n",
              "      <td>-37</td>\n",
              "      <td>-14</td>\n",
              "      <td>-10</td>\n",
              "      <td>-39</td>\n",
              "      <td>-78</td>\n",
              "      <td>-102</td>\n",
              "      <td>-98</td>\n",
              "      <td>-80</td>\n",
              "      <td>-54</td>\n",
              "      <td>-40</td>\n",
              "      <td>-35</td>\n",
              "      <td>-39</td>\n",
              "      <td>-32</td>\n",
              "      <td>-13</td>\n",
              "      <td>7</td>\n",
              "      <td>34</td>\n",
              "      <td>41</td>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>-15</td>\n",
              "      <td>...</td>\n",
              "      <td>-54</td>\n",
              "      <td>-82</td>\n",
              "      <td>-107</td>\n",
              "      <td>-126</td>\n",
              "      <td>-124</td>\n",
              "      <td>-108</td>\n",
              "      <td>-84</td>\n",
              "      <td>-68</td>\n",
              "      <td>-61</td>\n",
              "      <td>-56</td>\n",
              "      <td>-63</td>\n",
              "      <td>-62</td>\n",
              "      <td>-33</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>45</td>\n",
              "      <td>37</td>\n",
              "      <td>48</td>\n",
              "      <td>62</td>\n",
              "      <td>80</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>-11</td>\n",
              "      <td>-39</td>\n",
              "      <td>-44</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-48</td>\n",
              "      <td>-42</td>\n",
              "      <td>-6</td>\n",
              "      <td>29</td>\n",
              "      <td>57</td>\n",
              "      <td>64</td>\n",
              "      <td>48</td>\n",
              "      <td>19</td>\n",
              "      <td>-12</td>\n",
              "      <td>-30</td>\n",
              "      <td>-35</td>\n",
              "      <td>-35</td>\n",
              "      <td>-36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-105</td>\n",
              "      <td>-101</td>\n",
              "      <td>-96</td>\n",
              "      <td>-92</td>\n",
              "      <td>-89</td>\n",
              "      <td>-95</td>\n",
              "      <td>-102</td>\n",
              "      <td>-100</td>\n",
              "      <td>-87</td>\n",
              "      <td>-79</td>\n",
              "      <td>-72</td>\n",
              "      <td>-68</td>\n",
              "      <td>-74</td>\n",
              "      <td>-80</td>\n",
              "      <td>-83</td>\n",
              "      <td>-73</td>\n",
              "      <td>-68</td>\n",
              "      <td>-61</td>\n",
              "      <td>-58</td>\n",
              "      <td>-59</td>\n",
              "      <td>-64</td>\n",
              "      <td>-79</td>\n",
              "      <td>-84</td>\n",
              "      <td>-97</td>\n",
              "      <td>-94</td>\n",
              "      <td>-84</td>\n",
              "      <td>-77</td>\n",
              "      <td>-75</td>\n",
              "      <td>-72</td>\n",
              "      <td>-68</td>\n",
              "      <td>-76</td>\n",
              "      <td>-76</td>\n",
              "      <td>-72</td>\n",
              "      <td>-67</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-67</td>\n",
              "      <td>-68</td>\n",
              "      <td>-69</td>\n",
              "      <td>...</td>\n",
              "      <td>-61</td>\n",
              "      <td>-69</td>\n",
              "      <td>-66</td>\n",
              "      <td>-74</td>\n",
              "      <td>-69</td>\n",
              "      <td>-61</td>\n",
              "      <td>-51</td>\n",
              "      <td>-45</td>\n",
              "      <td>-45</td>\n",
              "      <td>-49</td>\n",
              "      <td>-58</td>\n",
              "      <td>-64</td>\n",
              "      <td>-78</td>\n",
              "      <td>-80</td>\n",
              "      <td>-90</td>\n",
              "      <td>-87</td>\n",
              "      <td>-83</td>\n",
              "      <td>-78</td>\n",
              "      <td>-64</td>\n",
              "      <td>-38</td>\n",
              "      <td>-22</td>\n",
              "      <td>-29</td>\n",
              "      <td>-42</td>\n",
              "      <td>-51</td>\n",
              "      <td>-68</td>\n",
              "      <td>-71</td>\n",
              "      <td>-69</td>\n",
              "      <td>-69</td>\n",
              "      <td>-74</td>\n",
              "      <td>-74</td>\n",
              "      <td>-80</td>\n",
              "      <td>-82</td>\n",
              "      <td>-81</td>\n",
              "      <td>-80</td>\n",
              "      <td>-77</td>\n",
              "      <td>-85</td>\n",
              "      <td>-77</td>\n",
              "      <td>-72</td>\n",
              "      <td>-69</td>\n",
              "      <td>-65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9</td>\n",
              "      <td>-65</td>\n",
              "      <td>-98</td>\n",
              "      <td>-102</td>\n",
              "      <td>-78</td>\n",
              "      <td>-48</td>\n",
              "      <td>-16</td>\n",
              "      <td>0</td>\n",
              "      <td>-21</td>\n",
              "      <td>-59</td>\n",
              "      <td>-90</td>\n",
              "      <td>-103</td>\n",
              "      <td>-84</td>\n",
              "      <td>-43</td>\n",
              "      <td>-9</td>\n",
              "      <td>3</td>\n",
              "      <td>-21</td>\n",
              "      <td>-60</td>\n",
              "      <td>-96</td>\n",
              "      <td>-103</td>\n",
              "      <td>-75</td>\n",
              "      <td>-29</td>\n",
              "      <td>14</td>\n",
              "      <td>55</td>\n",
              "      <td>78</td>\n",
              "      <td>73</td>\n",
              "      <td>28</td>\n",
              "      <td>-13</td>\n",
              "      <td>-43</td>\n",
              "      <td>-68</td>\n",
              "      <td>-78</td>\n",
              "      <td>-75</td>\n",
              "      <td>-55</td>\n",
              "      <td>-41</td>\n",
              "      <td>-19</td>\n",
              "      <td>-20</td>\n",
              "      <td>-29</td>\n",
              "      <td>-36</td>\n",
              "      <td>-20</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>26</td>\n",
              "      <td>10</td>\n",
              "      <td>-4</td>\n",
              "      <td>-13</td>\n",
              "      <td>-8</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>29</td>\n",
              "      <td>57</td>\n",
              "      <td>63</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "      <td>-13</td>\n",
              "      <td>-23</td>\n",
              "      <td>-9</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>-12</td>\n",
              "      <td>-32</td>\n",
              "      <td>-41</td>\n",
              "      <td>-65</td>\n",
              "      <td>-83</td>\n",
              "      <td>-89</td>\n",
              "      <td>-73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11495</th>\n",
              "      <td>-22</td>\n",
              "      <td>-22</td>\n",
              "      <td>-23</td>\n",
              "      <td>-26</td>\n",
              "      <td>-36</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-49</td>\n",
              "      <td>-57</td>\n",
              "      <td>-64</td>\n",
              "      <td>-73</td>\n",
              "      <td>-79</td>\n",
              "      <td>-76</td>\n",
              "      <td>-70</td>\n",
              "      <td>-63</td>\n",
              "      <td>-57</td>\n",
              "      <td>-57</td>\n",
              "      <td>-50</td>\n",
              "      <td>-45</td>\n",
              "      <td>-34</td>\n",
              "      <td>-33</td>\n",
              "      <td>-32</td>\n",
              "      <td>-30</td>\n",
              "      <td>-24</td>\n",
              "      <td>-24</td>\n",
              "      <td>-18</td>\n",
              "      <td>-9</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-3</td>\n",
              "      <td>-5</td>\n",
              "      <td>-13</td>\n",
              "      <td>-23</td>\n",
              "      <td>-39</td>\n",
              "      <td>-53</td>\n",
              "      <td>-59</td>\n",
              "      <td>-63</td>\n",
              "      <td>...</td>\n",
              "      <td>34</td>\n",
              "      <td>45</td>\n",
              "      <td>55</td>\n",
              "      <td>60</td>\n",
              "      <td>69</td>\n",
              "      <td>68</td>\n",
              "      <td>58</td>\n",
              "      <td>54</td>\n",
              "      <td>44</td>\n",
              "      <td>40</td>\n",
              "      <td>38</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>32</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>25</td>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>-18</td>\n",
              "      <td>-37</td>\n",
              "      <td>-47</td>\n",
              "      <td>-48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11496</th>\n",
              "      <td>-47</td>\n",
              "      <td>-11</td>\n",
              "      <td>28</td>\n",
              "      <td>77</td>\n",
              "      <td>141</td>\n",
              "      <td>211</td>\n",
              "      <td>246</td>\n",
              "      <td>240</td>\n",
              "      <td>193</td>\n",
              "      <td>136</td>\n",
              "      <td>78</td>\n",
              "      <td>8</td>\n",
              "      <td>-66</td>\n",
              "      <td>-132</td>\n",
              "      <td>-180</td>\n",
              "      <td>-210</td>\n",
              "      <td>-227</td>\n",
              "      <td>-225</td>\n",
              "      <td>-212</td>\n",
              "      <td>-192</td>\n",
              "      <td>-168</td>\n",
              "      <td>-144</td>\n",
              "      <td>-117</td>\n",
              "      <td>-88</td>\n",
              "      <td>-54</td>\n",
              "      <td>-21</td>\n",
              "      <td>6</td>\n",
              "      <td>29</td>\n",
              "      <td>46</td>\n",
              "      <td>60</td>\n",
              "      <td>76</td>\n",
              "      <td>92</td>\n",
              "      <td>110</td>\n",
              "      <td>128</td>\n",
              "      <td>152</td>\n",
              "      <td>171</td>\n",
              "      <td>150</td>\n",
              "      <td>91</td>\n",
              "      <td>21</td>\n",
              "      <td>-29</td>\n",
              "      <td>...</td>\n",
              "      <td>68</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>38</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>75</td>\n",
              "      <td>165</td>\n",
              "      <td>260</td>\n",
              "      <td>343</td>\n",
              "      <td>406</td>\n",
              "      <td>456</td>\n",
              "      <td>471</td>\n",
              "      <td>461</td>\n",
              "      <td>412</td>\n",
              "      <td>319</td>\n",
              "      <td>175</td>\n",
              "      <td>-5</td>\n",
              "      <td>-171</td>\n",
              "      <td>-293</td>\n",
              "      <td>-357</td>\n",
              "      <td>-378</td>\n",
              "      <td>-370</td>\n",
              "      <td>-346</td>\n",
              "      <td>-316</td>\n",
              "      <td>-278</td>\n",
              "      <td>-241</td>\n",
              "      <td>-201</td>\n",
              "      <td>-162</td>\n",
              "      <td>-126</td>\n",
              "      <td>-94</td>\n",
              "      <td>-65</td>\n",
              "      <td>-33</td>\n",
              "      <td>-7</td>\n",
              "      <td>14</td>\n",
              "      <td>27</td>\n",
              "      <td>48</td>\n",
              "      <td>77</td>\n",
              "      <td>117</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11497</th>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>-13</td>\n",
              "      <td>-16</td>\n",
              "      <td>10</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>-9</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>-1</td>\n",
              "      <td>-10</td>\n",
              "      <td>14</td>\n",
              "      <td>44</td>\n",
              "      <td>77</td>\n",
              "      <td>61</td>\n",
              "      <td>42</td>\n",
              "      <td>32</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "      <td>26</td>\n",
              "      <td>35</td>\n",
              "      <td>81</td>\n",
              "      <td>66</td>\n",
              "      <td>50</td>\n",
              "      <td>57</td>\n",
              "      <td>91</td>\n",
              "      <td>121</td>\n",
              "      <td>111</td>\n",
              "      <td>73</td>\n",
              "      <td>38</td>\n",
              "      <td>23</td>\n",
              "      <td>35</td>\n",
              "      <td>21</td>\n",
              "      <td>11</td>\n",
              "      <td>-12</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>61</td>\n",
              "      <td>88</td>\n",
              "      <td>...</td>\n",
              "      <td>-78</td>\n",
              "      <td>-90</td>\n",
              "      <td>-62</td>\n",
              "      <td>-38</td>\n",
              "      <td>-40</td>\n",
              "      <td>-21</td>\n",
              "      <td>-23</td>\n",
              "      <td>-11</td>\n",
              "      <td>-4</td>\n",
              "      <td>-9</td>\n",
              "      <td>-22</td>\n",
              "      <td>-42</td>\n",
              "      <td>-49</td>\n",
              "      <td>-48</td>\n",
              "      <td>-40</td>\n",
              "      <td>-40</td>\n",
              "      <td>-46</td>\n",
              "      <td>-43</td>\n",
              "      <td>-67</td>\n",
              "      <td>-67</td>\n",
              "      <td>-50</td>\n",
              "      <td>-18</td>\n",
              "      <td>-14</td>\n",
              "      <td>-39</td>\n",
              "      <td>-74</td>\n",
              "      <td>-86</td>\n",
              "      <td>-75</td>\n",
              "      <td>-68</td>\n",
              "      <td>-57</td>\n",
              "      <td>-78</td>\n",
              "      <td>-42</td>\n",
              "      <td>-65</td>\n",
              "      <td>-48</td>\n",
              "      <td>-61</td>\n",
              "      <td>-62</td>\n",
              "      <td>-67</td>\n",
              "      <td>-30</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11498</th>\n",
              "      <td>-40</td>\n",
              "      <td>-25</td>\n",
              "      <td>-9</td>\n",
              "      <td>-12</td>\n",
              "      <td>-2</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>22</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>-28</td>\n",
              "      <td>-37</td>\n",
              "      <td>-35</td>\n",
              "      <td>-35</td>\n",
              "      <td>-45</td>\n",
              "      <td>-64</td>\n",
              "      <td>-105</td>\n",
              "      <td>-140</td>\n",
              "      <td>-157</td>\n",
              "      <td>-157</td>\n",
              "      <td>-147</td>\n",
              "      <td>-153</td>\n",
              "      <td>-147</td>\n",
              "      <td>-126</td>\n",
              "      <td>-112</td>\n",
              "      <td>-83</td>\n",
              "      <td>-56</td>\n",
              "      <td>-41</td>\n",
              "      <td>-40</td>\n",
              "      <td>-38</td>\n",
              "      <td>-34</td>\n",
              "      <td>-47</td>\n",
              "      <td>-41</td>\n",
              "      <td>-40</td>\n",
              "      <td>-42</td>\n",
              "      <td>-49</td>\n",
              "      <td>-56</td>\n",
              "      <td>...</td>\n",
              "      <td>-120</td>\n",
              "      <td>-98</td>\n",
              "      <td>-77</td>\n",
              "      <td>-60</td>\n",
              "      <td>-73</td>\n",
              "      <td>-88</td>\n",
              "      <td>-97</td>\n",
              "      <td>-118</td>\n",
              "      <td>-108</td>\n",
              "      <td>-100</td>\n",
              "      <td>-97</td>\n",
              "      <td>-91</td>\n",
              "      <td>-109</td>\n",
              "      <td>-122</td>\n",
              "      <td>-134</td>\n",
              "      <td>-137</td>\n",
              "      <td>-107</td>\n",
              "      <td>-95</td>\n",
              "      <td>-67</td>\n",
              "      <td>-54</td>\n",
              "      <td>-40</td>\n",
              "      <td>-31</td>\n",
              "      <td>-19</td>\n",
              "      <td>7</td>\n",
              "      <td>22</td>\n",
              "      <td>46</td>\n",
              "      <td>68</td>\n",
              "      <td>87</td>\n",
              "      <td>97</td>\n",
              "      <td>105</td>\n",
              "      <td>114</td>\n",
              "      <td>121</td>\n",
              "      <td>135</td>\n",
              "      <td>148</td>\n",
              "      <td>143</td>\n",
              "      <td>116</td>\n",
              "      <td>86</td>\n",
              "      <td>68</td>\n",
              "      <td>59</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11499</th>\n",
              "      <td>29</td>\n",
              "      <td>41</td>\n",
              "      <td>57</td>\n",
              "      <td>72</td>\n",
              "      <td>74</td>\n",
              "      <td>62</td>\n",
              "      <td>54</td>\n",
              "      <td>43</td>\n",
              "      <td>31</td>\n",
              "      <td>23</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>-3</td>\n",
              "      <td>-5</td>\n",
              "      <td>-9</td>\n",
              "      <td>-14</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>60</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>50</td>\n",
              "      <td>33</td>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>-5</td>\n",
              "      <td>-4</td>\n",
              "      <td>-8</td>\n",
              "      <td>-15</td>\n",
              "      <td>-13</td>\n",
              "      <td>-2</td>\n",
              "      <td>21</td>\n",
              "      <td>39</td>\n",
              "      <td>48</td>\n",
              "      <td>37</td>\n",
              "      <td>10</td>\n",
              "      <td>-23</td>\n",
              "      <td>-47</td>\n",
              "      <td>-71</td>\n",
              "      <td>...</td>\n",
              "      <td>-107</td>\n",
              "      <td>-108</td>\n",
              "      <td>-83</td>\n",
              "      <td>-46</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>39</td>\n",
              "      <td>44</td>\n",
              "      <td>33</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>-13</td>\n",
              "      <td>-33</td>\n",
              "      <td>-61</td>\n",
              "      <td>-70</td>\n",
              "      <td>-75</td>\n",
              "      <td>-74</td>\n",
              "      <td>-58</td>\n",
              "      <td>-18</td>\n",
              "      <td>19</td>\n",
              "      <td>54</td>\n",
              "      <td>71</td>\n",
              "      <td>76</td>\n",
              "      <td>74</td>\n",
              "      <td>65</td>\n",
              "      <td>56</td>\n",
              "      <td>18</td>\n",
              "      <td>-28</td>\n",
              "      <td>-75</td>\n",
              "      <td>-98</td>\n",
              "      <td>-94</td>\n",
              "      <td>-59</td>\n",
              "      <td>-25</td>\n",
              "      <td>-4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>-2</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11500 rows × 178 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        X1   X2   X3   X4   X5   X6  ...  X173  X174  X175  X176  X177  X178\n",
              "0      135  190  229  223  192  125  ...   -77  -103  -127  -116   -83   -51\n",
              "1      386  382  356  331  320  315  ...   152   157   156   154   143   129\n",
              "2      -32  -39  -47  -37  -32  -36  ...    19   -12   -30   -35   -35   -36\n",
              "3     -105 -101  -96  -92  -89  -95  ...   -77   -85   -77   -72   -69   -65\n",
              "4       -9  -65  -98 -102  -78  -48  ...   -32   -41   -65   -83   -89   -73\n",
              "...    ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ...   ...\n",
              "11495  -22  -22  -23  -26  -36  -42  ...     5    -1   -18   -37   -47   -48\n",
              "11496  -47  -11   28   77  141  211  ...    14    27    48    77   117   170\n",
              "11497   14    6  -13  -16   10   26  ...   -62   -67   -30    -2    -1    -8\n",
              "11498  -40  -25   -9  -12   -2   12  ...   143   116    86    68    59    55\n",
              "11499   29   41   57   72   74   62  ...     2     5     4    -2     2    20\n",
              "\n",
              "[11500 rows x 178 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRFK2k4GqnHQ",
        "colab_type": "text"
      },
      "source": [
        "6. Δεν υπάρχουν απουσιάζουσες τιμές.\n",
        "7. Χρησιμοποιούμε την bincount για να μετρήσουμε τη συχνότητα των κατηγοριών. Παρατηρούμε οτι έχουμε ενα εξαιρετικά ισορροπημένο dataset. Και οι 5 κατηγορίες είναι ισοπληθείς. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1haboerrVVO",
        "colab_type": "code",
        "outputId": "a3fda0ec-db73-40a9-c54c-797c81fd3c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"frequencies:\", np.bincount(labels)[1:])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequencies: [2300 2300 2300 2300 2300]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rSqNc93uKNc",
        "colab_type": "text"
      },
      "source": [
        "8. Διαχωρίζουμε σε train και test set. Οι τιμές των χαρακτηριστικών αφορούν τα εγκεφαλικά σήματα (τάσεις), άρα είναι διατεταγμένα."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSBGq46YuZ0K",
        "colab_type": "code",
        "outputId": "c36ec9d2-9bfe-4136-8bbc-9635453f2b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test, train_labels, test_labels = train_test_split(df, labels, test_size=0.3)\n",
        "print(len(train))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjCK0y1KwrOX",
        "colab_type": "text"
      },
      "source": [
        "# Γ. Baseline Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Im4uxp-MXUd",
        "colab_type": "text"
      },
      "source": [
        "##### Dummy Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxApc9Auw5eR",
        "colab_type": "text"
      },
      "source": [
        "Εκπαιδεύουμε τους classifiers με τις default τιμές για να δούμε συγκρίνουμε τα αποτέλεσματα πριν και μετά την προεργασία. <br>\n",
        "\n",
        "Αρχίζουμε με τους Dummy Classifiers. Παρατηρούμε οτι επιτυγχάνουμε σε όλους περίπου 20% επιτυχία, όπως ήταν αναμενόμενο καθώς έχουμε 5 κατηγορίες."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm5JMFaGxRSV",
        "colab_type": "code",
        "outputId": "49cad9a2-615e-42fc-e0d7-75437e4a6ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "dc_uniform = DummyClassifier(strategy=\"uniform\")\n",
        "dc_constant_1 = DummyClassifier(strategy=\"constant\", constant=1)\n",
        "dc_constant_2 = DummyClassifier(strategy=\"constant\", constant=2)\n",
        "dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
        "dc_stratified = DummyClassifier(strategy=\"stratified\")\n",
        "\n",
        "#using fit to train the classifiers\n",
        "model_uniform = dc_uniform.fit(train, train_labels)\n",
        "model_constant_1 = dc_constant_1.fit(train, train_labels)\n",
        "model_constant_2 = dc_constant_2.fit(train, train_labels)\n",
        "model_most_frequent = dc_most_frequent.fit(train, train_labels)\n",
        "model_stratified = dc_stratified.fit(train, train_labels)\n",
        "\n",
        "#now we make our predictions\n",
        "preds_uniform = dc_uniform.predict(test)\n",
        "preds_constant_1 = dc_constant_1.predict(test)\n",
        "preds_constant_2 = dc_constant_2.predict(test)\n",
        "preds_most_frequent = dc_most_frequent.predict(test)\n",
        "preds_stratified = dc_stratified.predict(test)\n",
        "\n",
        "#print prediction accuracy\n",
        "accuracy = {}\n",
        "print(\"Uniform Classifier: \", accuracy_score(test_labels, preds_uniform))\n",
        "print(\"Constant Classifier (1): \", accuracy_score(test_labels, preds_constant_1))\n",
        "print(\"Constant Classifier (2): \", accuracy_score(test_labels, preds_constant_2))\n",
        "print(\"Most Frequent Classifier: \", accuracy_score(test_labels, preds_most_frequent))\n",
        "print(\"Stratified Classifier: \", accuracy_score(test_labels, preds_stratified))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uniform Classifier:  0.1936231884057971\n",
            "Constant Classifier (1):  0.20231884057971014\n",
            "Constant Classifier (2):  0.20115942028985506\n",
            "Most Frequent Classifier:  0.19507246376811593\n",
            "Stratified Classifier:  0.19884057971014493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDrfn2dg6OgQ",
        "colab_type": "text"
      },
      "source": [
        "Εκτυπώνουμε τον confusion matrix. Ο $C$ είναι ο πίνακας για τον οποίο ισχύει οτι $C_{i, j}$ είναι τα δείγματα της κατηγορίας $i$ που ταξινομήθηκαν στην $j$. Όπως φαίνεται οι Uniform και Stratified προβλέπουν οποιαδήποτε κατηγορία, ενώ οι άλλοι 3 είτε επιλέγουν σταθερά μία κατηγορία είτε αυτή με τα περισσότερα δείγματα. Μάλιστα, από τη στιγμή που τα δείγματα στο αρχικό data set είναι ίσα μεταξύ τους, τα πολυπληθέστερα δείγματα στο train set θα είναι τα λιγότερο πολυπληθή στο test set. Άρα ο classifier αυτός θα έχει χειρότερη επίδοση από τους constant classifiers, όπως φαίνεται και από τον confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMuRq4wD53zy",
        "colab_type": "code",
        "outputId": "9a5828c9-228c-4e9f-e6f1-a91a3508b6ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "#produce confusion matrices\n",
        "cnf_matrix_uniform = confusion_matrix(test_labels, preds_uniform)\n",
        "cnf_matrix_constant_1 = confusion_matrix(test_labels, preds_constant_1)\n",
        "cnf_matrix_constant_2 = confusion_matrix(test_labels, preds_constant_2)\n",
        "cnf_matrix_most_frequent = confusion_matrix(test_labels, preds_most_frequent)\n",
        "cnf_matrix_stratified = confusion_matrix(test_labels, preds_stratified)\n",
        "\n",
        "#print confusion matrices\n",
        "print(\"Uniform Classifier Confusion Matrix\\n\")\n",
        "print(cnf_matrix_uniform, \"\\n\")\n",
        "print(\"Constant Classifier (1) Confusion Matrix\\n\")\n",
        "print(cnf_matrix_constant_1, \"\\n\")\n",
        "print(\"Constant Classifier (2) Confusion Matrix\\n\")\n",
        "print(cnf_matrix_constant_2, \"\\n\")\n",
        "print(\"Most Frequent Classifier Confusion Matrix\\n\")\n",
        "print(cnf_matrix_most_frequent, \"\\n\")\n",
        "print(\"Stratified Classifier Confusion Matrix\\n\")\n",
        "print(cnf_matrix_stratified, \"\\n\")\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uniform Classifier Confusion Matrix\n",
            "\n",
            "[[125 131 160 141 141]\n",
            " [122 154 146 145 127]\n",
            " [145 142 141 125 134]\n",
            " [154 129 138 131 146]\n",
            " [144 135 140 137 117]] \n",
            "\n",
            "Constant Classifier (1) Confusion Matrix\n",
            "\n",
            "[[698   0   0   0   0]\n",
            " [694   0   0   0   0]\n",
            " [687   0   0   0   0]\n",
            " [698   0   0   0   0]\n",
            " [673   0   0   0   0]] \n",
            "\n",
            "Constant Classifier (2) Confusion Matrix\n",
            "\n",
            "[[  0 698   0   0   0]\n",
            " [  0 694   0   0   0]\n",
            " [  0 687   0   0   0]\n",
            " [  0 698   0   0   0]\n",
            " [  0 673   0   0   0]] \n",
            "\n",
            "Most Frequent Classifier Confusion Matrix\n",
            "\n",
            "[[  0   0   0   0 698]\n",
            " [  0   0   0   0 694]\n",
            " [  0   0   0   0 687]\n",
            " [  0   0   0   0 698]\n",
            " [  0   0   0   0 673]] \n",
            "\n",
            "Stratified Classifier Confusion Matrix\n",
            "\n",
            "[[143 138 133 139 145]\n",
            " [154 148 136 129 127]\n",
            " [136 136 129 138 148]\n",
            " [135 144 153 125 141]\n",
            " [139 130 137 126 141]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-GmyVk19rYV",
        "colab_type": "text"
      },
      "source": [
        "Εκτύπωση f1-micro average και f1-macro average.\n",
        "\n",
        "Η ακρίβεια αφορά την ικανότητα του εκτιμητή να εκτιμά ως δείγματα του test set που ανήκουν στη θετική κλάση μόνο αυτά που όντως ανήκουν.<br>\n",
        "Precision: $$P = \\frac{T_p}{T_p+F_p}$$\n",
        "\n",
        "Η ανάκληση αφορά την ικανότητα του εκτιμητή να εντοπίζει όλα τα δείγματα που ανήκουν στη θετική κλάση.<br>\n",
        "Recall: $$R = \\frac{T_p}{T_p + F_n}$$\n",
        "\n",
        "F1 score είναι ο αρμονικός μέσος όρος αυτών των δύο.<br>\n",
        "F1: $$F1 = 2\\frac{P \\times R}{P+R}$$\n",
        "\n",
        "Macro average: υπολογίζει f1 ξεχωριστά για κάθε κλάση και παίρνει τον μέσο όρο. Άρα κάθε κλάση αντιμετωπίζεται ισότιμα.\n",
        "\n",
        "Micro average: ενσωματώνει την πληροφορία για τον αριθμό των δειγμάτων που ανήκουν σε κάθε κλάση, χρησιμοποιώντας τις πραγματικές ποσότητες $T_p$, $F_p$, $F_n$ στον συνολικό υπολογισμό. Άρα είναι προτιμότερη όταν μία κλάση περιέχει αρκετά περισσότερα δείγματα."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXpKTfVv3xY6",
        "colab_type": "code",
        "outputId": "50c95408-0d0b-48b9-8140-95ecb2893861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#f1-micro\n",
        "print('\\033[1m' + \"f1-micro\" + '\\033[0m')\n",
        "print(\"Uniform Classifier: \", precision_recall_fscore_support(test_labels, preds_uniform, average='micro'))\n",
        "print(\"Constant Classifier (1): \", precision_recall_fscore_support(test_labels, preds_constant_1, average='micro'))\n",
        "print(\"Constant Classifier (2): \", precision_recall_fscore_support(test_labels, preds_constant_2, average='micro'))\n",
        "print(\"Most Frequent Classifier: \", precision_recall_fscore_support(test_labels, preds_most_frequent, average='micro'))\n",
        "print(\"Stratified Classifier: \", precision_recall_fscore_support(test_labels, preds_stratified, average='micro'), \"\\n\")\n",
        "\n",
        "\n",
        "#f1-macro\n",
        "print('\\033[1m' + \"f1-macro\" + '\\033[0m')\n",
        "print(\"Uniform Classifier: \", precision_recall_fscore_support(test_labels, preds_uniform, average='macro'))\n",
        "print(\"Constant Classifier (1): \", precision_recall_fscore_support(test_labels, preds_constant_1, average='macro'))\n",
        "print(\"Constant Classifier (2): \", precision_recall_fscore_support(test_labels, preds_constant_2, average='macro'))\n",
        "print(\"Most Frequent Classifier: \", precision_recall_fscore_support(test_labels, preds_most_frequent, average='macro'))\n",
        "print(\"Stratified Classifier: \", precision_recall_fscore_support(test_labels, preds_stratified, average='macro'))\n",
        "\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mf1-micro\u001b[0m\n",
            "Uniform Classifier:  (0.1936231884057971, 0.1936231884057971, 0.19362318840579712, None)\n",
            "Constant Classifier (1):  (0.20231884057971014, 0.20231884057971014, 0.20231884057971014, None)\n",
            "Constant Classifier (2):  (0.20115942028985506, 0.20115942028985506, 0.20115942028985506, None)\n",
            "Most Frequent Classifier:  (0.19507246376811593, 0.19507246376811593, 0.19507246376811593, None)\n",
            "Stratified Classifier:  (0.19884057971014493, 0.19884057971014493, 0.19884057971014493, None) \n",
            "\n",
            "\u001b[1mf1-macro\u001b[0m\n",
            "Uniform Classifier:  (0.19347564430799644, 0.19355056188713582, 0.19347425031713672, None)\n",
            "Constant Classifier (1):  (0.04046376811594203, 0.2, 0.06730954676952748, None)\n",
            "Constant Classifier (2):  (0.04023188405797101, 0.2, 0.06698841698841698, None)\n",
            "Most Frequent Classifier:  (0.03901449275362319, 0.2, 0.0652922629153529, None)\n",
            "Stratified Classifier:  (0.19870404287388205, 0.1988986445776997, 0.19874749537894051, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9DNzplOMs95",
        "colab_type": "text"
      },
      "source": [
        "##### Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1oeCSNONCxB",
        "colab_type": "text"
      },
      "source": [
        "Ο Gaussian Nauve Bayes υποθέτει οτι τα χαρακτηριστικά είναι ανεξάρτητα μεταξύ τους. Έτσι συνδέει κάθε χαρακτηριστικό $x_i$ με κάθε κλάση $y$ με την πιθανότητα $P(x_i \\mid y)$, η οποία υποθέτει πως ακολουθεί γκαουσιανή κατανομή. Χρησιμοποιεί τα δεδομένα προκειμένου για κάθε κλάση και χαρακτηριστικό, το οποίο παίρνει συνεχείς τιμές, να βρει τη μέση τιμή $\\mu_y$ και τη διακύμανση $\\sigma^2_y$ κάθε χαρακτηριστικού για τη κλάση $y$. Στην φάση του testing λαμβάνει υπόψην του τα γινόμενα των παραπάνω πιθανοτήτων των χαρακτηριστικών για κάθε κλάση, καθώς και την πιθανότητα της ίδιας της κλάσης και αναθέτει στο δείγμα την κλάση που μεγιστοποιεί το τελικό γινόμενο.\n",
        "\n",
        "Παρατηρούμε πως η ενσωμάτωση πληροφορίας, ακόμα και όταν έχουμε κάνει τις παραπάνω υποθέσεις υπερδιπλασιάζει την ακρίβεια των προβλέψεών μας.\n",
        "\n",
        "Επίσης, όπως φαίνεται από το confusion matrix υπάρχει αναθέτει πολλά δείγματα στην πέμπτη κλάση. Ωστόσο επιτυγχάνει σε μεγάλο βαθμό να εντοπίσει τις επιληπτικές κρίσεις (πρώτη κλάση)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej7lvLW_O8sm",
        "colab_type": "code",
        "outputId": "8cd6d463-4543-4fbb-8c8e-c13c59421da5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "\n",
        "#finding mean values and variations\n",
        "model_GNB = gnb.fit(train, train_labels)\n",
        "\n",
        "#making predictions\n",
        "preds = {}\n",
        "preds[\"Gaussian Naive Bayes\"] = gnb.predict(test)\n",
        "\n",
        "#calculate and print prediction accuracy\n",
        "accuracy = {}\n",
        "accuracy[\"Gaussian Naive Bayes\"] = accuracy_score(test_labels, preds[\"Gaussian Naive Bayes\"])\n",
        "print(\"Gaussian Naive Bayes: \", accuracy[\"Gaussian Naive Bayes\"], \"\\n\")\n",
        "\n",
        "#produce and print confusion matrix\n",
        "cnf_matrix_GNB = confusion_matrix(test_labels, preds[\"Gaussian Naive Bayes\"])\n",
        "print('\\033[1m' + \"Gaussian Naive Bayes - Confusion Matrix\" + '\\033[0m')\n",
        "print(cnf_matrix_GNB, \"\\n\")\n",
        "\n",
        "#f1-micro/macro\n",
        "print('\\033[1m' + \"f1-micro\" + '\\033[0m')\n",
        "print(\"Gaussian Naive Bayes: \", precision_recall_fscore_support(test_labels, preds[\"Gaussian Naive Bayes\"], average='micro'))\n",
        "print('\\033[1m' + \"f1-macro\" + '\\033[0m')\n",
        "print(\"Gaussian Naive Bayes: \", precision_recall_fscore_support(test_labels, preds[\"Gaussian Naive Bayes\"], average='macro'))\n",
        "\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gaussian Naive Bayes:  0.443768115942029 \n",
            "\n",
            "\u001b[1mGaussian Naive Bayes - Confusion Matrix\u001b[0m\n",
            "[[586 109   0   3   0]\n",
            " [ 43 114  94  89 354]\n",
            " [  2  85 125 118 357]\n",
            " [  0 161 121 195 221]\n",
            " [  0  31  80  51 511]] \n",
            "\n",
            "\u001b[1mf1-micro\u001b[0m\n",
            "Gaussian Naive Bayes:  (0.443768115942029, 0.443768115942029, 0.443768115942029, None)\n",
            "\u001b[1mf1-macro\u001b[0m\n",
            "Gaussian Naive Bayes:  (0.4472117216530095, 0.44488271791220485, 0.4239196274192298, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTnReOvNU069",
        "colab_type": "text"
      },
      "source": [
        "##### kNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NTWOpQ3U8mN",
        "colab_type": "text"
      },
      "source": [
        "Ο kNN υπολογίζει, για κάθε δείγμα του test set, τους k κοντινότερους γείτονές του, οι οποίοι είναι δείγματα του train set, στον n-διάστατο χώρο διαστάσεων των χαρακτηριστικών εισόδου. Αποφασίζει την κλάση του νέου δείγματα παίρνοντας είτε την πλειοψηφία των γειτόνων είτε λαμβάνοντας υπόψην και τις αποστάσεις του από αυτούς. Ως συνάρτηση απόστασης χρησιμοποιείται κυρίως η ευκλείδια. <br>\n",
        "Εξαιρετικά σημαντική για την απόδοσή του είναι η υπερπαράμετρος k. \n",
        "\n",
        "Το γεγονός οτι πρέπει να συγκρίνουμε την απόσταση κάθε νέου δείγματος στο train set με το νέο δείγμα καθιστά τη διαδικασία πρόβλεψης πολύ χρονοβόρα.\n",
        "Ωστόσο, η μεγάλη διαφορά από τον GNB είναι οτι δεν κάνει υποθέσεις για τις εξαρτήσεις των χαρακτηριστικών και τις κατανομές των πιθανοτήτων.\n",
        "\n",
        "Παρατηρούμε οτι επιτυγχάνει καλύτερες προβλέψεις από τον GNB, ωστόσο το ποσοστό είναι ακόμα χαμηλό."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6CGWaoHypKR",
        "colab_type": "code",
        "outputId": "62cc067f-76e4-4e59-d073-0586ce3e2e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5) #setting k to 5\n",
        "\n",
        "#saves training samples and their labels\n",
        "knn.fit(train, train_labels)\n",
        "\n",
        "#making predictions\n",
        "preds[\"kNN\"] = knn.predict(test)\n",
        "\n",
        "#calculate and print prediction accuracy\n",
        "accuracy[\"kNN\"] = accuracy_score(test_labels, preds[\"kNN\"])\n",
        "print(\"kNN: \", accuracy[\"kNN\"])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kNN:  0.46840579710144925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T80Gv0FLXxkP",
        "colab_type": "code",
        "outputId": "3de07d7c-ad77-4441-d03d-b4b2e08fdeda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#produce and print confusion matrix\n",
        "cnf_matrix_GNB = confusion_matrix(test_labels, preds[\"kNN\"])\n",
        "print('\\033[1m' + \"kNN - Confusion Matrix\" + '\\033[0m')\n",
        "print(cnf_matrix_GNB, \"\\n\")\n",
        "\n",
        "#f1-micro/macro\n",
        "print('\\033[1m' + \"f1-micro\" + '\\033[0m')\n",
        "print(\"kNN: \", precision_recall_fscore_support(test_labels, preds[\"kNN\"], average='micro'))\n",
        "print('\\033[1m' + \"f1-macro\" + '\\033[0m')\n",
        "print(\"kNN: \", precision_recall_fscore_support(test_labels, preds[\"kNN\"], average='macro'))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mkNN - Confusion Matrix\u001b[0m\n",
            "[[480 107  74  32   5]\n",
            " [  2 445 243   0   4]\n",
            " [  0 234 444   1   8]\n",
            " [  0 173 213 186 126]\n",
            " [  0 282 329   1  61]] \n",
            "\n",
            "\u001b[1mf1-micro\u001b[0m\n",
            "kNN:  (0.46840579710144925, 0.46840579710144925, 0.46840579710144925, None)\n",
            "\u001b[1mf1-macro\u001b[0m\n",
            "kNN:  (0.5679317350196911, 0.46645844844078, 0.45281563214582343, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHUP3bqgYgPZ",
        "colab_type": "text"
      },
      "source": [
        "##### Multi Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpMovT_TYxWN",
        "colab_type": "text"
      },
      "source": [
        "Ένα MLP περιέχει το input layer, το οποίο δέχεται τις εισόδους, 1 ή περισσότερα ενδιάμεσα επίπεδα, τα οποία αποτελούνται από νευρώνες που δέχονται εισόδους από τους νευρώνες του προηγούμενου επιπέδου, εφαρμόζουν βάρη σε αυτές και τις προσθέτουν μαζί με ένα bias. Μετά εφαρμόζουν στο αποτέλεσμα μία μη γραμμική συνάρτηση δημιουργώντας έτσι την έξοδο που προωθείται στο επόμενο επίπεδο. Στο τέλος έχουν ένα output layer, το οποίο κάνει και την τελική απόφαση.\n",
        "\n",
        "Κατά την εκπαίδευσή τους, ελαχιστοποιούν ένα κριτήριο αλλάζοντας τις τιμές των βαρών και των biases τους. \n",
        "\n",
        "Παρατηρούμε οτι δεν αποδίδει καλύτερα ούτε από τους Dummy Classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EI0siWOYybR",
        "colab_type": "code",
        "outputId": "122e6ed8-8f46-4a95-8a4d-198ea11f7c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,), random_state=1)\n",
        "\n",
        "#training\n",
        "clf.fit(train, train_labels)\n",
        "\n",
        "#predicting\n",
        "preds[\"Multi Layer Perceptron\"] = clf.predict(test)\n",
        "\n",
        "#calculate and print prediction accuracy\n",
        "accuracy[\"Multi Layer Perceptron\"] = accuracy_score(test_labels, preds[\"Multi Layer Perceptron\"])\n",
        "print(\"Multi Layer Perceptron: \", accuracy[\"Multi Layer Perceptron\"])\n",
        "\n",
        "#produce and print confusion matrix\n",
        "cnf_matrix_GNB = confusion_matrix(test_labels, preds[\"Multi Layer Perceptron\"])\n",
        "print('\\033[1m' + \"Multi Layer Perceptron - Confusion Matrix\" + '\\033[0m')\n",
        "print(cnf_matrix_GNB, \"\\n\")\n",
        "\n",
        "#f1-micro/macro\n",
        "print('\\033[1m' + \"f1-micro\" + '\\033[0m')\n",
        "print(\"Multi Layer Perceptron: \", precision_recall_fscore_support(test_labels, preds[\"Multi Layer Perceptron\"], average='micro'))\n",
        "print('\\033[1m' + \"f1-macro\" + '\\033[0m')\n",
        "print(\"Multi Layer Perceptron: \", precision_recall_fscore_support(test_labels, preds[\"Multi Layer Perceptron\"], average='macro'))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multi Layer Perceptron:  0.19246376811594204\n",
            "\u001b[1mMulti Layer Perceptron - Confusion Matrix\u001b[0m\n",
            "[[206 292  23 139  38]\n",
            " [214 304  11 148  17]\n",
            " [181 309   8 171  18]\n",
            " [183 342  23 123  27]\n",
            " [214 299  25 112  23]] \n",
            "\n",
            "\u001b[1mf1-micro\u001b[0m\n",
            "Multi Layer Perceptron:  (0.19246376811594204, 0.19246376811594204, 0.19246376811594204, None)\n",
            "\u001b[1mf1-macro\u001b[0m\n",
            "Multi Layer Perceptron:  (0.17128384863799656, 0.19104144352436797, 0.1539170502486155, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX772lpRoiU3",
        "colab_type": "text"
      },
      "source": [
        "##### Bar Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jpkyE-Jon2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "7cab02a8-5272-45c0-d834-61d68bc1b5dd"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n_groups = 5\n",
        "f1_micro = (f1_score(test_labels, preds_uniform, average = 'micro'), \n",
        "            f1_score(test_labels, preds_most_frequent, average = 'micro'), \n",
        "            f1_score(test_labels, preds[\"Gaussian Naive Bayes\"], average = 'micro'), \n",
        "            f1_score(test_labels, preds[\"kNN\"], average = 'micro'),  \n",
        "            f1_score(test_labels, preds[\"Multi Layer Perceptron\"], average = 'micro'))\n",
        "\n",
        "f1_macro = (f1_score(test_labels, preds_uniform, average = 'macro'), \n",
        "            f1_score(test_labels, preds_most_frequent, average = 'macro'), \n",
        "            f1_score(test_labels, preds[\"Gaussian Naive Bayes\"], average = 'macro'), \n",
        "            f1_score(test_labels, preds[\"kNN\"], average = 'macro'),  \n",
        "            f1_score(test_labels, preds[\"Multi Layer Perceptron\"], average = 'macro'))\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "index = np.arange(n_groups)\n",
        "bar_width = 0.2\n",
        "opacity = 0.6\n",
        "\n",
        "rects1 = plt.bar(index, f1_micro, bar_width,\n",
        "alpha=opacity,\n",
        "color='b',\n",
        "label='F1 micro')\n",
        "\n",
        "rects2 = plt.bar(index + bar_width, f1_macro, bar_width,\n",
        "alpha=opacity,\n",
        "color='g',\n",
        "label='F1 macro')\n",
        "\n",
        "plt.xlabel('Classifier')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Scores by classifier')\n",
        "plt.xticks(index + bar_width, (\"Uniform\", \"Most Frequent\", \"GNB\", \"kNN\", \"MLP\"))\n",
        "plt.legend()\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pgkrMU6t6sE",
        "colab_type": "text"
      },
      "source": [
        "Σχεδόν σε όλες τις περιπτώσεις τα precision είναι σχεδόν ίσα με τα recall, που οδηγεί και σε κοντινούς f1 μέσους όρους. Επίσης όπως φαίνεται από τα confusion matrices οι kNN και GNB βρίσκουν επιτυχώς την πρώτη κλάση, που δηλώνει την επιληπτική κρίση αλλά όχι τόσο επιτυχώς τις άλλες. Αυτό σημαίνει οτι τα δεδομένα με ετικέτα 1 έιναι πολύ καλύτερα διαχωρισμένα από τα υπόλοιπα. Φαίνεται λοιπόν ο λόγος για τον οποίο το dataset χρησιμοποιείται και για binary classification.\n",
        "\n",
        "Η απόδοση του perceptron είναι πολύ χαμηλή σε όλες τις μετρικές, γεγονός που υποδεικνύει την ανάγκη για προεργασία των δεδομένων στα νευρωνικά δίκτυα."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T02fDOdhs5p",
        "colab_type": "text"
      },
      "source": [
        "# Δ. Βελτιστοποίηση Ταξινομητών"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSSO7UFShzfL",
        "colab_type": "text"
      },
      "source": [
        "Χρησιμοποιούμε την διαδικασία pipeline για την εφαρμογή διαδοχικών δεν υπάρχει μεγάλη ανάγκη για εφαρμογή oversampling ή undersampling. Αυτό επιβεβαιώθηκε όταν κάναμε τις ανάλογες δοκιμές. \n",
        "\n",
        "* Λόγω του ισορροπημένου dataset, όπως φαίνεται και παρακάτω, δεν χρειάζεται να χρησιμοποιήσουμε oversampler ή undersampler.\n",
        "\n",
        "* Διαστατικότητα: Χρησιμοποιούμε τον μετασχηματιστή VarianceThreshold, ο οποίος μειώνει τον αριθμό των χαρακτηριστικών με βάση την διακύμανση των τιμών του στα δείγματα (επιλογή χαρακτηριστικών). Όταν η διακύμανση είναι μικρή θεωρούμε οτι το χαρακτηριστικό δεν προσφέρει πολλή πληροφορία για την κατηγοριοποίηση. <br>\n",
        "Επίσης χρησιμοποιούμε τον PCA για την ανάλυση των δεδομένων σε κύριες συνιστώσες και την χρήση των συνιστωσών με την περισσότερη διακύμανση (εξαγωγή χαρακτηριστικών), δηλαδή πληροφορία. \n",
        "\n",
        "* Κανονικοποίηση: Αμβλύνουμε τις διαφορές μεταξύ των τιμών των χαρακτηριστικών. Αν ένα χαρακτηριστικό έχει πολύ μεγαλύτερες τιμές από ένα άλλο η σημασία του σε εκτιμητές όπως ο kNN, που μετρά τις αποστάσεις από τα χαρακτηριστικά, είναι μεγαλύτερη χωρίς αυτό να σημαίνει οτι παρέχει περισσότερη πληροφορία για την κατηγοριοποίηση. Χρησιμοποιούμε δύο μετασχηματιστές κανονικοποίησης, τον scaler και τον min_max_scaler. \n",
        "\n",
        "Η σειρά που ακολουθείται είναι η εξής:\n",
        "0. minmax αν VarianceThreshold για να μην επηρεαστεί η επιλογή από τις τιμές των χαρακτηριστικών\n",
        "1. Κανονικοποίηση (minmax ή z-score)\n",
        "2. PCA\n",
        "3. Εκτιμητής\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkD2OagKoBRj",
        "colab_type": "text"
      },
      "source": [
        "Χρήση grid search για την βελτιστοποίηση των υπερπαραμέτρων. Φτιάχνουμε σύνολο πιθανών συνδυασμών τιμών των παραμέτρων για να βρόυμε τον βέλτιστο. Υπολογίζεται ο μέσος όρος σε όλα τα folds (5 εδώ) του cross-validation με βάση της f1 μετρικές. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sI7f6mNqLbz",
        "colab_type": "code",
        "outputId": "40a7fb64-a76f-4be5-ca2f-64000fdd1799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"train frequencies:\", np.bincount(train_labels)[1:])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train frequencies: [1602 1606 1613 1602 1627]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edhYR-AZqf5x",
        "colab_type": "text"
      },
      "source": [
        "Εκτυπώνουμε την διακύμανση αφού έχουμε εφαρμόσει minmax για να υπολογίσουμε σωστά τα thresholds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptC32mF7pdBB",
        "colab_type": "code",
        "outputId": "dfd15180-cf41-45b3-a107-1ee95afa029b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler \n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_train_minmax = min_max_scaler.fit_transform(train)\n",
        "train_variance = X_train_minmax.var(axis=0)\n",
        "print(np.max(train_variance))\n",
        "print(np.min(train_variance))\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.003699443925720919\n",
            "0.0016128598715795769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH8IBIt_6iFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.decomposition import PCA\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqsotbyW6vHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Prepares and applies GridSearchcv. Each processing step if None is not applied, else it is applied.\n",
        "\"\"\"\n",
        "def GridSearch(data, preprocessing_steps, parameters, classifier, Scoring):\n",
        "  (train, train_labels, test, test_labels) = data\n",
        "  dictionary = {} #dictionary for Gridsearch grid\n",
        "\n",
        "  #checking for sampling condition\n",
        "  if parameters[\"sampling_strategy\"] < 0 or parameters[\"sampling_strategy\"] > 1:\n",
        "    parameters[\"sampling_strategy\"] = 0\n",
        "  if preprocessing_steps[\"sampling\"] == \"Over\":\n",
        "    ros = RandomOverSampler(parameters[\"sampling_strategy\"])\n",
        "  elif preprocessing_steps[\"sampling\"] == \"Under\":\n",
        "    ros = RandomUnderSampler(parameters[\"sampling_strategy\"])\n",
        "  else:\n",
        "    ros = None\n",
        "\n",
        "  #checking for Variance Threshold selector\n",
        "  if preprocessing_steps[\"selector\"] == \"VT\":\n",
        "    preprocessing_steps[\"scaler\"] == None   #no need for a scaler since we will use minmax in the beginning\n",
        "    scaler_minmax = MinMaxScaler()   #minmax is applied before VT\n",
        "    selector = VarianceThreshold()\n",
        "    dictionary[\"selector__threshold\"] = parameters[\"vthreshold\"]\n",
        "  else:\n",
        "    scaler_minmax = None\n",
        "    selector = None\n",
        "\n",
        "  #checking for the use of a scaler\n",
        "  if preprocessing_steps[\"scaler\"] == \"minmax\":\n",
        "    scaler = MinMaxScaler()\n",
        "  elif preprocessing_steps[\"scaler\"] == \"zscore\":\n",
        "    scaler = StandardScaler()\n",
        "  else:\n",
        "    scaler = None\n",
        "\n",
        "  #checking for the use of PCA\n",
        "  if preprocessing_steps[\"extractor\"] == \"PCA\":\n",
        "    pca = PCA()\n",
        "    dictionary[\"pca__n_components\"] = parameters[\"n_components\"]\n",
        "  else:\n",
        "    pca = None\n",
        "  \n",
        "  #creating estimator\n",
        "  if classifier == \"GNB\":\n",
        "    clf = GaussianNB()\n",
        "  elif classifier == \"kNN\":\n",
        "    clf = KNeighborsClassifier()\n",
        "    dictionary[\"kNN__n_neighbors\"] = parameters[\"k\"]\n",
        "    dictionary[\"kNN__weights\"] = parameters[\"weights\"]\n",
        "    dictionary[\"kNN__metric\"] = parameters[\"metrics\"]\n",
        "  elif classifier == \"MLP\":\n",
        "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,), random_state=1)\n",
        "    dictionary[\"MLP__solver\"] = parameters[\"solver\"]\n",
        "    dictionary[\"MLP__max_iter\"] = parameters[\"max_iter\"]\n",
        "    dictionary[\"MLP__alpha\"] = parameters[\"alpha\"]\n",
        "    dictionary[\"MLP__hidden_layer_sizes\"] = parameters[\"hidden_layer_sizes\"]\n",
        "    dictionary[\"MLP__activation\"] = parameters[\"activation\"]\n",
        "    dictionary[\"MLP__learning_rate\"] = parameters[\"learning_rate\"]\n",
        "\n",
        "\n",
        "  #create pipeline, using memory so that transformed data is saved and not recomputed with each fold change\n",
        "  pipe = Pipeline(steps=[('sampler', ros), ('minmax_scaler', scaler_minmax), ('selector', selector), ('scaler', scaler), ('pca', pca), (classifier, clf)], memory = 'tmp')  \n",
        "\n",
        "  #create estimator\n",
        "  estimator = GridSearchCV(pipe, dictionary, cv=5, scoring=Scoring, n_jobs=-1) #number of folds is 5\n",
        "\n",
        "  #fit and predict\n",
        "  start_time = time.time()\n",
        "  estimator.fit(train, train_labels)\n",
        "  preds = estimator.predict(test)\n",
        "  t = time.time() - start_time\n",
        "  print(\"Συνολικός χρόνος fit και predict: %s seconds\" % t)\n",
        "  accuracy = accuracy_score(test_labels, preds)\n",
        "  print(\"Accuracy: \", accuracy)\n",
        "  print(\"Precision_Recall_fscore: \", precision_recall_fscore_support(test_labels, preds, average='micro'))\n",
        "  print(\"Precision_Recall_fscore: \", precision_recall_fscore_support(test_labels, preds, average='macro'))\n",
        "\n",
        "  #print(estimator.best_estimator_)\n",
        "  print(estimator.best_params_, \"\\n\")\n",
        "\n",
        "  return preds, t, precision_recall_fscore_support(test_labels, preds, average='micro')[2], precision_recall_fscore_support(test_labels, preds, average='macro')[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OWvQV2vr1Sl",
        "colab_type": "text"
      },
      "source": [
        "##### Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbDPNvE6iWzP",
        "colab_type": "code",
        "outputId": "7f3c8118-026e-451e-ceb5-4e5945eceb8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "classifier = \"GNB\"\n",
        "\n",
        "#setting up parameters\n",
        "data = (train, train_labels, test, test_labels)\n",
        "vthreshold = [0, 0.0017, 0.002, 0.0023] \n",
        "n_components = [10, 20, 30, 40, 50, 60, 70]\n",
        "\n",
        "preprocessing_steps = {\"sampling\" : None, \"selector\" : None, \"scaler\" : None, \"extractor\" : None}\n",
        "parameters = {\"sampling_strategy\" : 0, \"vthreshold\" : vthreshold, \"n_components\" : n_components}\n",
        "\n",
        "#f1-micro\n",
        "best_GNB_micro = 0\n",
        "for selector in (None, \"VT\"):\n",
        "  for scaler in (None, \"minmax\", \"zscore\"):\n",
        "    for extractor in (None, \"PCA\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-micro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_micro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_micro > best_GNB_micro:\n",
        "        print(\"Best so far:\", f1_micro, \"\\n\")\n",
        "        best_GNB_micro_time = t\n",
        "        best_GNB_micro_preds = preds\n",
        "        best_GNB_micro = f1_micro\n",
        "\n",
        "\n",
        "#f1-macro\n",
        "best_GNB_macro = 0\n",
        "for selector in (None, \"VT\"):\n",
        "  for scaler in (None, \"minmax\", \"zscore\"):\n",
        "    for extractor in (None, \"PCA\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-macro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_macro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_macro > best_GNB_macro:\n",
        "        print(\"Best so far:\", f1_macro, \"\\n\")\n",
        "        best_GNB_macro_time = t\n",
        "        best_GNB_macro_preds = preds\n",
        "        best_GNB_macro = f1_macro\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.2828199863433838 seconds\n",
            "Accuracy:  0.443768115942029\n",
            "Precision_Recall_fscore:  (0.443768115942029, 0.443768115942029, 0.443768115942029, None)\n",
            "Precision_Recall_fscore:  (0.4472117216530095, 0.44488271791220485, 0.4239196274192298, None)\n",
            "{} \n",
            "\n",
            "Best so far: 0.443768115942029 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 7.979326009750366 seconds\n",
            "Accuracy:  0.6533333333333333\n",
            "Precision_Recall_fscore:  (0.6533333333333333, 0.6533333333333333, 0.6533333333333333, None)\n",
            "Precision_Recall_fscore:  (0.660099572694001, 0.6533748623673283, 0.6420097081522884, None)\n",
            "{'pca__n_components': 50} \n",
            "\n",
            "Best so far: 0.6533333333333333 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.219547986984253 seconds\n",
            "Accuracy:  0.443768115942029\n",
            "Precision_Recall_fscore:  (0.443768115942029, 0.443768115942029, 0.443768115942029, None)\n",
            "Precision_Recall_fscore:  (0.4472117216530095, 0.44488271791220485, 0.4239196274192298, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 5.620418071746826 seconds\n",
            "Accuracy:  0.6333333333333333\n",
            "Precision_Recall_fscore:  (0.6333333333333333, 0.6333333333333333, 0.6333333333333333, None)\n",
            "Precision_Recall_fscore:  (0.6385718762718763, 0.6333299195781182, 0.6223316140829181, None)\n",
            "{'pca__n_components': 50} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.2011430263519287 seconds\n",
            "Accuracy:  0.443768115942029\n",
            "Precision_Recall_fscore:  (0.443768115942029, 0.443768115942029, 0.443768115942029, None)\n",
            "Precision_Recall_fscore:  (0.4472117216530095, 0.44488271791220485, 0.4239196274192298, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 5.500432968139648 seconds\n",
            "Accuracy:  0.6571014492753623\n",
            "Precision_Recall_fscore:  (0.6571014492753623, 0.6571014492753623, 0.6571014492753623, None)\n",
            "Precision_Recall_fscore:  (0.6632347781547668, 0.657169893298202, 0.6459477762537957, None)\n",
            "{'pca__n_components': 50} \n",
            "\n",
            "Best so far: 0.6571014492753623 \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 2.1315488815307617 seconds\n",
            "Accuracy:  0.44521739130434784\n",
            "Precision_Recall_fscore:  (0.44521739130434784, 0.44521739130434784, 0.44521739130434784, None)\n",
            "Precision_Recall_fscore:  (0.45020466003798176, 0.44629115864837293, 0.4261096794153483, None)\n",
            "{'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 17.241461753845215 seconds\n",
            "Accuracy:  0.6333333333333333\n",
            "Precision_Recall_fscore:  (0.6333333333333333, 0.6333333333333333, 0.6333333333333333, None)\n",
            "Precision_Recall_fscore:  (0.6385718762718763, 0.6333299195781182, 0.6223316140829181, None)\n",
            "{'pca__n_components': 50, 'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 2.308988332748413 seconds\n",
            "Accuracy:  0.44521739130434784\n",
            "Precision_Recall_fscore:  (0.44521739130434784, 0.44521739130434784, 0.44521739130434784, None)\n",
            "Precision_Recall_fscore:  (0.45020466003798176, 0.44629115864837293, 0.4261096794153483, None)\n",
            "{'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 23.0169038772583 seconds\n",
            "Accuracy:  0.6336231884057971\n",
            "Precision_Recall_fscore:  (0.6336231884057971, 0.6336231884057971, 0.6336231884057971, None)\n",
            "Precision_Recall_fscore:  (0.6388595393707236, 0.6336210403932566, 0.6225853411959824, None)\n",
            "{'pca__n_components': 50, 'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 2.4637973308563232 seconds\n",
            "Accuracy:  0.44521739130434784\n",
            "Precision_Recall_fscore:  (0.44521739130434784, 0.44521739130434784, 0.44521739130434784, None)\n",
            "Precision_Recall_fscore:  (0.45020466003798176, 0.44629115864837293, 0.4261096794153483, None)\n",
            "{'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 23.246352195739746 seconds\n",
            "Accuracy:  0.6431884057971015\n",
            "Precision_Recall_fscore:  (0.6431884057971015, 0.6431884057971015, 0.6431884057971015, None)\n",
            "Precision_Recall_fscore:  (0.6515462382198716, 0.6431226879195644, 0.6326445919750716, None)\n",
            "{'pca__n_components': 50, 'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 0.2597229480743408 seconds\n",
            "Accuracy:  0.443768115942029\n",
            "Precision_Recall_fscore:  (0.443768115942029, 0.443768115942029, 0.443768115942029, None)\n",
            "Precision_Recall_fscore:  (0.4472117216530095, 0.44488271791220485, 0.4239196274192298, None)\n",
            "{} \n",
            "\n",
            "Best so far: 0.4239196274192298 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.306016206741333 seconds\n",
            "Accuracy:  0.6533333333333333\n",
            "Precision_Recall_fscore:  (0.6533333333333333, 0.6533333333333333, 0.6533333333333333, None)\n",
            "Precision_Recall_fscore:  (0.660099572694001, 0.6533748623673283, 0.6420097081522884, None)\n",
            "{'pca__n_components': 50} \n",
            "\n",
            "Best so far: 0.6420097081522884 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 0.38359570503234863 seconds\n",
            "Accuracy:  0.443768115942029\n",
            "Precision_Recall_fscore:  (0.443768115942029, 0.443768115942029, 0.443768115942029, None)\n",
            "Precision_Recall_fscore:  (0.4472117216530095, 0.44488271791220485, 0.4239196274192298, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.9023818969726562 seconds\n",
            "Accuracy:  0.6333333333333333\n",
            "Precision_Recall_fscore:  (0.6333333333333333, 0.6333333333333333, 0.6333333333333333, None)\n",
            "Precision_Recall_fscore:  (0.6385718762718763, 0.6333299195781182, 0.6223316140829181, None)\n",
            "{'pca__n_components': 50} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 0.40443849563598633 seconds\n",
            "Accuracy:  0.443768115942029\n",
            "Precision_Recall_fscore:  (0.443768115942029, 0.443768115942029, 0.443768115942029, None)\n",
            "Precision_Recall_fscore:  (0.4472117216530095, 0.44488271791220485, 0.4239196274192298, None)\n",
            "{} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.843648910522461 seconds\n",
            "Accuracy:  0.6571014492753623\n",
            "Precision_Recall_fscore:  (0.6571014492753623, 0.6571014492753623, 0.6571014492753623, None)\n",
            "Precision_Recall_fscore:  (0.6632347781547668, 0.657169893298202, 0.6459477762537957, None)\n",
            "{'pca__n_components': 50} \n",
            "\n",
            "Best so far: 0.6459477762537957 \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.3799583911895752 seconds\n",
            "Accuracy:  0.44521739130434784\n",
            "Precision_Recall_fscore:  (0.44521739130434784, 0.44521739130434784, 0.44521739130434784, None)\n",
            "Precision_Recall_fscore:  (0.45020466003798176, 0.44629115864837293, 0.4261096794153483, None)\n",
            "{'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 8.649694442749023 seconds\n",
            "Accuracy:  0.6333333333333333\n",
            "Precision_Recall_fscore:  (0.6333333333333333, 0.6333333333333333, 0.6333333333333333, None)\n",
            "Precision_Recall_fscore:  (0.6385718762718763, 0.6333299195781182, 0.6223316140829181, None)\n",
            "{'pca__n_components': 50, 'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.562598705291748 seconds\n",
            "Accuracy:  0.44521739130434784\n",
            "Precision_Recall_fscore:  (0.44521739130434784, 0.44521739130434784, 0.44521739130434784, None)\n",
            "Precision_Recall_fscore:  (0.45020466003798176, 0.44629115864837293, 0.4261096794153483, None)\n",
            "{'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 10.53570008277893 seconds\n",
            "Accuracy:  0.6336231884057971\n",
            "Precision_Recall_fscore:  (0.6336231884057971, 0.6336231884057971, 0.6336231884057971, None)\n",
            "Precision_Recall_fscore:  (0.6388595393707236, 0.6336210403932566, 0.6225853411959824, None)\n",
            "{'pca__n_components': 50, 'selector__threshold': 0} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 1.5914654731750488 seconds\n",
            "Accuracy:  0.44521739130434784\n",
            "Precision_Recall_fscore:  (0.44521739130434784, 0.44521739130434784, 0.44521739130434784, None)\n",
            "Precision_Recall_fscore:  (0.45020466003798176, 0.44629115864837293, 0.4261096794153483, None)\n",
            "{'selector__threshold': 0.0017} \n",
            "\n",
            "\u001b[1m f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} \u001b[0m\n",
            "Συνολικός χρόνος fit και predict: 10.217759132385254 seconds\n",
            "Accuracy:  0.6431884057971015\n",
            "Precision_Recall_fscore:  (0.6431884057971015, 0.6431884057971015, 0.6431884057971015, None)\n",
            "Precision_Recall_fscore:  (0.6515462382198716, 0.6431226879195644, 0.6326445919750716, None)\n",
            "{'pca__n_components': 50, 'selector__threshold': 0.0017} \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDTTV3ZthFz3",
        "colab_type": "text"
      },
      "source": [
        "##### kNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6yOtJGLfXwm",
        "colab_type": "text"
      },
      "source": [
        "Η αποτελεσματικότητα του kNN, εκτός από το k, εξαρτάται και από την ύπαρξη βαρών στον υπολογισμό των γειτόνων, δηλαδή από το αν οι κοντινοί γείτονες αποκτούν μεγαλύτερη σημασία από τους μακρινότερους. Εφαρμόζουμε 2 περιπτώσεις:\n",
        "* uniform: όλοι οι γείτονες έχουν την ίδια σημασία\n",
        "* distance: η σημασία είναι αντιστρόφως ανάλογη της απόστασης\n",
        "\n",
        "Εκτός αυτού σημασία έχει και ο τρόπος υπολογισμού της απόστασης. Εφαρμόζουμε 2 τρόπους υπολογισμού:\n",
        "* manhattan\n",
        "* euclidean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ_nsn7bVpIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = \"kNN\"\n",
        "\n",
        "#setting up parameters\n",
        "data = (train, train_labels, test, test_labels)\n",
        "vthreshold = [0, 0.0017, 0.002, 0.0023] \n",
        "n_components = [10, 15, 20, 25, 30, 35]\n",
        "k = [1, 3, 5]\n",
        "weights = [\"uniform\", \"distance\"]\n",
        "metrics = [\"euclidean\", \"manhattan\"]\n",
        "\n",
        "preprocessing_steps = {\"sampling\" : None, \"selector\" : None, \"scaler\" : None, \"extractor\" : None}\n",
        "parameters = {\"sampling_strategy\" : 0, \"vthreshold\" : vthreshold, \"n_components\" : n_components, \"k\" : k, \"weights\" : weights, \"metrics\" : metrics}\n",
        "\n",
        "#f1-micro\n",
        "best_kNN_micro = 0\n",
        "for selector in (None, \"VT\"):\n",
        "  for scaler in (None, \"minmax\", \"zscore\"):\n",
        "    for extractor in (None, \"PCA\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-micro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_micro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_micro > best_kNN_micro:\n",
        "        print(\"Best so far:\", f1_micro, \"\\n\")\n",
        "        best_kNN_micro_time = t\n",
        "        best_kNN_micro_preds = preds\n",
        "        best_kNN_micro = f1_micro\n",
        "\n",
        "#f1-macro\n",
        "best_kNN_macro = 0\n",
        "for selector in (None, \"VT\"):\n",
        "  for scaler in (None, \"minmax\", \"zscore\"):\n",
        "    for extractor in (None, \"PCA\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-macro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_macro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_macro > best_kNN_macro:\n",
        "        print(\"Best so far:\", f1_micro, \"\\n\")\n",
        "        best_kNN_macro_time = t\n",
        "        best_kNN_macro_preds = preds\n",
        "        best_kNN_macro = f1_macro"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms4aW8wsBTY1",
        "colab_type": "text"
      },
      "source": [
        "f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 155.94002842903137 seconds\n",
        "Accuracy:  0.5382608695652173<br>\n",
        "Precision_Recall_fscore:  (0.5382608695652173, 0.5382608695652173, 0.5382608695652173, None)<br>\n",
        "Precision_Recall_fscore:  (0.6116939651203526, 0.5362970303969432, 0.5345488609961603, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform'} \n",
        "\n",
        "Best so far: 0.5382608695652173 \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 177.15761733055115 seconds\n",
        "Accuracy:  0.5704347826086956<br>\n",
        "Precision_Recall_fscore:  (0.5704347826086956, 0.5704347826086956, 0.5704347826086956, None)<br>\n",
        "Precision_Recall_fscore:  (0.6205889157153534, 0.5691597423177073, 0.5728985444648659, None)<br>\n",
        "{'kNN__metric': 'manhattan', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 30} \n",
        "\n",
        "Best so far: 0.5704347826086956 \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 160.4299430847168 seconds\n",
        "Accuracy:  0.5368115942028986<br>\n",
        "Precision_Recall_fscore:  (0.5368115942028986, 0.5368115942028986, 0.5368115942028986, None)<br>\n",
        "Precision_Recall_fscore:  (0.6076885944706372, 0.5347848677885435, 0.5315050475325286, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform'} \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 175.8805661201477 seconds\n",
        "Accuracy:  0.567536231884058<br>\n",
        "Precision_Recall_fscore:  (0.567536231884058, 0.567536231884058, 0.567536231884058, None)<br>\n",
        "Precision_Recall_fscore:  (0.619623800305156, 0.5658816667447705, 0.5725327699900926, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 30} \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 151.6079216003418 seconds\n",
        "Accuracy:  0.5388405797101449<br>\n",
        "Precision_Recall_fscore:  (0.5388405797101449, 0.5388405797101449, 0.5388405797101449, None)<br>\n",
        "Precision_Recall_fscore:  (0.6145741881150677, 0.5369045265105867, 0.5355752757772972, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform'} \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 179.2935791015625 seconds\n",
        "Accuracy:  0.571304347826087<br>\n",
        "Precision_Recall_fscore:  (0.571304347826087, 0.571304347826087, 0.571304347826087, None)<br>\n",
        "Precision_Recall_fscore:  (0.625739943658974, 0.569659970930135, 0.5761206545738996, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 30} \n",
        "\n",
        "Best so far: 0.571304347826087 \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 531.2911882400513 seconds\n",
        "Accuracy:  0.5368115942028986<br>\n",
        "Precision_Recall_fscore:  (0.5368115942028986, 0.5368115942028986, 0.5368115942028986, None)<br>\n",
        "Precision_Recall_fscore:  (0.6076885944706372, 0.5347848677885435, 0.5315050475325286, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'selector__threshold': 0} \n",
        "\n",
        "f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 496.1291735172272 seconds\n",
        "Accuracy:  0.524927536231884<br>\n",
        "Precision_Recall_fscore:  (0.524927536231884, 0.524927536231884, 0.524927536231884, None)<br>\n",
        "Precision_Recall_fscore:  (0.6018532717154714, 0.5275128810454286, 0.5198811975697916, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'selector__threshold': 0} \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 617.9515242576599 seconds\n",
        "Accuracy:  0.547536231884058<br>\n",
        "Precision_Recall_fscore:  (0.547536231884058, 0.547536231884058, 0.547536231884058, None)<br>\n",
        "Precision_Recall_fscore:  (0.6107291942171147, 0.5495094296596342, 0.5507985248694627, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 35, 'selector__threshold': 0} \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 500.93980598449707 seconds\n",
        "Accuracy:  0.524927536231884<br>\n",
        "Precision_Recall_fscore:  (0.524927536231884, 0.524927536231884, 0.524927536231884, None)<br>\n",
        "Precision_Recall_fscore:  (0.6018532717154714, 0.5275128810454286, 0.5198811975697916, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'selector__threshold': 0} \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 629.9736206531525 seconds\n",
        "Accuracy:  0.547536231884058<br>\n",
        "Precision_Recall_fscore:  (0.547536231884058, 0.547536231884058, 0.547536231884058, None)<br>\n",
        "Precision_Recall_fscore:  (0.6107291942171147, 0.5495094296596342, 0.5507985248694627, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 35, 'selector__threshold': 0} \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 501.1655333042145 seconds\n",
        "Accuracy:  0.5231884057971015<br>\n",
        "Precision_Recall_fscore:  (0.5231884057971015, 0.5231884057971015, 0.5231884057971015, None)<br>\n",
        "Precision_Recall_fscore:  (0.6000927571539625, 0.525751267524505, 0.5184719443303563, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'selector__threshold': 0} \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 640.167172908783 seconds\n",
        "Accuracy:  0.556231884057971<br>\n",
        "Precision_Recall_fscore:  (0.556231884057971, 0.556231884057971, 0.556231884057971, None)<br>\n",
        "Precision_Recall_fscore:  (0.6006751214045278, 0.5577667335009407, 0.5620974542733507, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 25, 'selector__threshold': 0} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 184.88850140571594 seconds\n",
        "Accuracy:  0.5336231884057971<br>\n",
        "Precision_Recall_fscore:  (0.5336231884057971, 0.5336231884057971, 0.5336231884057971, None)<br>\n",
        "Precision_Recall_fscore:  (0.6131360900113694, 0.5329733267783303, 0.5306372847953326, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform'} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 171.44153213500977 seconds\n",
        "Accuracy:  0.5626086956521739<br>\n",
        "Precision_Recall_fscore:  (0.5626086956521739, 0.5626086956521739, 0.5626086956521739, None)<br>\n",
        "Precision_Recall_fscore:  (0.5992006103045691, 0.5647486759490894, 0.5727681823114018, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 20} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 186.49681520462036 seconds\n",
        "Accuracy:  0.5313043478260869<br>\n",
        "Precision_Recall_fscore:  (0.5313043478260869, 0.5313043478260869, 0.5313043478260869, None)<br>\n",
        "Precision_Recall_fscore:  (0.6103363608721251, 0.5305514318112949, 0.5285987558247256, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform'} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'}<br> \n",
        "Συνολικός χρόνος fit και predict: 177.48603010177612 seconds\n",
        "Accuracy:  0.563768115942029<br>\n",
        "Precision_Recall_fscore:  (0.563768115942029, 0.563768115942029, 0.563768115942029, None)<br>\n",
        "Precision_Recall_fscore:  (0.6206978513352238, 0.5646466936923876, 0.5701676369000378, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 30} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 187.0180253982544 seconds\n",
        "Accuracy:  0.5356521739130434<br>\n",
        "Precision_Recall_fscore:  (0.5356521739130434, 0.5356521739130434, 0.5356521739130434, None)<br>\n",
        "Precision_Recall_fscore:  (0.6140211191681275, 0.5349254670259016, 0.5319080253660903, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform'} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'}<br> \n",
        "Συνολικός χρόνος fit και predict: 179.02517986297607 seconds\n",
        "Accuracy:  0.5626086956521739<br>\n",
        "Precision_Recall_fscore:  (0.5626086956521739, 0.5626086956521739, 0.5626086956521739, None)<br>\n",
        "Precision_Recall_fscore:  (0.6007418358630561, 0.5647921509814828, 0.573050155694501, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 20} \n",
        "\n",
        "Best so far: 0.5626086956521739 \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 633.8428337574005 seconds\n",
        "Accuracy:  0.5321739130434783<br>\n",
        "Precision_Recall_fscore:  (0.5321739130434783, 0.5321739130434783, 0.5321739130434783, None)<br>\n",
        "Precision_Recall_fscore:  (0.6036176178663751, 0.532277743149647, 0.5330280242258331, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'selector__threshold': 0.0023}<br> \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 708.5733802318573 seconds\n",
        "Accuracy:  0.5655072463768116<br>\n",
        "Precision_Recall_fscore:  (0.5655072463768116, 0.5655072463768116, 0.5655072463768116, None)<br>\n",
        "Precision_Recall_fscore:  (0.621474683435526, 0.5663244726241995, 0.5716901890058848, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 30, 'selector__threshold': 0.0017} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 639.6631438732147 seconds\n",
        "Accuracy:  0.5321739130434783<br>\n",
        "Precision_Recall_fscore:  (0.5321739130434783, 0.5321739130434783, 0.5321739130434783, None)<br>\n",
        "Precision_Recall_fscore:  (0.6036176178663751, 0.532277743149647, 0.5330280242258331, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'selector__threshold': 0.0023} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'}<br> \n",
        "Συνολικός χρόνος fit και predict: 731.5496926307678 seconds\n",
        "Accuracy:  0.5646376811594203<br>\n",
        "Precision_Recall_fscore:  (0.5646376811594203, 0.5646376811594203, 0.5646376811594203, None)<br>\n",
        "Precision_Recall_fscore:  (0.6198413966829107, 0.5654289502361398, 0.5706875613521175, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 30, 'selector__threshold': 0.0017} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 637.1497604846954 seconds\n",
        "Accuracy:  0.5318840579710145<br>\n",
        "Precision_Recall_fscore:  (0.5318840579710145, 0.5318840579710145, 0.5318840579710145, None)<br>\n",
        "Precision_Recall_fscore:  (0.6038400285429424, 0.5318555405730838, 0.5318979781630594, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'selector__threshold': 0.0023} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 738.8507409095764 seconds\n",
        "Accuracy:  0.5657971014492753<br>\n",
        "Precision_Recall_fscore:  (0.5657971014492753, 0.5657971014492753, 0.5657971014492753, None)<br>\n",
        "Precision_Recall_fscore:  (0.6032459350788891, 0.5680004655808871, 0.5763006670077019, None)<br>\n",
        "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 1, 'kNN__weights': 'uniform', 'pca__n_components': 20, 'selector__threshold': 0.0017} \n",
        "\n",
        "Best so far: 0.5657971014492753 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkBFYLyIhOs_",
        "colab_type": "text"
      },
      "source": [
        "##### Multi Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VarcbdPXvDT7",
        "colab_type": "text"
      },
      "source": [
        "Οι παράμετροι που εξετάζουμε είναι οι παρακάτω:\n",
        "* Ο αριθμός των νευρώνων στον κρυμμένο επίπεδο.\n",
        "* Η μη γραμμική συνάρτηση που εφαρμόζεται. Μπορεί να εφαρμοστεί η σιγμοειδής, η υπερβολική εφαπτομένη ή η relu. Παρατηρήσαμε οτι η πρώτη δεν εφαρμοζόταν και επιλέξαμε να συνεχίσουμε με τις άλλες δύο.\n",
        "* Ο τρόπος ενημέρωσης των βαρών. Εφαρμόσαμε μία quasi-Newton method και την stochastic gradient descent.\n",
        "* alpha: Η παράμετρος για την F2 κανονικοποίηση, η οποία βοηθά στην αποφυγή του overfitting, φροντίζοντας τα βάρη να μη μαθαίνουν τις ιδιομορφίες του dataset.\n",
        "* Μέγιστος αριθμός επαναλήψεων που επιτρέπουμε στον αλγόρθμο.\n",
        "* Το learing rate, το οποίο αφορά την \"ώθηση\" που δίνουμε σε κάθε ενημέρωση των παραμέτρων."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI9d2ybbhQcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = \"MLP\"\n",
        "\n",
        "#setting up parameters\n",
        "data = (train.iloc[1:1000, :], train_labels.iloc[1:1000], test, test_labels)\n",
        "vthreshold = [0.0017, 0.002, 0.0023] \n",
        "n_components = [30, 35, 40]\n",
        "\n",
        "hidden_layer_sizes = [(5, ), (10, ), (15, )]\n",
        "activation = [\"tanh\", \"relu\"]\n",
        "solver = [\"lbfgs\", \"sgd\"]\n",
        "max_iter = [40, 80, 120]\n",
        "alpha = [0.00001, 0.0001, 0.001]\n",
        "learning_rate = [\"constant\", \"invscaling\"]\n",
        "\n",
        "preprocessing_steps = {\"sampling\" : None, \"selector\" : None, \"scaler\" : None, \"extractor\" : None}\n",
        "parameters = {\"sampling_strategy\" : 0, \"vthreshold\" : vthreshold, \"n_components\" : n_components, \"solver\": solver, \"max_iter\": max_iter, \"alpha\": alpha, \"hidden_layer_sizes\": hidden_layer_sizes, \"activation\": activation, \"learning_rate\" : learning_rate}\n",
        "\n",
        "#f1-micro\n",
        "best_MLP_micro = 0\n",
        "for scaler in (None, \"minmax\", \"zscore\"):\n",
        "  for extractor in (None, \"PCA\"):\n",
        "    for selector in (None, \"VT\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-micro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_micro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_micro > best_MLP_micro:\n",
        "        print(\"Best so far:\", f1_micro, \"\\n\")\n",
        "        best_MLP_micro_time = t\n",
        "        best_MLP_micro_preds = preds\n",
        "        best_MLP_micro = f1_micro\n",
        "\n",
        "#f1-macro\n",
        "best_MLP_macro = 0\n",
        "for scaler in (None, \"minmax\", \"zscore\"):\n",
        "  for extractor in (None, \"PCA\"):\n",
        "    for selector in (None, \"VT\"):\n",
        "      preprocessing_steps[\"selector\"] = selector\n",
        "      preprocessing_steps[\"scaler\"] = scaler\n",
        "      preprocessing_steps[\"extractor\"] = extractor\n",
        "      print('\\033[1m', \"f1-macro\", \"Preprocessing steps: \", preprocessing_steps, '\\033[0m')\n",
        "      results = GridSearch(data, preprocessing_steps, parameters, classifier, Scoring = 'f1_macro')\n",
        "      preds, t, f1_micro, f1_macro = results\n",
        "      if f1_macro > best_MLP_macro:\n",
        "        print(\"Best so far:\", f1_macro, \"\\n\")\n",
        "        best_MLP_macro_time = t\n",
        "        best_MLP_macro_preds = preds\n",
        "        best_MLP_macro = f1_macro"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ7QZOiN40MQ",
        "colab_type": "text"
      },
      "source": [
        "f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 158.21877598762512 seconds <br>\n",
        "Accuracy:  0.3310144927536232<br>\n",
        "Precision_Recall_fscore:  (0.3310144927536232, 0.3310144927536232, 0.3310144927536232, None)<br>\n",
        "Precision_Recall_fscore:  (0.3276732863394307, 0.33167211437304855, 0.31636655037476535, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 0.0001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'invscaling', 'MLP__max_iter': 80, 'MLP__solver': 'sgd'} \n",
        "\n",
        "Best so far: 0.3310144927536232 \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 433.99163484573364 seconds\n",
        "Accuracy:  0.38666666666666666<br>\n",
        "Precision_Recall_fscore:  (0.38666666666666666, 0.38666666666666666, 0.38666666666666666, None)<br>\n",
        "Precision_Recall_fscore:  (0.4006256716191846, 0.39398396696614435, 0.36029309376794955, None)<br>\n",
        "{'MLP__activation': 'tanh', 'MLP__alpha': 0.001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'lbfgs', 'selector__threshold': 0.0017} \n",
        "\n",
        "Best so far: 0.38666666666666666 \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 283.1568763256073 seconds\n",
        "Accuracy:  0.28782608695652173<br>\n",
        "Precision_Recall_fscore:  (0.28782608695652173, 0.28782608695652173, 0.28782608695652173, None)<br>\n",
        "Precision_Recall_fscore:  (0.28577185051959136, 0.2883354851888736, 0.25569296097281646, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 1e-05, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'invscaling', 'MLP__max_iter': 80, 'MLP__solver': 'sgd', 'pca__n_components': 40} \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 978.6760702133179 seconds\n",
        "Accuracy:  0.4281159420289855<br>\n",
        "Precision_Recall_fscore:  (0.4281159420289855, 0.4281159420289855, 0.4281159420289855, None)<br>\n",
        "Precision_Recall_fscore:  (0.44074005229765084, 0.4338093678379888, 0.4314515900401468, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 1e-05, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'lbfgs', 'pca__n_components': 40, 'selector__threshold': 0.0023} \n",
        "\n",
        "Best so far: 0.4281159420289855 \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 140.3534996509552 seconds\n",
        "Accuracy:  0.38666666666666666<br>\n",
        "Precision_Recall_fscore:  (0.38666666666666666, 0.38666666666666666, 0.38666666666666666, None)<br>\n",
        "Precision_Recall_fscore:  (0.4006256716191846, 0.39398396696614435, 0.36029309376794955, None)<br>\n",
        "{'MLP__activation': 'tanh', 'MLP__alpha': 0.001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'lbfgs'} \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 448.2339680194855 seconds\n",
        "Accuracy:  0.3373913043478261<br>\n",
        "Precision_Recall_fscore:  (0.3373913043478261, 0.3373913043478261, 0.3373913043478261, None)<br>\n",
        "Precision_Recall_fscore:  (0.3462694725456258, 0.3469727248794432, 0.28617406263537976, None)<br>\n",
        "{'MLP__activation': 'tanh', 'MLP__alpha': 0.001, 'MLP__hidden_layer_sizes': (10,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'lbfgs', 'selector__threshold': 0.0023} \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 313.1024115085602 seconds\n",
        "Accuracy:  0.4504347826086956<br>\n",
        "Precision_Recall_fscore:  (0.4504347826086956, 0.4504347826086956, 0.4504347826086956, None)<br>\n",
        "Precision_Recall_fscore:  (0.4657608913799328, 0.45612698030369836, 0.45278188771680705, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 0.0001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'lbfgs', 'pca__n_components': 35} \n",
        "\n",
        "Best so far: 0.4504347826086956 \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 1020.8281011581421 seconds\n",
        "Accuracy:  0.4156521739130435<br>\n",
        "Precision_Recall_fscore:  (0.4156521739130435, 0.4156521739130435, 0.4156521739130435, None)<br>\n",
        "Precision_Recall_fscore:  (0.42890467585445835, 0.42212146746667367, 0.415279581973075, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 0.001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'lbfgs', 'pca__n_components': 35, 'selector__threshold': 0.0023} \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 172.6538348197937 seconds\n",
        "Accuracy:  0.4927536231884058<br>\n",
        "Precision_Recall_fscore:  (0.4927536231884058, 0.4927536231884058, 0.4927536231884058, None)<br>\n",
        "Precision_Recall_fscore:  (0.5179894754838774, 0.4949074848116342, 0.5039265908453473, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 0.0001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 40, 'MLP__solver': 'lbfgs'} \n",
        "\n",
        "Best so far: 0.4927536231884058 \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 543.4926447868347 seconds\n",
        "Accuracy:  0.4927536231884058<br>\n",
        "Precision_Recall_fscore:  (0.4927536231884058, 0.4927536231884058, 0.4927536231884058, None)<br>\n",
        "Precision_Recall_fscore:  (0.5179894754838774, 0.4949074848116342, 0.5039265908453473, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 0.0001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 40, 'MLP__solver': 'lbfgs', 'selector__threshold': 0.0017} \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 344.2996292114258 seconds\n",
        "Accuracy:  0.5023188405797101<br>\n",
        "Precision_Recall_fscore:  (0.5023188405797101, 0.5023188405797101, 0.5023188405797101, None)<br>\n",
        "Precision_Recall_fscore:  (0.5141244977062582, 0.5060607163624835, 0.5090797821886365, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 0.0001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 40, 'MLP__solver': 'lbfgs', 'pca__n_components': 40} \n",
        "\n",
        "Best so far: 0.5023188405797101 \n",
        "\n",
        " f1-micro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 1111.2693781852722 seconds\n",
        "Accuracy:  0.5028985507246376<br>\n",
        "Precision_Recall_fscore:  (0.5028985507246376, 0.5028985507246376, 0.5028985507246376, None)<br>\n",
        "Precision_Recall_fscore:  (0.5177762449080909, 0.5064809044747374, 0.5106715197625844, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 1e-05, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 80, 'MLP__solver': 'lbfgs', 'pca__n_components': 40, 'selector__threshold': 0.0023} \n",
        "\n",
        "Best so far: 0.5028985507246376 \n",
        "\n",
        "\n",
        "f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 124.02273631095886 seconds\n",
        "Accuracy:  0.2866666666666667<br>\n",
        "Precision_Recall_fscore:  (0.2866666666666667, 0.2866666666666667, 0.2866666666666667, None)<br>\n",
        "Precision_Recall_fscore:  (0.285221736129834, 0.2847552513203665, 0.2547745690196092, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 0.001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'invscaling', 'MLP__max_iter': 120, 'MLP__solver': 'sgd'} \n",
        "\n",
        "Best so far: 0.2547745690196092 \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 351.72380661964417 seconds\n",
        "Accuracy:  0.34608695652173915<br>\n",
        "Precision_Recall_fscore:  (0.34608695652173915, 0.34608695652173915, 0.34608695652173915, None)<br>\n",
        "Precision_Recall_fscore:  (0.35939938330036275, 0.3440203816471273, 0.33290430502636037, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 1e-05, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'lbfgs', 'selector__threshold': 0.0017} \n",
        "\n",
        "Best so far: 0.33290430502636037 \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': None, 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 222.92825317382812 seconds\n",
        "Accuracy:  0.2336231884057971<br>\n",
        "Precision_Recall_fscore:  (0.2336231884057971, 0.2336231884057971, 0.2336231884057971, None)<br>\n",
        "Precision_Recall_fscore:  (0.21794012920467482, 0.2352534382286513, 0.17830731823296958, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 0.0001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'invscaling', 'MLP__max_iter': 120, 'MLP__solver': 'sgd', 'pca__n_components': 30} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': None, 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 755.0554883480072 seconds\n",
        "Accuracy:  0.4855072463768116<br>\n",
        "Precision_Recall_fscore:  (0.4855072463768116, 0.4855072463768116, 0.4855072463768116, None)<br>\n",
        "Precision_Recall_fscore:  (0.5082237838226467, 0.48783407372464965, 0.4900961314548803, None)<br>\n",
        "{'MLP__activation': 'tanh', 'MLP__alpha': 0.0001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'lbfgs', 'pca__n_components': 35, 'selector__threshold': 0.0017} \n",
        "\n",
        "Best so far: 0.4900961314548803 \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 111.49629211425781 seconds\n",
        "Accuracy:  0.34608695652173915<br>\n",
        "Precision_Recall_fscore:  (0.34608695652173915, 0.34608695652173915, 0.34608695652173915, None)<br>\n",
        "Precision_Recall_fscore:  (0.35939938330036275, 0.3440203816471273, 0.33290430502636037, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 1e-05, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'lbfgs'} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 365.4844331741333 seconds\n",
        "Accuracy:  0.34202898550724636<br>\n",
        "Precision_Recall_fscore:  (0.34202898550724636, 0.34202898550724636, 0.34202898550724636, None)<br>\n",
        "Precision_Recall_fscore:  (0.29838756368762065, 0.3375805931913928, 0.2978301183007766, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 0.001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'lbfgs', 'selector__threshold': 0.0017} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'minmax', 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 247.06837105751038 seconds\n",
        "Accuracy:  0.4855072463768116<br>\n",
        "Precision_Recall_fscore:  (0.4855072463768116, 0.4855072463768116, 0.4855072463768116, None)<br>\n",
        "Precision_Recall_fscore:  (0.5082237838226467, 0.48783407372464965, 0.4900961314548803, None)<br>\n",
        "{'MLP__activation': 'tanh', 'MLP__alpha': 0.0001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'lbfgs', 'pca__n_components': 35} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'minmax', 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 793.3789689540863 seconds\n",
        "Accuracy:  0.48985507246376814<br>\n",
        "Precision_Recall_fscore:  (0.48985507246376814, 0.48985507246376814, 0.48985507246376814, None)<br>\n",
        "Precision_Recall_fscore:  (0.5104601646301817, 0.4916470705203725, 0.4926466412377364, None)<br>\n",
        "{'MLP__activation': 'tanh', 'MLP__alpha': 0.001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'lbfgs', 'pca__n_components': 35, 'selector__threshold': 0.0017} \n",
        "\n",
        "Best so far: 0.4926466412377364 \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 135.28493213653564 seconds\n",
        "Accuracy:  0.49333333333333335<br>\n",
        "Precision_Recall_fscore:  (0.49333333333333335, 0.49333333333333335, 0.4933333333333334, None)<br>\n",
        "Precision_Recall_fscore:  (0.5064258046007876, 0.4932723800700754, 0.49802517306166694, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 0.001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'sgd'} \n",
        "\n",
        "Best so far: 0.49802517306166694 \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': None} <br>\n",
        "Συνολικός χρόνος fit και predict: 418.2179820537567 seconds\n",
        "Accuracy:  0.49333333333333335<br>\n",
        "Precision_Recall_fscore:  (0.49333333333333335, 0.49333333333333335, 0.4933333333333334, None)<br>\n",
        "Precision_Recall_fscore:  (0.5064258046007876, 0.4932723800700754, 0.49802517306166694, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 0.001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'sgd', 'selector__threshold': 0.0017} \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': None, 'scaler': 'zscore', 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 265.14181303977966 seconds\n",
        "Accuracy:  0.5017391304347826<br>\n",
        "Precision_Recall_fscore:  (0.5017391304347826, 0.5017391304347826, 0.5017391304347826, None)<br>\n",
        "Precision_Recall_fscore:  (0.5079471094705704, 0.5013292544838859, 0.5029988897908113, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 1e-05, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 120, 'MLP__solver': 'lbfgs', 'pca__n_components': 30} \n",
        "\n",
        "Best so far: 0.5029988897908113 \n",
        "\n",
        " f1-macro Preprocessing steps:  {'sampling': None, 'selector': 'VT', 'scaler': 'zscore', 'extractor': 'PCA'} <br>\n",
        "Συνολικός χρόνος fit και predict: 851.7301435470581 seconds\n",
        "Accuracy:  0.5136231884057971<br>\n",
        "Precision_Recall_fscore:  (0.5136231884057971, 0.5136231884057971, 0.5136231884057971, None)<br>\n",
        "Precision_Recall_fscore:  (0.5168959908192678, 0.5140317050916288, 0.5139550454032816, None)<br>\n",
        "{'MLP__activation': 'relu', 'MLP__alpha': 0.001, 'MLP__hidden_layer_sizes': (15,), 'MLP__learning_rate': 'constant', 'MLP__max_iter': 80, 'MLP__solver': 'lbfgs', 'pca__n_components': 30, 'selector__threshold': 0.0017} \n",
        "\n",
        "Best so far: 0.5139550454032816"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUPoKHzZw4LY",
        "colab_type": "text"
      },
      "source": [
        "##### Ανάλυση Δεδομένων"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oq-RvJmw8EX",
        "colab_type": "text"
      },
      "source": [
        "Παρακάτω φαίνονται οι χρόνοι εκτέλεσης. Παρατηρούμε τον μεγάλο χρόνο για τον kNN, που οφείλεται, όπως είπαμε παραπάνω, στην πρόβλεψη λόγω του υπολογισμού των αποστάσεων. Αντίθετα ο GNB είναι πιο γρήγορος, το οποίο οφείλεται σε μεγάλο βαθμό στις υποθέσεις που κάνει, οι οποίες μας εξασφαλίζουν αρκετή πληροφορία, την οποία δεν χρειάζεται να αναζητήσουμε αλλιώς. Επίσης ο GNB εκπαιδεύεται αρκετά γρηγορότερα από το MLP, καθώς στο δεύτερο πρέπει να υπολογιστούν όλα τα βάρη μέσω του backpropagation, το οποίο είναι μια αρκετά αργή διαδικασία.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0krosFPteMXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6cce3b03-cf17-4fb7-93bd-94c992c271e5"
      },
      "source": [
        "print(\"GNB time (micro): \", best_GNB_micro_time)\n",
        "print(\"GNB time (macro): \", best_GNB_macro_time)\n",
        "print(\"kNN time (micro): \", 179.2935791015625)\n",
        "print(\"kNN time (macro): \", 738.8507409095764)\n",
        "print(\"MLP time(micro): \", 1111.2693781852722)\n",
        "print(\"MLP time(macro): \", 851.7301435470581)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GNB time (micro):  5.500432968139648\n",
            "GNB time (macro):  1.843648910522461\n",
            "kNN time (micro):  179.2935791015625\n",
            "kNN time (macro):  738.8507409095764\n",
            "MLP time(micro):  1111.2693781852722\n",
            "MLP time(macro):  851.7301435470581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3eEt_zDzrEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "6c1fd944-ece9-436b-cd66-62ce1c0ea395"
      },
      "source": [
        "n_groups = 4\n",
        "f1_micro = (f1_score(test_labels, preds_uniform, average = 'micro'), \n",
        "            0.6652173913043479, \n",
        "            0.571304347826087, \n",
        "            0.5028985507246376)\n",
        "\n",
        "f1_macro = (f1_score(test_labels, preds_uniform, average = 'macro'), \n",
        "            0.6502906107965731, \n",
        "            0.5657971014492753, \n",
        "            0.5139550454032816)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "index = np.arange(n_groups)\n",
        "bar_width = 0.3\n",
        "opacity = 0.7\n",
        "\n",
        "rects1 = plt.bar(index, f1_micro, bar_width,\n",
        "alpha=opacity,\n",
        "color='b',\n",
        "label='F1 micro ')\n",
        "\n",
        "rects2 = plt.bar(index + bar_width, f1_macro, bar_width,\n",
        "alpha=opacity,\n",
        "color='g',\n",
        "label='F1 macro')\n",
        "\n",
        "plt.xlabel('Classifier')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Scores by classifier')\n",
        "plt.xticks(index + bar_width, (\"Uniform\", \"GNB\", \"kNN\", \"MLP\"))\n",
        "plt.legend()\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OKV2O0k5wmp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "8a713f14-a9de-4db9-e7f0-7eec499c0094"
      },
      "source": [
        "n_groups = 3\n",
        "before_micro = (0.4405797101449275, \n",
        "            0.4692753623188406, \n",
        "            0.1910144927536232)\n",
        "\n",
        "after_micro = (0.6652173913043479, \n",
        "            0.571304347826087, \n",
        "            0.5028985507246376)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "index = np.arange(n_groups)\n",
        "bar_width = 0.3\n",
        "opacity = 0.7\n",
        "\n",
        "rects1 = plt.bar(index, before_micro, bar_width,\n",
        "alpha=opacity,\n",
        "color='b',\n",
        "label='F1 micro (before)')\n",
        "\n",
        "rects2 = plt.bar(index + bar_width, after_micro, bar_width,\n",
        "alpha=opacity,\n",
        "color='g',\n",
        "label='F1 micro (after)')\n",
        "\n",
        "plt.xlabel('Classifier')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Scores by classifier')\n",
        "plt.xticks(index + bar_width, (\"GNB\", \"kNN\", \"MLP\"))\n",
        "plt.legend()\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9h3RF9dEC6q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "f7e47951-346e-4389-a084-fd2d32b3d38d"
      },
      "source": [
        "n_groups = 3\n",
        "before_macro = (0.42572395425713394, \n",
        "            0.4436424483615854, \n",
        "            0.15061076919861244)\n",
        "\n",
        "after_macro = (0.6502906107965731, \n",
        "            0.571304347826087, \n",
        "            0.5139550454032816)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "index = np.arange(n_groups)\n",
        "bar_width = 0.3\n",
        "opacity = 0.7\n",
        "\n",
        "rects1 = plt.bar(index, before_macro, bar_width,\n",
        "alpha=opacity,\n",
        "color='b',\n",
        "label='F1 macro (before)')\n",
        "\n",
        "rects2 = plt.bar(index + bar_width, after_macro, bar_width,\n",
        "alpha=opacity,\n",
        "color='g',\n",
        "label='F1 macro (after)')\n",
        "\n",
        "plt.xlabel('Classifier')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Scores by classifier')\n",
        "plt.xticks(index + bar_width, (\"GNB\", \"kNN\", \"MLP\"))\n",
        "plt.legend()\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ2FKd9jD9uB",
        "colab_type": "text"
      },
      "source": [
        "Παρατηρείται εντυπωσιακή αύξηση στα αποτελέσματα και των 3 εκτιμητών μετά την προεπεξεργασία. Η μεγαλύτερη αύξηση παρατηρείται στο νευρωνικό, μετά στην GBN και τέλος στο kNN. \n",
        "* Στους GNB και kNN είναι εμφανές πως οφείλεται στο PCA. Υπάρχουν 2 περιοχές τιμών, αυτές που προκύπτουν όταν χρησιμοποιείται και αυτές που προκύπτουν οταν δεν εφαρμόζεται. Οι συνιστώσες που μένουν είναι κυρίως 50 και 30 αντίστοιχα από τις 178 αρχικές. \n",
        "* Στο MLP παρατηρούμε πως χρήσιμος είναι και ο z-score και ο PCA. Με τον z-score οι είσοδοι αντιμετωπίζονται ισότιμα και αποφεύγεται το overfitting λόγω ειδικών περιπτώσεων. Με τον PCA μειώνεται ο αριθμός των χαρακτηριστικών, κάτι το οποίο βοηθά επίσης το μοντέλο να γενικεύσει καλύτερα με τα δείγματα που έχει για train.\n",
        "\n",
        "Λόγω της ισορροπίας του dataset δεν παρατηρείται ιδιαίτερη διαφορά μεταξύ f1-micro και f1-macro. \n",
        "\n",
        "Ενδιαφέρον είχε το γεγονός οτι επιλέχθηκε σε όλες τις περιπτώσει το k στον αλγόριθμο kNN να πάρει την τιμή 1. Στην αρχή ξεκινήσαμε από 1 πολύ μεγαλύτερο σύνολο περιπτώσεων για το k (μέχρι 50), ωστόσο επέμεινε στην τιμή 1, γεγονός που ίσως οφείλεται σε ιδιαιτερότητες του dataset. Επίσης επιλέγεται γενικώς η Ευκλείδια απόσταση και η ομοιόφορφη σημασιολόγηση των αποστάσεων.\n",
        "\n",
        "Δυστυχώς δεν προλάβαμε να εκπαιδεύσουμε το MLP όπως θα θέλαμε και χρησιμοποιήσαμε μόνο 1000 από τα 8500 δείγματα. Ωστόσο, ακόμα και έτσι τα ποιοτικά χαρακτηριστικά όπως η ανάγκη για προεγρασία είναι εμφανή. Επιβεβαιώνεται λοιπόν η σημασία της προεργασίας για τα νευρωνικά λόγω της ευαισθησίας των παραμέτρων στα χαρακτηριστικά των τιμών εισόδου. <br>\n",
        "Το learning rate παραμένει σταθερό ενώ ο βέλτιστος αριθμός επιπέδων είναι κυρίως 15.\n",
        "\n"
      ]
    }
  ]
}